<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>Coyote Tester | kafka-connect-cassandra v0.2.2 | Results</title>

    </head>
    <body>

        <div id="testResults" style="display:inline;width:33%"></div>
        <div id="testTimes" style="display:inline;width:66%"></div>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.4.4/d3.min.js"></script>
        <script src="https://storage.googleapis.com/artifacts-landoop/d3pie.min.js"></script>
        <script>
         var pie = new d3pie("testResults", {
             "header": {
                 "title": {
                     "text": "all passed",
                     "color": "#fffefe",
                     "fontSize": 34,
                     "font": "sans"
                 },
                 "subtitle": {
                     "text": "kafka-connect-cassandra v0.2.2",
                     "color": "#E8E6E6",
                     "fontSize": 14,
                     "font": "sans"
                 },
                 "location": "pie-center",
                 "titleSubtitlePadding": 10
             },
             "footer": {
                "text": "Coyote-tester, part of Landoopâ„¢ test-suite. 2016 Oct 12, Wed, 21:52 UTC",
                "color": "#E8E6E6",
                "fontSize": 14,
                "font": "open sans",
                "location": "bottom-left"
             },
             "size": {
                 "canvasHeight": 375,
                 "canvasWidth": 500,
                 "pieInnerRadius": "72%",
                 "pieOuterRadius": "92%"
             },
             "data": {
                 "sortOrder": "label-desc",
                 "content": [
                     {
                         "label": "failed",
                         "value": 0,
                         "color": "#e21515"
                     },
                     {
                         "label": "passed",
                         "value": 15,
                         "color": "#64a61f"
                     }
                 ]
             },
             "labels": {
                 "outer": {
                     "format": "label-percentage1",
                     "pieDistance": 25
                 },
                 "inner": {
                     "format": "none"
                 },
                 "mainLabel": {
                     "color": "#ffffff",
                     "fontSize": 16
                 },
                 "percentage": {
                     "color": "#919191",
                     "fontSize": 16,
                     "decimalPlaces": 1
                 },
                 "value": {
                     "color": "#cccc43",
                     "fontSize": 16
                 },
                 "lines": {
                     "enabled": true,
                     "color": "#777777"
                 },
                 "truncation": {
                     "enabled": true
                 }
             },
             "effects": {
                 "pullOutSegmentOnClick": {
                     "effect": "linear",
                     "speed": 400,
                     "size": 8
                 }
             },
             "misc": {
                 "colors": {
                     "background": "#2b2b2b",
                     "segmentStroke": "#f6f6f6"
                 }
             }
         });
        </script>
        <script>
         var pie = new d3pie("testTimes", {
             "header": {
                 "title": {
                     "text": "57 s",
                     "color": "#fffefe",
                     "fontSize": 34,
                     "font": "sans"
             },
                 "subtitle": {
                     "text": "total time",
                     "color": "#999999",
                     "fontSize": 14,
                     "font": "sans"
                 },
                 "location": "pie-center",
                 "titleSubtitlePadding": 10
             },
             "footer": {
                "text": "",
                "color": "#999999",
                "fontSize": 10,
                "font": "open sans",
                "location": "bottom-left"
             },
             "size": {
                 "canvasHeight": 375,
                 "canvasWidth": 700,
                 "pieInnerRadius": "72%",
                 "pieOuterRadius": "85%"
             },
             "data": {
                 "sortOrder": "label-desc",
                 "smallSegmentGrouping": {
                     "enabled": true,
                     "value": 3
                 },
                 "content": [
                     {
                         "label": "Setup Containers, Docker Compose Pull",
                         "value": 1.864029956,
                         "color": "#2383c1"
                     },{
                         "label": "Setup Containers, Build Docker Images",
                         "value": 0.42921604900000004,
                         "color": "#64a61f"
                     },{
                         "label": "Setup Containers, Docker Compose Up",
                         "value": 2.604413226,
                         "color": "#7b6788"
                     },{
                         "label": "Setup Containers, Check docker compose log",
                         "value": 0.545461847,
                         "color": "#a05c56"
                     },{
                         "label": "Setup Cassandra Source Connector, Create Source Topic",
                         "value": 2.34657838,
                         "color": "#961919"
                     },{
                         "label": "Setup Cassandra Source Connector, Create Cassandra Source Table and Data",
                         "value": 2.358830267,
                         "color": "#d8d239"
                     },{
                         "label": "Setup Cassandra Source Connector, Create a Cassandra Source Distributed Connector",
                         "value": 1.531217976,
                         "color": "#e98125"
                     },{
                         "label": "Setup Cassandra Sink Connector, Create Sink Topic",
                         "value": 3.429319496,
                         "color": "#d0743c"
                     },{
                         "label": "Setup Cassandra Sink Connector, Create Cassandra Sink Table",
                         "value": 2.213271093,
                         "color": "#635122"
                     },{
                         "label": "Setup Cassandra Sink Connector, Create a Cassandra Sink Distributed Connector",
                         "value": 1.164907715,
                         "color": "#6ada6a"
                     },{
                         "label": "Test Cassandra Source Connector, Read Entries from Topic",
                         "value": 20.799471143,
                         "color": "#0b6197"
                     },{
                         "label": "Test Cassandra Sink Connector, Write Entries into Topic",
                         "value": 2.931199913,
                         "color": "#7c9058"
                     },{
                         "label": "Test Cassandra Sink Connector, Verify entries",
                         "value": 2.237279749,
                         "color": "#207f32"
                     },{
                         "label": "Other Tests, Read First 2000 Lines of Connect Logs",
                         "value": 0.051854458000000006,
                         "color": "#44b9af"
                     },{
                         "label": "Clean-up Containers, Docker Compose Down",
                         "value": 12.289162284,
                         "color": "#2383c1"
                     },
                 ]
             },
             "labels": {
                 "outer": {
                     "format": "label-percentage1",
                     "pieDistance": 25
                 },
                 "inner": {
                     "format": "none"
                 },
                 "mainLabel": {
                     "color": "#ffffff",
                     "fontSize": 12
                 },
                 "percentage": {
                     "color": "#919191",
                     "fontSize": 12,
                     "decimalPlaces": 1
                 },
                 "value": {
                     "color": "#cccc43",
                     "fontSize": 12
                 },
                 "lines": {
                     "enabled": true,
                     "color": "#777777"
                 },
                 "truncation": {
                     "enabled": true
                 }
             },
             "effects": {
                 "pullOutSegmentOnClick": {
                     "effect": "linear",
                     "speed": 400,
                     "size": 8
                 }
             },
             "misc": {
                 "colors": {
                     "background": "#2b2b2b",
                     "segmentStroke": "#f6f6f6"
                 }
             }
         });
        </script>

        <style type="text/css">
         body {
             font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial;
             font-size: 14px;
             line-height: 20px;
             font-weight: 400;
             color: #3b3b3b;
             -webkit-font-smoothing: antialiased;
             font-smoothing: antialiased;
             background: #2b2b2b;
         }

         .wrapper {
             margin: 0 auto;
             padding: 40px;
             /*max-width: 800px;*/
         }

         div.ui-tooltip {
             color: red;
             border-radius: 20px;
             /*font: bold 12px "Helvetica Neue", Sans-Serif;*/
             /*text-transform: uppercase;*/
             box-shadow: 0 0 7px black;
             /*width: 400px;*/
             word-wrap: "normal";
             max-width: 900px;
         }

         .ui-tooltip-content {
             color: black;
             font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
             word-wrap: "normal";
             /*max-width: 900px;*/
         }

         .table {
             margin: 0 0 40px 0;
             width: 100%;
             box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2);
             display: table;
         }

         @media screen and (max-width: 90%) {
             .table {
                 display: block;
             }
         }

         .row {
             display: table-row;
             background: #f6f6f6;
         }

         .row:nth-of-type(odd) {
             background: #e9e9e9;
         }

         .row.header {
             font-weight: 900;
             color: #ffffff;
             background: #ea6153;
         }
         .row.green {
             background: #27ae60;
         }
         .row.blue {
             background: #2980b9;
         }
         .row.purple {
             background: #8e44ad;
         }
         .row.gray {
             background: #2c3e50;
         }
         .row.yellow {
             background: #f1c40f;
         }
         .row.orange {
             background: #d35400;
         }
         .row.turquoise {
             background: #1abc9c;
         }

         @media screen and (max-width: 90%) {
             .row {
                 padding: 8px 0;
                 display: block;
             }
         }

         .cell {
             padding: 6px 12px;
             display: table-cell;
         }

         .cell.red {
             background: #ea6153;
         }

         .cell.green {
             background: #27ae60;
         }

         .cell.skip {
             background: #2b2b2b;
         }

         .cell.center {
             text-align: center;
         }

         .cell.width12 {
             width: 12%;
             max-width: 10px;
         }
         @media screen and (max-width: 90%) {
             .cell {
                 padding: 2px 12px;
                 display: block;
             }
         }
         /* .hideContent {overflow:hidden;line-height:1em;height:2em;}
            .showContent {line-height:1em;height:auto;}
          */
        </style>

        <div class="wrapper">

            <div class="table">
            <div class="row header">
                    <div class="cell">
                        Setup Containers
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Docker Compose Pull
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.86
                    </div>
                    <div class="cell">
                        (ignore) 1
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose pull</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose pull
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                        Pulling repository docker.io/landoop/cassandra
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_0" class="trigger" data-tooltip-id="0_0" title="Pulling cassandra (landoop/cassandra:latest)...</br>Error: image landoop/cassandra:latest not found</br></br>">view</button>
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Build Docker Images
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        0.43
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose build</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose build
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_1" class="trigger" data-tooltip-id="0_1" title="Step 1 : FROM cassandra:latest</br> ---&gt; a552f6550254</br>Step 2 : MAINTAINER Marios Andreopoulos &lt;marios@landoop.com&gt;</br> ---&gt; Using cache</br> ---&gt; e58ed2491a79</br>Step 3 : RUN sed -e &#39;s/authenticator: AllowAllAuthenticator/authenticator: PasswordAuthenticator/&#39;         -i /etc/cassandra/cassandra.yaml</br> ---&gt; Using cache</br> ---&gt; 27808c1c0b3c</br>Successfully built 27808c1c0b3c</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_1" class="trigger" data-tooltip-id="0_1" title="Building cassandra</br>fast-data-dev uses an image, skipping</br></br>">view</button>
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Docker Compose Up
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.60
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose up -d</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose up -d
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_2" class="trigger" data-tooltip-id="0_2" title="Creating network &#34;kafkaconnectcassandra_default&#34; with the default driver</br>Creating kafkaconnectcassandra_cassandra_1</br>Creating kafkaconnectcassandra_fast-data-dev_1</br></br>">view</button>
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Check docker compose log
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        0.55
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose logs</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose logs
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_3" class="trigger" data-tooltip-id="0_3" title="Attaching to kafkaconnectcassandra_fast-data-dev_1, kafkaconnectcassandra_cassandra_1</br>[33mcassandra_1      |[0m INFO  21:49:18 Configuration location: file:/etc/cassandra/cassandra.yaml</br>[36mfast-data-dev_1  |[0m [92mSetting advertised host to [96mfast-data-dev[34m[92m.[34m</br>[33mcassandra_1      |[0m INFO  21:49:19 Node configuration:[allocate_tokens_for_keyspace=null; authenticator=PasswordAuthenticator; authorizer=AllowAllAuthorizer; auto_bootstrap=true; auto_snapshot=true; batch_size_fail_threshold_in_kb=50; batch_size_warn_threshold_in_kb=5; batchlog_replay_throttle_in_kb=1024; broadcast_address=172.19.0.2; broadcast_rpc_address=172.19.0.2; buffer_pool_use_heap_if_exhausted=true; cas_contention_timeout_in_ms=1000; cdc_enabled=false; cdc_free_space_check_interval_ms=250; cdc_raw_directory=null; cdc_total_space_in_mb=null; client_encryption_options=&lt;REDACTED&gt;; cluster_name=Test Cluster; column_index_cache_size_in_kb=2; column_index_size_in_kb=64; commit_failure_policy=stop; commitlog_compression=null; commitlog_directory=/var/lib/cassandra/commitlog; commitlog_max_compression_buffers_in_pool=3; commitlog_periodic_queue_size=-1; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_batch_window_in_ms=null; commitlog_sync_period_in_ms=10000; commitlog_total_space_in_mb=null; compaction_large_partition_warning_threshold_mb=100; compaction_throughput_mb_per_sec=16; concurrent_compactors=null; concurrent_counter_writes=32; concurrent_materialized_view_writes=32; concurrent_reads=32; concurrent_replicates=null; concurrent_writes=32; counter_cache_keys_to_save=2147483647; counter_cache_save_period=7200; counter_cache_size_in_mb=null; counter_write_request_timeout_in_ms=5000; credentials_cache_max_entries=1000; credentials_update_interval_in_ms=-1; credentials_validity_in_ms=2000; cross_node_timeout=false; data_file_directories=[Ljava.lang.String;@29176cc1; disk_access_mode=auto; disk_failure_policy=stop; disk_optimization_estimate_percentile=0.95; disk_optimization_page_cross_chance=0.1; disk_optimization_strategy=ssd; dynamic_snitch=true; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; enable_scripted_user_defined_functions=false; enable_user_defined_functions=false; enable_user_defined_functions_threads=true; encryption_options=null; endpoint_snitch=SimpleSnitch; file_cache_size_in_mb=null; gc_log_threshold_in_ms=200; gc_warn_threshold_in_ms=1000; hinted_handoff_disabled_datacenters=[]; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_compression=null; hints_directory=null; hints_flush_period_in_ms=10000; incremental_backups=false; index_interval=null; index_summary_capacity_in_mb=null; index_summary_resize_interval_in_minutes=60; initial_token=null; inter_dc_stream_throughput_outbound_megabits_per_sec=200; inter_dc_tcp_nodelay=false; internode_authenticator=null; internode_compression=dc; internode_recv_buff_size_in_bytes=null; internode_send_buff_size_in_bytes=null; key_cache_keys_to_save=2147483647; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=172.19.0.2; listen_interface=null; listen_interface_prefer_ipv6=false; listen_on_broadcast_address=false; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; max_hints_file_size_in_mb=128; max_mutation_size_in_kb=null; max_streaming_retries=3; max_value_size_in_mb=256; memtable_allocation_type=heap_buffers; memtable_cleanup_threshold=null; memtable_flush_writers=1; memtable_heap_space_in_mb=null; memtable_offheap_space_in_mb=null; min_free_space_per_drive_in_mb=50; native_transport_max_concurrent_connections=-1; native_transport_max_concurrent_connections_per_ip=-1; native_transport_max_frame_size_in_mb=256; native_transport_max_threads=128; native_transport_port=9042; native_transport_port_ssl=null; num_tokens=256; otc_coalescing_strategy=TIMEHORIZON; otc_coalescing_window_us=200; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_cache_max_entries=1000; permissions_update_interval_in_ms=-1; permissions_validity_in_ms=2000; phi_convict_threshold=8.0; prepared_statements_cache_size_mb=null; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_scheduler_id=null; request_scheduler_options=null; request_timeout_in_ms=10000; role_manager=CassandraRoleManager; roles_cache_max_entries=1000; roles_update_interval_in_ms=-1; roles_validity_in_ms=2000; row_cache_class_name=org.apache.cassandra.cache.OHCProvider; row_cache_keys_to_save=2147483647; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=0.0.0.0; rpc_interface=null; rpc_interface_prefer_ipv6=false; rpc_keepalive=true; rpc_listen_backlog=50; rpc_max_threads=2147483647; rpc_min_threads=16; rpc_port=9160; rpc_recv_buff_size_in_bytes=null; rpc_send_buff_size_in_bytes=null; rpc_server_type=sync; saved_caches_directory=/var/lib/cassandra/saved_caches; seed_provider=org.apache.cassandra.locator.SimpleSeedProvider{seeds=172.19.0.2}; server_encryption_options=&lt;REDACTED&gt;; snapshot_before_compaction=false; ssl_storage_port=7001; sstable_preemptive_open_interval_in_mb=50; start_native_transport=true; start_rpc=false; storage_port=7000; stream_throughput_outbound_megabits_per_sec=200; streaming_socket_timeout_in_ms=86400000; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; thrift_prepared_statements_cache_size_mb=null; tombstone_failure_threshold=100000; tombstone_warn_threshold=1000; tracetype_query_ttl=86400; tracetype_repair_ttl=604800; transparent_data_encryption_options=org.apache.cassandra.config.TransparentDataEncryptionOptions@2f177a4b; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; unlogged_batch_across_partitions_warn_threshold=10; user_defined_function_fail_timeout=1500; user_defined_function_warn_timeout=500; user_function_timeout_policy=die; windows_timer_interval=1; write_request_timeout_in_ms=2000]</br>[36mfast-data-dev_1  |[0m [92mStarting services.[39m</br>[33mcassandra_1      |[0m INFO  21:49:19 DiskAccessMode &#39;auto&#39; determined to be mmap, indexAccessMode is mmap</br>[36mfast-data-dev_1  |[0m [34mYou may visit [96mhttp://fast-data-dev:3030[34m in about a minute.[39m</br>[33mcassandra_1      |[0m INFO  21:49:19 Global memtable on-heap threshold is enabled at 1996MB</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:11,900 CRIT Supervisor running as root (no user in config file)</br>[33mcassandra_1      |[0m INFO  21:49:19 Global memtable off-heap threshold is enabled at 1996MB</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:11,904 INFO supervisord started with pid 7</br>[33mcassandra_1      |[0m INFO  21:49:19 Hostname: 44a80e65ffe3</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:12,906 INFO spawned: &#39;zookeeper&#39; with pid 48</br>[33mcassandra_1      |[0m INFO  21:49:19 JVM vendor/version: OpenJDK 64-Bit Server VM/1.8.0_102</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:12,907 INFO spawned: &#39;caddy&#39; with pid 49</br>[33mcassandra_1      |[0m INFO  21:49:19 Heap size: 7.800GiB/7.800GiB</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:12,908 INFO spawned: &#39;broker&#39; with pid 50</br>[33mcassandra_1      |[0m INFO  21:49:19 Code Cache Non-heap memory: init = 2555904(2496K) used = 6346368(6197K) committed = 6422528(6272K) max = 251658240(245760K)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:12,909 INFO spawned: &#39;smoke-tests&#39; with pid 51</br>[33mcassandra_1      |[0m INFO  21:49:19 Metaspace Non-heap memory: init = 0(0K) used = 15734080(15365K) committed = 16252928(15872K) max = -1(-1K)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:12,911 INFO spawned: &#39;connect-distributed&#39; with pid 52</br>[33mcassandra_1      |[0m INFO  21:49:19 Compressed Class Space Non-heap memory: init = 0(0K) used = 1903928(1859K) committed = 2097152(2048K) max = 1073741824(1048576K)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:12,912 INFO spawned: &#39;logs-to-kafka&#39; with pid 54</br>[33mcassandra_1      |[0m INFO  21:49:19 Par Eden Space Heap memory: init = 1718091776(1677824K) used = 309264560(302016K) committed = 1718091776(1677824K) max = 1718091776(1677824K)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:12,913 INFO spawned: &#39;schema-registry&#39; with pid 55</br>[33mcassandra_1      |[0m INFO  21:49:19 Par Survivor Space Heap memory: init = 214695936(209664K) used = 0(0K) committed = 214695936(209664K) max = 214695936(209664K)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:12,915 INFO spawned: &#39;rest-proxy&#39; with pid 57</br>[33mcassandra_1      |[0m INFO  21:49:19 CMS Old Gen Heap memory: init = 6442450944(6291456K) used = 0(0K) committed = 6442450944(6291456K) max = 6442450944(6291456K)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:13,997 INFO success: zookeeper entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:13,997 INFO success: caddy entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:49:19 Classpath: /etc/cassandra:/usr/share/cassandra/lib/HdrHistogram-2.1.9.jar:/usr/share/cassandra/lib/ST4-4.0.8.jar:/usr/share/cassandra/lib/airline-0.6.jar:/usr/share/cassandra/lib/antlr-runtime-3.5.2.jar:/usr/share/cassandra/lib/asm-5.0.4.jar:/usr/share/cassandra/lib/caffeine-2.2.6.jar:/usr/share/cassandra/lib/cassandra-driver-core-3.0.1-shaded.jar:/usr/share/cassandra/lib/commons-cli-1.1.jar:/usr/share/cassandra/lib/commons-codec-1.2.jar:/usr/share/cassandra/lib/commons-lang3-3.1.jar:/usr/share/cassandra/lib/commons-math3-3.2.jar:/usr/share/cassandra/lib/compress-lzf-0.8.4.jar:/usr/share/cassandra/lib/concurrent-trees-2.4.0.jar:/usr/share/cassandra/lib/concurrentlinkedhashmap-lru-1.4.jar:/usr/share/cassandra/lib/disruptor-3.0.1.jar:/usr/share/cassandra/lib/ecj-4.4.2.jar:/usr/share/cassandra/lib/guava-18.0.jar:/usr/share/cassandra/lib/high-scale-lib-1.0.6.jar:/usr/share/cassandra/lib/hppc-0.5.4.jar:/usr/share/cassandra/lib/jackson-core-asl-1.9.2.jar:/usr/share/cassandra/lib/jackson-mapper-asl-1.9.2.jar:/usr/share/cassandra/lib/jamm-0.3.0.jar:/usr/share/cassandra/lib/javax.inject.jar:/usr/share/cassandra/lib/jbcrypt-0.3m.jar:/usr/share/cassandra/lib/jcl-over-slf4j-1.7.7.jar:/usr/share/cassandra/lib/jflex-1.6.0.jar:/usr/share/cassandra/lib/jna-4.0.0.jar:/usr/share/cassandra/lib/joda-time-2.4.jar:/usr/share/cassandra/lib/json-simple-1.1.jar:/usr/share/cassandra/lib/libthrift-0.9.2.jar:/usr/share/cassandra/lib/log4j-over-slf4j-1.7.7.jar:/usr/share/cassandra/lib/logback-classic-1.1.3.jar:/usr/share/cassandra/lib/logback-core-1.1.3.jar:/usr/share/cassandra/lib/lz4-1.3.0.jar:/usr/share/cassandra/lib/metrics-core-3.1.0.jar:/usr/share/cassandra/lib/metrics-jvm-3.1.0.jar:/usr/share/cassandra/lib/metrics-logback-3.1.0.jar:/usr/share/cassandra/lib/netty-all-4.0.39.Final.jar:/usr/share/cassandra/lib/ohc-core-0.4.3.jar:/usr/share/cassandra/lib/ohc-core-j8-0.4.3.jar:/usr/share/cassandra/lib/primitive-1.0.jar:/usr/share/cassandra/lib/reporter-config-base-3.0.0.jar:/usr/share/cassandra/lib/reporter-config3-3.0.0.jar:/usr/share/cassandra/lib/sigar-1.6.4.jar:/usr/share/cassandra/lib/slf4j-api-1.7.7.jar:/usr/share/cassandra/lib/snakeyaml-1.11.jar:/usr/share/cassandra/lib/snappy-java-1.1.1.7.jar:/usr/share/cassandra/lib/snowball-stemmer-1.3.0.581.1.jar:/usr/share/cassandra/lib/stream-2.5.2.jar:/usr/share/cassandra/lib/thrift-server-0.3.7.jar:/usr/share/cassandra/apache-cassandra-3.9.jar:/usr/share/cassandra/apache-cassandra-thrift-3.9.jar:/usr/share/cassandra/apache-cassandra.jar:/usr/share/cassandra/stress.jar::/usr/share/cassandra/lib/jamm-0.3.0.jar</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:13,997 INFO success: broker entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:49:19 JVM Arguments: [-Xloggc:/var/log/cassandra/gc.log, -ea, -XX:+UseThreadPriorities, -XX:ThreadPriorityPolicy=42, -XX:+HeapDumpOnOutOfMemoryError, -Xss256k, -XX:StringTableSize=1000003, -XX:+AlwaysPreTouch, -XX:-UseBiasedLocking, -XX:+UseTLAB, -XX:+ResizeTLAB, -XX:+PerfDisableSharedMem, -Djava.net.preferIPv4Stack=true, -XX:+UseParNewGC, -XX:+UseConcMarkSweepGC, -XX:+CMSParallelRemarkEnabled, -XX:SurvivorRatio=8, -XX:MaxTenuringThreshold=1, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:CMSWaitDuration=10000, -XX:+CMSParallelInitialMarkEnabled, -XX:+CMSEdenChunksRecordAlways, -XX:+CMSClassUnloadingEnabled, -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, -XX:+PrintHeapAtGC, -XX:+PrintTenuringDistribution, -XX:+PrintGCApplicationStoppedTime, -XX:+PrintPromotionFailure, -XX:+UseGCLogFileRotation, -XX:NumberOfGCLogFiles=10, -XX:GCLogFileSize=10M, -Xms8192M, -Xmx8192M, -Xmn2048M, -XX:CompileCommandFile=/etc/cassandra/hotspot_compiler, -javaagent:/usr/share/cassandra/lib/jamm-0.3.0.jar, -Dcassandra.jmx.local.port=7199, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.password.file=/etc/cassandra/jmxremote.password, -Djava.library.path=/usr/share/cassandra/lib/sigar-bin, -Dlogback.configurationFile=logback.xml, -Dcassandra.logdir=/var/log/cassandra, -Dcassandra.storagedir=/var/lib/cassandra, -Dcassandra-foreground=yes]</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:13,997 INFO success: smoke-tests entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m WARN  21:49:20 Unable to lock JVM memory (ENOMEM). This can result in part of the JVM being swapped out, especially with mmapped I/O enabled. Increase RLIMIT_MEMLOCK or run Cassandra as root.</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:13,997 INFO success: connect-distributed entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:13,997 INFO success: logs-to-kafka entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:13,997 INFO success: schema-registry entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:13,998 INFO success: rest-proxy entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:14,824 INFO exited: schema-registry (exit status 1; not expected)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:14,829 INFO spawned: &#39;schema-registry&#39; with pid 442</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:14,850 INFO exited: rest-proxy (exit status 1; not expected)</br>[33mcassandra_1      |[0m WARN  21:49:20 jemalloc shared library could not be preloaded to speed up memory allocations</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:14,853 INFO spawned: &#39;rest-proxy&#39; with pid 473</br>[33mcassandra_1      |[0m WARN  21:49:20 JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:16,099 INFO success: schema-registry entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m WARN  21:49:20 OpenJDK is not recommended. Please upgrade to the newest Oracle Java release</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:16,099 INFO success: rest-proxy entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:49:20 Initializing SIGAR library</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:42,924 INFO exited: smoke-tests (exit status 0; expected)</br>[33mcassandra_1      |[0m INFO  21:49:20 Checked OS settings and found them configured for optimal performance.</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:49:52,920 INFO exited: logs-to-kafka (exit status 0; expected)</br>[33mcassandra_1      |[0m WARN  21:49:20 Directory /var/lib/cassandra/data doesn&#39;t exist</br>[33mcassandra_1      |[0m WARN  21:49:20 Directory /var/lib/cassandra/commitlog doesn&#39;t exist</br>[33mcassandra_1      |[0m WARN  21:49:20 Directory /var/lib/cassandra/saved_caches doesn&#39;t exist</br>[33mcassandra_1      |[0m WARN  21:49:20 Directory /var/lib/cassandra/hints doesn&#39;t exist</br>[33mcassandra_1      |[0m INFO  21:49:20 Initialized prepared statement caches with 31 MB (native) and 31 MB (Thrift)</br>[33mcassandra_1      |[0m INFO  21:49:20 Initializing system.IndexInfo</br>[33mcassandra_1      |[0m INFO  21:49:21 Initializing system.batches</br>[33mcassandra_1      |[0m INFO  21:49:21 Initializing system.paxos</br>[33mcassandra_1      |[0m INFO  21:49:21 Initializing system.local</br>[33mcassandra_1      |[0m INFO  21:49:21 Initializing system.peers</br>[33mcassandra_1      |[0m INFO  21:49:21 Initializing system.peer_events</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.range_xfers</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.compaction_history</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.sstable_activity</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.size_estimates</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.available_ranges</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.views_builds_in_progress</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.built_views</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.hints</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.batchlog</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.schema_keyspaces</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.schema_columnfamilies</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.schema_columns</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.schema_triggers</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.schema_usertypes</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.schema_functions</br>[33mcassandra_1      |[0m INFO  21:49:22 Initializing system.schema_aggregates</br>[33mcassandra_1      |[0m INFO  21:49:22 Not submitting build tasks for views in keyspace system as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:49:22 Configured JMX server at: service:jmx:rmi://127.0.0.1/jndi/rmi://127.0.0.1:7199/jmxrmi</br>[33mcassandra_1      |[0m INFO  21:49:23 Initializing key cache with capacity of 100 MBs.</br>[33mcassandra_1      |[0m INFO  21:49:23 Initializing row cache with capacity of 0 MBs</br>[33mcassandra_1      |[0m INFO  21:49:23 Initializing counter cache with capacity of 50 MBs</br>[33mcassandra_1      |[0m INFO  21:49:23 Scheduling counter cache save to every 7200 seconds (going to save all keys).</br>[33mcassandra_1      |[0m INFO  21:49:23 Global buffer pool is enabled, when pool is exhausted (max is 512.000MiB) it will allocate on heap</br>[33mcassandra_1      |[0m INFO  21:49:23 Populating token metadata from system tables</br>[33mcassandra_1      |[0m INFO  21:49:24 Token metadata: </br>[33mcassandra_1      |[0m INFO  21:49:24 Initializing system_schema.keyspaces</br>[33mcassandra_1      |[0m INFO  21:49:24 Initializing system_schema.tables</br>[33mcassandra_1      |[0m INFO  21:49:24 Initializing system_schema.columns</br>[33mcassandra_1      |[0m INFO  21:49:24 Initializing system_schema.triggers</br>[33mcassandra_1      |[0m INFO  21:49:24 Initializing system_schema.dropped_columns</br>[33mcassandra_1      |[0m INFO  21:49:24 Initializing system_schema.views</br>[33mcassandra_1      |[0m INFO  21:49:24 Initializing system_schema.types</br>[33mcassandra_1      |[0m INFO  21:49:24 Initializing system_schema.functions</br>[33mcassandra_1      |[0m INFO  21:49:24 Initializing system_schema.aggregates</br>[33mcassandra_1      |[0m INFO  21:49:24 Initializing system_schema.indexes</br>[33mcassandra_1      |[0m INFO  21:49:24 Not submitting build tasks for views in keyspace system_schema as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:49:24 Completed loading (14 ms; 1 keys) KeyCache cache</br>[33mcassandra_1      |[0m INFO  21:49:24 No commitlog files found; skipping replay</br>[33mcassandra_1      |[0m INFO  21:49:24 Populating token metadata from system tables</br>[33mcassandra_1      |[0m INFO  21:49:24 Token metadata: </br>[33mcassandra_1      |[0m INFO  21:49:24 Cassandra version: 3.9</br>[33mcassandra_1      |[0m INFO  21:49:24 Thrift API version: 20.1.0</br>[33mcassandra_1      |[0m INFO  21:49:24 CQL supported versions: 3.4.2 (default: 3.4.2)</br>[33mcassandra_1      |[0m INFO  21:49:24 Initializing index summary manager with a memory pool size of 399 MB and a resize interval of 60 minutes</br>[33mcassandra_1      |[0m INFO  21:49:24 Starting Messaging Service on /172.19.0.2:7000 (eth0)</br>[33mcassandra_1      |[0m WARN  21:49:24 No host ID found, created 6bb4d3d6-a26e-4c15-bc27-906c5e91718b (Note: This should happen exactly once per node).</br>[33mcassandra_1      |[0m INFO  21:49:24 Loading persisted ring state</br>[33mcassandra_1      |[0m INFO  21:49:24 Starting up server gossip</br>[33mcassandra_1      |[0m INFO  21:49:24 This node will not auto bootstrap because it is configured to be a seed node.</br>[33mcassandra_1      |[0m INFO  21:49:24 Generated random tokens. tokens are [-6307527403898871078, 8354199958673784895, 336908382534289928, 7313407741479144087, 8072196284594197946, -3878284723263886174, -3217090731793620111, -4629506238795662743, 5709600306267065488, 8102628918005762302, -5226079663995174147, -4028884849271280475, 8845506372990635391, 2020664681449645628, 6235910882659564206, -8444201143089260286, 2135306716459177120, -6508279993646941257, 2897060251731031485, -8270855397382240856, -2697944503602641290, 1919995235892130341, -4592181934964084013, -1494577622555953499, 7423118469285459633, 6018234995915914511, 3652447892446688098, 6904827990387738028, 6904627856842354880, -1411633208674455403, 486168761310591960, 465401801938550290, 4250645159791787616, 1017881057804846336, -4760144960371619464, 7603875333462537974, 9095591631535988135, 5451562358479575798, 3225789935599420199, -7202314700356406267, -5835812197261223241, 5810628396695172503, 6310919305376768894, 3937627516639672967, -664825429440242433, 71680053361778212, 8372106805794267250, -3220356199085755016, 1855635861492345832, 5390478747050000467, -7198218454555200373, 4130708914499908020, -8164024770589474822, -7398006027219552518, -8290734294837704045, 2716328581470122617, -2872165077005196387, 1837821091364936717, 7813097908443480022, 6878706415793333111, -2307397694787645991, -1565966151050669439, 287711385065103911, -5890624821842638371, 1905832986721815847, -8311325778732709098, -4168487167720277776, 1180941684328218645, -5177808917479658942, 7855467252595687403, -6056659821101987519, -465936973847236159, -149889712118817600, -4913058106874024395, 2874013004356803667, 6474644396870269395, -563469748493303589, 6221862682515504463, -1422503494087916207, -2529427288240712646, -4099885727222385369, -1083568536151619958, -8538309734802056347, 6734022776654882345, 5910744809699570564, -4205917721041349691, 5377177082773483309, -6569141111577450597, -8695369702221202733, -1719092425439936126, -7359408650177946492, 1942922024528806224, -1798372080552372377, 3093593188085279190, -1262850127370431048, 659496507449090661, -1343781404448527763, 1849229164054531207, 4511292325321603231, -6105661066133069764, 2381864490189938206, 1043800252879576382, -6896222823533586911, -6149907575363474140, -7281286550334013477, 8108275285330099229, 8757182809791720688, 6582672757121179800, -7088541606359495953, 4451866233757258054, -1046152260928522242, 8661063494856778120, 5744223395442349105, 9131961578485155557, 3309163918592687953, 577154650175013833, 243913611700309247, -5751652062488516222, 4893105466330597194, -7710882455083742539, 3962814685273330331, 4904744625608660166, 3379819320610384928, -9201436795425014326, -5473935059223826064, 7483645415620504073, 8659410610361738721, 5988060409855949856, 4602782065428774250, 3136427901638340295, 451469676521850879, 1161867221032198347, -8582017778909547613, 1313359741685854196, 8755958093164869311, 8051362402691369349, -4244495002744838600, 5877839975152064342, 8197368736765741161, 8075876687219143562, 3069724479980418607, 6970893555413454360, 8089444587005544242, 8834054561393194024, -503037153043742608, 599205247562166011, 6666570638739069716, -5517137263533227350, 2115128391615226603, 2170717045418389121, -4088507269031377936, -2332494175998168953, 4482866487981548024, 6451554476951966180, -5114333669198623171, 2427748136903782619, -468715775200692790, -8331265436949692923, 2872107310977630049, 8679905792027833545, 7237292323484013788, 7732778334070567397, -8931313963587660080, -143473911485587158, -7967077071628157752, -4121654045658250874, 7679166750955982620, 1016752508119497380, -8612613717667764067, 6639994686398879681, 6902013232646026244, 1396086221671485317, -126421377633898213, 3345439415936582698, 1015587720155526391, 8691255050884842990, 4087466234491257165, 4683026392654833133, 5191069765508472899, -5841113674929663867, 1149226643008611304, 3284888885843690666, -3108767770031983207, 3953264636815563779, 2296713602619186829, -6091529811708692579, 8005982317279358850, -3498678931640067477, -1429145646041571405, 7609482862370661027, -457647918401087767, -7163927966898711550, 1423394894826339725, 75041612152688168, -4332100448139976614, 1487572419258692452, -7808831000098961585, -1330769762798301287, -4408568113635216480, 2754911123734110635, 7803442666549593133, -4634972793712562883, 8209367087133481196, 1884511236955540648, 1028221524795877909, 1793451112762974566, -3069800317926219600, -4154447733093151475, -1764881790517273875, -3062382368652992149, 7899101051924671593, -1465414798442092175, -8178805512674378132, 4922079079000536327, 3001464214149873087, 975317926049332079, 3507958888550472126, 4341215603761883801, -8371196315537889667, 5542344914293687609, -8371654416824147948, -2125200814484315033, 2535829326755179420, 3380722299142400205, 4917631357290430389, -8465919059381185958, 7208844841843024141, -7377711490510421780, -7051323708419488049, -2376941230944027691, 6444432674352359495, 3145447507898625620, 2468934034052481654, -2138350587463450087, 8746793011397767024, 3431869195452360739, -8521256799073420506, -4773534418139596774, -1591534875344028098, -502218640840975605, 495548946783386062, -5714937145385214973, 7505024888952490986, -5845408711591149548, 5196123286422753064, -5081154646736344515, -4717749815064811749, -9095934944891653950, -3744575213187343768, 2528262689889801377, -3263928518536448175, 8088309802456795026, 2663302670279184884, 1625614141326335387, -4070271154636080152, 7849594456842278261]</br>[33mcassandra_1      |[0m INFO  21:49:24 Create new Keyspace: KeyspaceMetadata{name=system_traces, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=2}}, tables=[org.apache.cassandra.config.CFMetaData@3c0a695d[cfId=c5e99f16-8677-3914-b17e-960613512345,ksName=system_traces,cfName=sessions,flags=[COMPOUND],params=TableParams{comment=tracing sessions, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@de378a90, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [client command coordinator duration request started_at parameters]],partitionKeyColumns=[session_id],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UUIDType,columnMetadata=[client, command, session_id, coordinator, request, started_at, duration, parameters],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@d4177df[cfId=8826e8e9-e16a-3728-8753-3bc1fc713c25,ksName=system_traces,cfName=events,flags=[COMPOUND],params=TableParams{comment=tracing events, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@de378a90, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.TimeUUIDType),partitionColumns=[[] | [activity source source_elapsed thread]],partitionKeyColumns=[session_id],clusteringColumns=[event_id],keyValidator=org.apache.cassandra.db.marshal.UUIDType,columnMetadata=[activity, session_id, thread, event_id, source, source_elapsed],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}</br>[33mcassandra_1      |[0m INFO  21:49:25 Not submitting build tasks for views in keyspace system_traces as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:49:25 Initializing system_traces.events</br>[33mcassandra_1      |[0m INFO  21:49:25 Initializing system_traces.sessions</br>[33mcassandra_1      |[0m INFO  21:49:25 Create new Keyspace: KeyspaceMetadata{name=system_distributed, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}, tables=[org.apache.cassandra.config.CFMetaData@61bb82c[cfId=759fffad-624b-3181-80ee-fa9a52d1f627,ksName=system_distributed,cfName=repair_history,flags=[COMPOUND],params=TableParams{comment=Repair history, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@de378a90, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.TimeUUIDType),partitionColumns=[[] | [coordinator exception_message exception_stacktrace finished_at parent_id range_begin range_end started_at status participants]],partitionKeyColumns=[keyspace_name, columnfamily_name],clusteringColumns=[id],keyValidator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type),columnMetadata=[status, id, coordinator, finished_at, participants, exception_stacktrace, parent_id, range_end, range_begin, exception_message, keyspace_name, started_at, columnfamily_name],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@ede6972[cfId=deabd734-b99d-3b9c-92e5-fd92eb5abf14,ksName=system_distributed,cfName=parent_repair_history,flags=[COMPOUND],params=TableParams{comment=Repair history, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@de378a90, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [exception_message exception_stacktrace finished_at keyspace_name started_at columnfamily_names options requested_ranges successful_ranges]],partitionKeyColumns=[parent_id],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[requested_ranges, exception_message, keyspace_name, successful_ranges, started_at, finished_at, options, exception_stacktrace, parent_id, columnfamily_names],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@7da0a3c0[cfId=5582b59f-8e4e-35e1-b913-3acada51eb04,ksName=system_distributed,cfName=view_build_status,flags=[COMPOUND],params=TableParams{comment=Materialized View build status, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@de378a90, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UUIDType),partitionColumns=[[] | [status]],partitionKeyColumns=[keyspace_name, view_name],clusteringColumns=[host_id],keyValidator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type),columnMetadata=[status, keyspace_name, view_name, host_id],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}</br>[33mcassandra_1      |[0m INFO  21:49:25 Not submitting build tasks for views in keyspace system_distributed as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:49:25 Initializing system_distributed.parent_repair_history</br>[33mcassandra_1      |[0m INFO  21:49:25 Initializing system_distributed.repair_history</br>[33mcassandra_1      |[0m INFO  21:49:25 Initializing system_distributed.view_build_status</br>[33mcassandra_1      |[0m INFO  21:49:26 Node /172.19.0.2 state jump to NORMAL</br>[33mcassandra_1      |[0m INFO  21:49:26 Create new Keyspace: KeyspaceMetadata{name=system_auth, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[org.apache.cassandra.config.CFMetaData@18789e16[cfId=5bc52802-de25-35ed-aeab-188eecebb090,ksName=system_auth,cfName=roles,flags=[COMPOUND],params=TableParams{comment=role definitions, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@de378a90, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [can_login is_superuser salted_hash member_of]],partitionKeyColumns=[role],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[role, salted_hash, member_of, can_login, is_superuser],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@44f95a86[cfId=0ecdaa87-f8fb-3e60-88d1-74fb36fe5c0d,ksName=system_auth,cfName=role_members,flags=[COMPOUND],params=TableParams{comment=role memberships lookup table, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@de378a90, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | []],partitionKeyColumns=[role],clusteringColumns=[member],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[role, member],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@43f6dbae[cfId=3afbe79f-2194-31a7-add7-f5ab90d8ec9c,ksName=system_auth,cfName=role_permissions,flags=[COMPOUND],params=TableParams{comment=permissions granted to db roles, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@de378a90, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [permissions]],partitionKeyColumns=[role],clusteringColumns=[resource],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[resource, role, permissions],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@2eef55fd[cfId=5f2fbdad-91f1-3946-bd25-d5da3a5c35ec,ksName=system_auth,cfName=resource_role_permissons_index,flags=[COMPOUND],params=TableParams{comment=index of db roles with permissions granted on a resource, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@de378a90, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | []],partitionKeyColumns=[resource],clusteringColumns=[role],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[resource, role],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}</br>[33mcassandra_1      |[0m INFO  21:49:26 Not submitting build tasks for views in keyspace system_auth as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:49:26 Initializing system_auth.resource_role_permissons_index</br>[33mcassandra_1      |[0m INFO  21:49:26 Initializing system_auth.role_members</br>[33mcassandra_1      |[0m INFO  21:49:26 Initializing system_auth.role_permissions</br>[33mcassandra_1      |[0m INFO  21:49:26 Initializing system_auth.roles</br>[33mcassandra_1      |[0m INFO  21:49:26 (Re)initializing CredentialsCache (validity period/update interval/max entries) (2000/2000/1000)</br>[33mcassandra_1      |[0m INFO  21:49:26 Waiting for gossip to settle before accepting client requests...</br>[33mcassandra_1      |[0m INFO  21:49:34 No gossip backlog; proceeding</br>[33mcassandra_1      |[0m INFO  21:49:34 Netty using native Epoll event loop</br>[33mcassandra_1      |[0m INFO  21:49:34 Using Netty Version: [netty-buffer=netty-buffer-4.0.39.Final.38bdf86, netty-codec=netty-codec-4.0.39.Final.38bdf86, netty-codec-haproxy=netty-codec-haproxy-4.0.39.Final.38bdf86, netty-codec-http=netty-codec-http-4.0.39.Final.38bdf86, netty-codec-socks=netty-codec-socks-4.0.39.Final.38bdf86, netty-common=netty-common-4.0.39.Final.38bdf86, netty-handler=netty-handler-4.0.39.Final.38bdf86, netty-tcnative=netty-tcnative-1.1.33.Fork19.fe4816e, netty-transport=netty-transport-4.0.39.Final.38bdf86, netty-transport-native-epoll=netty-transport-native-epoll-4.0.39.Final.38bdf86, netty-transport-rxtx=netty-transport-rxtx-4.0.39.Final.38bdf86, netty-transport-sctp=netty-transport-sctp-4.0.39.Final.38bdf86, netty-transport-udt=netty-transport-udt-4.0.39.Final.38bdf86]</br>[33mcassandra_1      |[0m INFO  21:49:34 Starting listening for CQL clients on /0.0.0.0:9042 (unencrypted)...</br>[33mcassandra_1      |[0m INFO  21:49:34 Not starting RPC server as requested. Use JMX (StorageService-&gt;startRPCServer()) or nodetool (enablethrift) to start it</br>[33mcassandra_1      |[0m INFO  21:49:36 Scheduling approximate time-check task with a precision of 10 milliseconds</br>[33mcassandra_1      |[0m INFO  21:49:36 Created default superuser role &#39;cassandra&#39;</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 4 out of 4
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        5.44 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header green">
                    <div class="cell">
                        Setup Cassandra Source Connector
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Create Source Topic
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.35
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</br>  kafka-topics --zookeeper fast-data-dev:2181 --topic cassandra-source --partition 1 --replication 1 --create</br></br>'>docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev
  kafka-topics --zookeeper fast-data-dev:2181 --topic cassandra-source --partition 1 --replication 1 --create

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                        Created topic &#34;cassandra-source&#34;.
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Create Cassandra Source Table and Data
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.36
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra</br>  cqlsh -u cassandra -p cassandra cassandra</br></br>'>docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra
  cqlsh -u cassandra -p cassandra cassandra

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_1_1" class="trigger" data-tooltip-id="1_1" title=" id | created                              | price | product                 | qty</br>----+--------------------------------------+-------+-------------------------+-----</br>  1 | dc6b10a0-90c5-11e6-9e12-9b89c16b65a4 |  94.2 |  OP-DAX-P-20150201-95.7 | 100</br>  2 | dc6bace0-90c5-11e6-9e12-9b89c16b65a4 |  99.5 |   OP-DAX-C-20150201-100 | 100</br>  3 | dc6c2210-90c5-11e6-9e12-9b89c16b65a4 |   150 | FU-KOSPI-C-20150201-100 | 200</br></br>(3 rows)</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Create a Cassandra Source Distributed Connector
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.53
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev</br>  curl -vs --stderr - -X POST -H &#34;Content-Type: application/json&#34;</br>       --data @-</br>       &#34;http://fast-data-dev:8083/connectors&#34;</br></br>'>docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev
  curl -vs --stderr - -X POST -H &#34;Content-Type: application/json&#34;
       --data @-
       &#34;http://fast-data-dev:8083/connectors&#34;

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_1_2" class="trigger" data-tooltip-id="1_2" title="*   Trying 172.19.0.3...</br>* TCP_NODELAY set</br>* Connected to fast-data-dev (172.19.0.3) port 8083 (#0)</br>&gt; POST /connectors HTTP/1.1</br>&gt; Host: fast-data-dev:8083</br>&gt; User-Agent: curl/7.50.3</br>&gt; Accept: */*</br>&gt; Content-Type: application/json</br>&gt; Content-Length: 522</br>&gt; </br>} [522 bytes data]</br>* upload completely sent off: 522 out of 522 bytes</br>&lt; HTTP/1.1 201 Created</br>&lt; Date: Wed, 12 Oct 2016 21:50:17 GMT</br>&lt; Location: http://fast-data-dev:8083/connectors/cassandra-source</br>&lt; Content-Type: application/json</br>&lt; Content-Length: 511</br>&lt; Server: Jetty(9.2.12.v20150709)</br>&lt; </br>{ [511 bytes data]</br>{&#34;name&#34;:&#34;cassandra-source&#34;,&#34;config&#34;:{&#34;connector.class&#34;:&#34;com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector&#34;,&#34;tasks.max&#34;:&#34;1&#34;,&#34;connect.cassandra.key.space&#34;:&#34;source&#34;,&#34;connect.cassandra.import.route.query&#34;:&#34;INSERT INTO cassandra-source SELECT * FROM orders PK created&#34;,&#34;connect.cassandra.import.mode&#34;:&#34;incremental&#34;,&#34;connect.cassandra.contact.points&#34;:&#34;cassandra&#34;,&#34;connect.cassandra.username&#34;:&#34;cassandra&#34;,&#34;connect.cassandra.password&#34;:&#34;cassandra&#34;,&#34;name&#34;:&#34;cassandra-source&#34;},&#34;tasks&#34;:[]}* Curl_http_done: called premature == 0</br>* Connection #0 to host fast-data-dev left intact</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 3 out of 3
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        6.24 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header blue">
                    <div class="cell">
                        Setup Cassandra Sink Connector
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Create Sink Topic
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        3.43
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</br>  kafka-topics --zookeeper fast-data-dev:2181 --topic cassandra-sink --partition 1 --replication 1 --create</br></br>'>docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev
  kafka-topics --zookeeper fast-data-dev:2181 --topic cassandra-sink --partition 1 --replication 1 --create

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                        Created topic &#34;cassandra-sink&#34;.
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Create Cassandra Sink Table
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.21
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra</br>  cqlsh -u cassandra -p cassandra cassandra</br></br>'>docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra
  cqlsh -u cassandra -p cassandra cassandra

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Create a Cassandra Sink Distributed Connector
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.16
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev</br>  curl -vs --stderr - -X POST -H &#34;Content-Type: application/json&#34;</br>       --data @-</br>       &#34;http://fast-data-dev:8083/connectors&#34;</br></br>'>docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev
  curl -vs --stderr - -X POST -H &#34;Content-Type: application/json&#34;
       --data @-
       &#34;http://fast-data-dev:8083/connectors&#34;

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_2_2" class="trigger" data-tooltip-id="2_2" title="*   Trying 172.19.0.3...</br>* TCP_NODELAY set</br>* Connected to fast-data-dev (172.19.0.3) port 8083 (#0)</br>&gt; POST /connectors HTTP/1.1</br>&gt; Host: fast-data-dev:8083</br>&gt; User-Agent: curl/7.50.3</br>&gt; Accept: */*</br>&gt; Content-Type: application/json</br>&gt; Content-Length: 481</br>&gt; </br>} [481 bytes data]</br>* upload completely sent off: 481 out of 481 bytes</br>&lt; HTTP/1.1 201 Created</br>&lt; Date: Wed, 12 Oct 2016 21:50:24 GMT</br>&lt; Location: http://fast-data-dev:8083/connectors/cassandra-sink</br>&lt; Content-Type: application/json</br>&lt; Content-Length: 468</br>&lt; Server: Jetty(9.2.12.v20150709)</br>&lt; </br>{ [468 bytes data]</br>{&#34;name&#34;:&#34;cassandra-sink&#34;,&#34;config&#34;:{&#34;connector.class&#34;:&#34;com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector&#34;,&#34;tasks.max&#34;:&#34;1&#34;,&#34;topics&#34;:&#34;cassandra-sink&#34;,&#34;connect.cassandra.key.space&#34;:&#34;sink&#34;,&#34;connect.cassandra.export.route.query&#34;:&#34;INSERT INTO orders SELECT * FROM cassandra-sink&#34;,&#34;connect.cassandra.contact.points&#34;:&#34;cassandra&#34;,&#34;connect.cassandra.username&#34;:&#34;cassandra&#34;,&#34;connect.cassandra.password&#34;:&#34;cassandra&#34;,&#34;name&#34;:&#34;cassandra-sink&#34;},&#34;tasks&#34;:[]}* Curl_http_done: called premature == 0</br>* Connection #0 to host fast-data-dev left intact</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 3 out of 3
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        6.81 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header purple">
                    <div class="cell">
                        Test Cassandra Source Connector
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Read Entries from Topic
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        20.80
                    </div>
                    <div class="cell">
                        (ignore) 124
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='timeout 20 docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</br>  kafka-avro-console-consumer --zookeeper fast-data-dev:2181/confluent</br>                              --bootstrap-server fast-data-dev:9092</br>                              --topic cassandra-source --from-beginning --new-consumer</br>                              --property schema.registry.url=http://fast-data-dev:8081</br></br>'>timeout 20 docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        timeout 20 docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev
  kafka-avro-console-consumer --zookeeper fast-data-dev:2181/confluent
                              --bootstrap-server fast-data-dev:9092
                              --topic cassandra-source --from-beginning --new-consumer
                              --property schema.registry.url=http://fast-data-dev:8081

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_3_0" class="trigger" data-tooltip-id="3_0" title="{&#34;id&#34;:{&#34;int&#34;:1},&#34;created&#34;:{&#34;string&#34;:&#34;dc6b10a0-90c5-11e6-9e12-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:94.2},&#34;product&#34;:{&#34;string&#34;:&#34;OP-DAX-P-20150201-95.7&#34;},&#34;qty&#34;:{&#34;int&#34;:100}}</br>{&#34;id&#34;:{&#34;int&#34;:2},&#34;created&#34;:{&#34;string&#34;:&#34;dc6bace0-90c5-11e6-9e12-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:99.5},&#34;product&#34;:{&#34;string&#34;:&#34;OP-DAX-C-20150201-100&#34;},&#34;qty&#34;:{&#34;int&#34;:100}}</br>{&#34;id&#34;:{&#34;int&#34;:3},&#34;created&#34;:{&#34;string&#34;:&#34;dc6c2210-90c5-11e6-9e12-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:150.0},&#34;product&#34;:{&#34;string&#34;:&#34;FU-KOSPI-C-20150201-100&#34;},&#34;qty&#34;:{&#34;int&#34;:200}}</br>{&#34;id&#34;:{&#34;int&#34;:1},&#34;created&#34;:{&#34;string&#34;:&#34;dc6b10a0-90c5-11e6-9e12-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:94.2},&#34;product&#34;:{&#34;string&#34;:&#34;OP-DAX-P-20150201-95.7&#34;},&#34;qty&#34;:{&#34;int&#34;:100}}</br>{&#34;id&#34;:{&#34;int&#34;:2},&#34;created&#34;:{&#34;string&#34;:&#34;dc6bace0-90c5-11e6-9e12-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:99.5},&#34;product&#34;:{&#34;string&#34;:&#34;OP-DAX-C-20150201-100&#34;},&#34;qty&#34;:{&#34;int&#34;:100}}</br>{&#34;id&#34;:{&#34;int&#34;:3},&#34;created&#34;:{&#34;string&#34;:&#34;dc6c2210-90c5-11e6-9e12-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:150.0},&#34;product&#34;:{&#34;string&#34;:&#34;FU-KOSPI-C-20150201-100&#34;},&#34;qty&#34;:{&#34;int&#34;:200}}</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_3_0" class="trigger" data-tooltip-id="3_0" title="SLF4J: Class path contains multiple SLF4J bindings.</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-serde-tools/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/schema-registry/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</br>SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]</br>Processed a total of 6 messages</br></br>">view</button>
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 1 out of 1
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        20.80 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header gray">
                    <div class="cell">
                        Test Cassandra Sink Connector
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Write Entries into Topic
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.93
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm -i --network=kafkaconnectcassandra_default landoop/fast-data-dev</br>  kafka-avro-console-producer --broker-list fast-data-dev:9092</br>    --topic cassandra-sink --property schema.registry.url=&#34;http://fast-data-dev:8081&#34;</br>    --property</br>    value.schema=&#39;{&#34;type&#34;:&#34;record&#34;,&#34;name&#34;:&#34;myrecord&#34;,&#34;fields&#34;:[{&#34;name&#34;:&#34;id&#34;,&#34;type&#34;:&#34;int&#34;},{&#34;name&#34;:&#34;created&#34;, &#34;type&#34;: &#34;string&#34;}, {&#34;name&#34;:&#34;product&#34;, &#34;type&#34;: &#34;string&#34;}, {&#34;name&#34;:&#34;price&#34;, &#34;type&#34;: &#34;double&#34;}]}&#39;</br></br>'>docker run --rm -i --network=kafkaconnectcassandra_default landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm -i --network=kafkaconnectcassandra_default landoop/fast-data-dev
  kafka-avro-console-producer --broker-list fast-data-dev:9092
    --topic cassandra-sink --property schema.registry.url=&#34;http://fast-data-dev:8081&#34;
    --property
    value.schema=&#39;{&#34;type&#34;:&#34;record&#34;,&#34;name&#34;:&#34;myrecord&#34;,&#34;fields&#34;:[{&#34;name&#34;:&#34;id&#34;,&#34;type&#34;:&#34;int&#34;},{&#34;name&#34;:&#34;created&#34;, &#34;type&#34;: &#34;string&#34;}, {&#34;name&#34;:&#34;product&#34;, &#34;type&#34;: &#34;string&#34;}, {&#34;name&#34;:&#34;price&#34;, &#34;type&#34;: &#34;double&#34;}]}&#39;

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_4_0" class="trigger" data-tooltip-id="4_0" title="SLF4J: Class path contains multiple SLF4J bindings.</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-serde-tools/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/schema-registry/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</br>SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]</br></br>">view</button>
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Verify entries
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.24
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm -i --network=kafkaconnectcassandra_default landoop/cassandra</br>  cqlsh -u cassandra -p cassandra cassandra</br></br>'>docker run --rm -i --network=kafkaconnectcassandra_default landoop/cassandra</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm -i --network=kafkaconnectcassandra_default landoop/cassandra
  cqlsh -u cassandra -p cassandra cassandra

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_4_1" class="trigger" data-tooltip-id="4_1" title=" id | created             | price | product                         | qty</br>----+---------------------+-------+---------------------------------+------</br>  1 | 2016-05-06 13:53:00 |  94.2 |          OP-DAX-P-20150201-95.7 | null</br>  2 | 2016-05-06 13:54:00 |  99.5 |           OP-DAX-C-20150201-100 | null</br>  4 | 2016-05-06 13:56:00 |   150 |         FU-KOSPI-C-20150201-100 | null</br>  3 | 2016-05-06 13:55:00 | 10000 | FU-DATAMOUNTAINEER-20150201-100 | null</br></br>(4 rows)</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 2 out of 2
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        5.17 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header yellow">
                    <div class="cell">
                        Other Tests
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Read First 2000 Lines of Connect Logs
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        0.05
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker exec kafkaconnectcassandra_fast-data-dev_1 head -n2000 /var/log/connect-distributed.log</br></br>'>docker exec kafkaconnectcassandra_fast-data-dev_1 head -n2000 /var/log/connect-distributed.log</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker exec kafkaconnectcassandra_fast-data-dev_1 head -n2000 /var/log/connect-distributed.log

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_5_0" class="trigger" data-tooltip-id="5_0" title="SLF4J: Class path contains multiple SLF4J bindings.</br>SLF4J: Found binding in [jar:file:/extra-connect-jars/kafka-connect-twitter-0.1-develop-8624fbe-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-serde-tools/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-blockchain/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-bloomberg/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-cassandra/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-druid/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-elastic/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-hazelcast/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-hbase/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-hdfs/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-influxdb/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-jms/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-kudu/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-redis/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-rethink/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-voltdb/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-yahoo/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</br>[main] INFO org.apache.kafka.connect.runtime.distributed.DistributedConfig - DistributedConfig values: </br>	cluster = connect</br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	offset.storage.topic = connect-offsets</br>	ssl.truststore.password = null</br>	key.converter = class io.confluent.connect.avro.AvroConverter</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	config.storage.topic = connect-configs</br>	request.timeout.ms = 40000</br>	rest.advertised.host.name = null</br>	heartbeat.interval.ms = 3000</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	rest.port = 8083</br>	access.control.allow.origin = </br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	worker.unsync.backoff.ms = 300000</br>	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter</br>	send.buffer.bytes = 131072</br>	group.id = connect-cluster</br>	task.shutdown.graceful.timeout.ms = 5000</br>	rest.advertised.port = null</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	value.converter = class io.confluent.connect.avro.AvroConverter</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	worker.sync.timeout.ms = 3000</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	status.storage.topic = connect-statuses</br>	rest.host.name = null</br>	ssl.keystore.location = null</br>	offset.flush.timeout.ms = 5000</br>	ssl.cipher.suites = null</br>	offset.flush.interval.ms = 60000</br>	security.protocol = PLAINTEXT</br>	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter</br>	access.control.allow.methods = </br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br></br>[main] INFO org.eclipse.jetty.util.log - Logging initialized @7975ms</br>[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[main] INFO org.apache.kafka.connect.runtime.Connect - Kafka Connect starting</br>[main] INFO org.apache.kafka.connect.runtime.rest.RestServer - Starting REST server</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Herder starting</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Worker starting</br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 9223372036854775807</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 2147483647</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 9223372036854775807</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = producer-1</br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 2147483647</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.connect.storage.KafkaOffsetBackingStore - Starting KafkaOffsetBackingStore</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Starting KafkaBasedLog with topic connect-offsets</br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = producer-2</br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration group.id = connect-cluster was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = consumer-1</br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[main] INFO org.eclipse.jetty.server.Server - jetty-9.2.12.v20150709</br>[2016-10-12 21:49:25,313] INFO HV000001: Hibernate Validator 5.1.2.Final (org.hibernate.validator.internal.util.Version:27)</br>Oct 12, 2016 9:49:25 PM org.glassfish.jersey.internal.Errors logErrors</br>WARNING: The following warnings have been detected: WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.</br>WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.</br>WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.</br>WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.</br></br>[main] INFO org.eclipse.jetty.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@260ff5b7{/,null,AVAILABLE}</br>[main] INFO org.eclipse.jetty.server.ServerConnector - Started ServerConnector@4d8286c4{HTTP/1.1}{0.0.0.0:8083}</br>[main] INFO org.eclipse.jetty.server.Server - Started @12977ms</br>[main] INFO org.apache.kafka.connect.runtime.rest.RestServer - REST server listening at http://172.19.0.3:8083/, advertising URL http://172.19.0.3:8083/</br>[main] INFO org.apache.kafka.connect.runtime.Connect - Kafka Connect started</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Finished reading KafkaBasedLog for topic connect-offsets</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Started KafkaBasedLog for topic connect-offsets</br>[DistributedHerder] INFO org.apache.kafka.connect.storage.KafkaOffsetBackingStore - Finished reading offsets topic and starting KafkaOffsetBackingStore</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Worker started</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Starting KafkaBasedLog with topic connect-statuses</br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 0</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.StringSerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = producer-3</br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 0</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.StringSerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration group.id = connect-cluster was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = consumer-2</br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Finished reading KafkaBasedLog for topic connect-statuses</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Started KafkaBasedLog for topic connect-statuses</br>[DistributedHerder] INFO org.apache.kafka.connect.storage.KafkaConfigBackingStore - Starting KafkaConfigBackingStore</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Starting KafkaBasedLog with topic connect-configs</br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.StringSerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = producer-4</br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.StringSerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration group.id = connect-cluster was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = consumer-3</br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Finished reading KafkaBasedLog for topic connect-configs</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Started KafkaBasedLog for topic connect-configs</br>[DistributedHerder] INFO org.apache.kafka.connect.storage.KafkaConfigBackingStore - Started KafkaConfigBackingStore</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Herder started</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 1</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-1a17a077-5913-4da9-bf5e-120dd036519f&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=-1, connectorIds=[], taskIds=[]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset -1</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[CLASSPATH traversal thread.] INFO org.reflections.Reflections - Reflections took 48856 ms to scan 1732 urls, producing 24325 keys and 198556 values </br>[KafkaBasedLog Work Thread - connect-configs] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Connector cassandra-source config updated</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Rebalance started</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished stopping tasks in preparation for rebalance</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 2</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-1a17a077-5913-4da9-bf5e-120dd036519f&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=1, connectorIds=[cassandra-source], taskIds=[]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset 1</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-source of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[qtp970865974-33] INFO org.apache.kafka.connect.runtime.rest.RestServer - 172.19.0.4 - - [12/Oct/2016:21:50:17 +0000] &#34;POST /connectors HTTP/1.1&#34; 201 511  844</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-source with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Starting Cassandra source task with {connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.import.mode=incremental, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.username=cassandra}.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Setting task configurations for 1 workers.</br>[KafkaBasedLog Work Thread - connect-configs] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Tasks [cassandra-source-0] configs updated</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Rebalance started</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopped connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished stopping tasks in preparation for rebalance</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 3</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-1a17a077-5913-4da9-bf5e-120dd036519f&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=3, connectorIds=[cassandra-source], taskIds=[cassandra-source-0]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset 3</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-source of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-source with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Starting Cassandra source task with {connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.import.mode=incremental, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.username=cassandra}.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Setting task configurations for 1 workers.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.TaskConfig - TaskConfig values: </br>	task.class = class com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated task cassandra-source-0 with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSource - CassandraConfigSource values: </br>	connect.cassandra.import.mode = incremental</br>	connect.cassandra.key.space = source</br>	connect.cassandra.import.source.allow.filtering = true</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.import.route.query = INSERT INTO cassandra-source SELECT * FROM orders PK created</br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.import.poll.interval = 60000</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.source.task.batch.size = 100</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.source.task.buffer.size = 10000</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.assigned.tables = orders</br>	connect.cassandra.max.retires = 20</br></br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - </br></br>    ____        __        __  ___                  __        _</br>   / __ \____ _/ /_____ _/  |/  /___  __  ______  / /_____ _(_)___  ___  ___  _____</br>  / / / / __ `/ __/ __ `/ /|_/ / __ \/ / / / __ \/ __/ __ `/ / __ \/ _ \/ _ \/ ___/</br> / /_/ / /_/ / /_/ /_/ / /  / / /_/ / /_/ / / / / /_/ /_/ / / / / /  __/  __/ /</br>/_____/\__,_/\__/\__,_/_/  /_/\____/\__,_/_/ /_/\__/\__,_/_/_/ /_/\___/\___/_/</br>       ______                                __           _____</br>      / ____/___ _______________ _____  ____/ /________ _/ ___/____  __  _______________</br>     / /   / __ `/ ___/ ___/ __ `/ __ \/ __  / ___/ __ `/\__ \/ __ \/ / / / ___/ ___/ _ \</br>    / /___/ /_/ (__  |__  ) /_/ / / / / /_/ / /  / /_/ /___/ / /_/ / /_/ / /  / /__/  __/</br>    \____/\__,_/____/____/\__,_/_/ /_/\__,_/_/   \__,_//____/\____/\__,_/_/   \___/\___/</br></br> By Andrew Stevenson.</br>[pool-1-thread-1] INFO com.datastax.driver.core.NettyUtil - Found Netty&#39;s native epoll transport in the classpath, using it</br>[pool-1-thread-1] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name &#39;datacenter1&#39; for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)</br>[pool-1-thread-1] INFO com.datastax.driver.core.Cluster - New Cassandra host cassandra/172.19.0.2:9042 added</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Connection to Cassandra established.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Received setting:</br> CassandraSourceSetting(com.datamountaineer.connector.config.Config@68e780e7,source,false,Some(created),60000,CassandraConfigSource({connect.cassandra.import.mode=incremental, connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, task.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.assigned.tables=orders, connect.cassandra.username=cassandra}),ThrowErrorPolicy(),20)</br>[pool-1-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Source task WorkerSourceTask{id=cassandra-source-0} finished initialization and start</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Query SELECT * FROM source.orders WHERE created &gt; maxTimeuuid(?) AND created &lt;= minTimeuuid(?)  ALLOW FILTERING executing with bindings (1900-01-01 00:00:00.000Z, 2016-10-12 21:50:20.818Z).</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying returning results for source.orders.</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:50:16.234Z</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:50:16.238Z</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:50:16.241Z</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Processed 3 rows for table cassandra-source.orders</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.queues.QueueHelpers$ - Found 3. Draining entries to batchSize 100.</br>[KafkaBasedLog Work Thread - connect-configs] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Connector cassandra-sink config updated</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Rebalance started</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopped connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping task cassandra-source-0</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Stopping Cassandra source.</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Shutting down Queries.</br>[qtp970865974-44] INFO org.apache.kafka.connect.runtime.rest.RestServer - 172.19.0.4 - - [12/Oct/2016:21:50:24 +0000] &#34;POST /connectors HTTP/1.1&#34; 201 468  519</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying stopped for source.cassandra-source.</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - All stopped.</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Shutting down Cassandra driver connections.</br>[pool-1-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Finished WorkerSourceTask{id=cassandra-source-0} commitOffsets successfully in 2270 ms</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished stopping tasks in preparation for rebalance</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 4</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-1a17a077-5913-4da9-bf5e-120dd036519f&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=4, connectorIds=[cassandra-source, cassandra-sink], taskIds=[cassandra-source-0]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset 4</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-source of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-source with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Starting Cassandra source task with {connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.import.mode=incremental, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.username=cassandra}.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Setting task configurations for 1 workers.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>	tasks.max = 1</br>	name = cassandra-sink</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-sink of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-sink with version 1 of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSink - CassandraConfigSink values: </br>	connect.cassandra.key.space = sink</br>	connect.cassandra.export.route.query = INSERT INTO orders SELECT * FROM cassandra-sink</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.max.retires = 20</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>	tasks.max = 1</br>	name = cassandra-sink</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector - Setting task configurations for 1 workers.</br>[KafkaBasedLog Work Thread - connect-configs] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Tasks [cassandra-source-0, cassandra-sink-0] configs updated</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.TaskConfig - TaskConfig values: </br>	task.class = class com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated task cassandra-source-0 with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Rebalance started</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopped connector cassandra-source</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSource - CassandraConfigSource values: </br>	connect.cassandra.import.mode = incremental</br>	connect.cassandra.key.space = source</br>	connect.cassandra.import.source.allow.filtering = true</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.import.route.query = INSERT INTO cassandra-source SELECT * FROM orders PK created</br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.import.poll.interval = 60000</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.source.task.batch.size = 100</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.source.task.buffer.size = 10000</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.assigned.tables = orders</br>	connect.cassandra.max.retires = 20</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopped connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping task cassandra-source-0</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - </br></br>    ____        __        __  ___                  __        _</br>   / __ \____ _/ /_____ _/  |/  /___  __  ______  / /_____ _(_)___  ___  ___  _____</br>  / / / / __ `/ __/ __ `/ /|_/ / __ \/ / / / __ \/ __/ __ `/ / __ \/ _ \/ _ \/ ___/</br> / /_/ / /_/ / /_/ /_/ / /  / / /_/ / /_/ / / / / /_/ /_/ / / / / /  __/  __/ /</br>/_____/\__,_/\__/\__,_/_/  /_/\____/\__,_/_/ /_/\__/\__,_/_/_/ /_/\___/\___/_/</br>       ______                                __           _____</br>      / ____/___ _______________ _____  ____/ /________ _/ ___/____  __  _______________</br>     / /   / __ `/ ___/ ___/ __ `/ __ \/ __  / ___/ __ `/\__ \/ __ \/ / / / ___/ ___/ _ \</br>    / /___/ /_/ (__  |__  ) /_/ / / / / /_/ / /  / /_/ /___/ / /_/ / /_/ / /  / /__/  __/</br>    \____/\__,_/____/____/\__,_/_/ /_/\__,_/_/   \__,_//____/\____/\__,_/_/   \___/\___/</br></br> By Andrew Stevenson.</br>[pool-1-thread-1] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name &#39;datacenter1&#39; for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)</br>[pool-1-thread-1] INFO com.datastax.driver.core.Cluster - New Cassandra host cassandra/172.19.0.2:9042 added</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Connection to Cassandra established.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Received setting:</br> CassandraSourceSetting(com.datamountaineer.connector.config.Config@15ab6f80,source,false,Some(created),60000,CassandraConfigSource({connect.cassandra.import.mode=incremental, connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, task.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.assigned.tables=orders, connect.cassandra.username=cassandra}),ThrowErrorPolicy(),20)</br>[pool-1-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Source task WorkerSourceTask{id=cassandra-source-0} finished initialization and start</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Stopping Cassandra source.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Shutting down Queries.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying stopped for source.cassandra-source.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - All stopped.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Shutting down Cassandra driver connections.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished stopping tasks in preparation for rebalance</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 5</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-1a17a077-5913-4da9-bf5e-120dd036519f&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=6, connectorIds=[cassandra-source, cassandra-sink], taskIds=[cassandra-source-0, cassandra-sink-0]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset 6</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-source of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-source with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Starting Cassandra source task with {connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.import.mode=incremental, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.username=cassandra}.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Setting task configurations for 1 workers.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>	tasks.max = 1</br>	name = cassandra-sink</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-sink of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-sink with version 1 of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSink - CassandraConfigSink values: </br>	connect.cassandra.key.space = sink</br>	connect.cassandra.export.route.query = INSERT INTO orders SELECT * FROM cassandra-sink</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.max.retires = 20</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>	tasks.max = 1</br>	name = cassandra-sink</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector - Setting task configurations for 1 workers.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.TaskConfig - TaskConfig values: </br>	task.class = class com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated task cassandra-source-0 with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting task cassandra-sink-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.TaskConfig - TaskConfig values: </br>	task.class = class com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkTask</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating task cassandra-sink-0</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSource - CassandraConfigSource values: </br>	connect.cassandra.import.mode = incremental</br>	connect.cassandra.key.space = source</br>	connect.cassandra.import.source.allow.filtering = true</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.import.route.query = INSERT INTO cassandra-source SELECT * FROM orders PK created</br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.import.poll.interval = 60000</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.source.task.batch.size = 100</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.source.task.buffer.size = 10000</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.assigned.tables = orders</br>	connect.cassandra.max.retires = 20</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkTask - Task initialising</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated task cassandra-sink-0 with version 1 of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkTask</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - </br></br>    ____        __        __  ___                  __        _</br>   / __ \____ _/ /_____ _/  |/  /___  __  ______  / /_____ _(_)___  ___  ___  _____</br>  / / / / __ `/ __/ __ `/ /|_/ / __ \/ / / / __ \/ __/ __ `/ / __ \/ _ \/ _ \/ ___/</br> / /_/ / /_/ / /_/ /_/ / /  / / /_/ / /_/ / / / / /_/ /_/ / / / / /  __/  __/ /</br>/_____/\__,_/\__/\__,_/_/  /_/\____/\__,_/_/ /_/\__/\__,_/_/_/ /_/\___/\___/_/</br>       ______                                __           _____</br>      / ____/___ _______________ _____  ____/ /________ _/ ___/____  __  _______________</br>     / /   / __ `/ ___/ ___/ __ `/ __ \/ __  / ___/ __ `/\__ \/ __ \/ / / / ___/ ___/ _ \</br>    / /___/ /_/ (__  |__  ) /_/ / / / / /_/ / /  / /_/ /___/ / /_/ / /_/ / /  / /__/  __/</br>    \____/\__,_/____/____/\__,_/_/ /_/\__,_/_/   \__,_//____/\____/\__,_/_/   \___/\___/</br></br> By Andrew Stevenson.</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cassandra-sink</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = consumer-4</br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cassandra-sink</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSink - CassandraConfigSink values: </br>	connect.cassandra.key.space = sink</br>	connect.cassandra.export.route.query = INSERT INTO orders SELECT * FROM cassandra-sink</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.max.retires = 20</br></br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkTask - </br>    ____        __        __  ___                  __        _</br>   / __ \____ _/ /_____ _/  |/  /___  __  ______  / /_____ _(_)___  ___  ___  _____</br>  / / / / __ `/ __/ __ `/ /|_/ / __ \/ / / / __ \/ __/ __ `/ / __ \/ _ \/ _ \/ ___/</br> / /_/ / /_/ / /_/ /_/ / /  / / /_/ / /_/ / / / / /_/ /_/ / / / / /  __/  __/ /</br>/_____/\__,_/\__/\__,_/_/  /_/\____/\__,_/_/ /_/\__/\__,_/_/_/ /_/\___/\___/_/</br>       ______                                __           _____ _       __</br>      / ____/___ _______________ _____  ____/ /________ _/ ___/(_)___  / /__</br>     / /   / __ `/ ___/ ___/ __ `/ __ \/ __  / ___/ __ `/\__ \/ / __ \/ //_/</br>    / /___/ /_/ (__  |__  ) /_/ / / / / /_/ / /  / /_/ /___/ / / / / / ,&lt;</br>    \____/\__,_/____/____/\__,_/_/ /_/\__,_/_/   \__,_//____/_/_/ /_/_/|_|</br></br> By Andrew Stevenson.</br>[pool-1-thread-1] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name &#39;datacenter1&#39; for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)</br>[pool-1-thread-1] INFO com.datastax.driver.core.Cluster - New Cassandra host cassandra/172.19.0.2:9042 added</br>[pool-1-thread-2] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name &#39;datacenter1&#39; for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)</br>[pool-1-thread-2] INFO com.datastax.driver.core.Cluster - New Cassandra host cassandra/172.19.0.2:9042 added</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Connection to Cassandra established.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Received setting:</br> CassandraSourceSetting(com.datamountaineer.connector.config.Config@356a365b,source,false,Some(created),60000,CassandraConfigSource({connect.cassandra.import.mode=incremental, connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, task.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.assigned.tables=orders, connect.cassandra.username=cassandra}),ThrowErrorPolicy(),20)</br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraJsonWriter - Initialising Cassandra writer.</br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraJsonWriter - Preparing statements for cassandra-sink.</br>[pool-1-thread-2] INFO org.apache.kafka.connect.runtime.WorkerSinkTask - Sink task WorkerSinkTask{id=cassandra-sink-0} finished initialization and start</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cassandra-sink.</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group connect-cassandra-sink</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cassandra-sink</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cassandra-sink with generation 1</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [cassandra-sink-0] for group connect-cassandra-sink</br>[pool-1-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Source task WorkerSourceTask{id=cassandra-source-0} finished initialization and start</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Query SELECT * FROM source.orders WHERE created &gt; maxTimeuuid(?) AND created &lt;= minTimeuuid(?)  ALLOW FILTERING executing with bindings (1900-01-01 00:00:00.000Z, 2016-10-12 21:50:32.154Z).</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying returning results for source.orders.</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:50:16.234Z</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.queues.QueueHelpers$ - Found 1. Draining entries to batchSize 100.</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:50:16.238Z</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:50:16.241Z</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Processed 3 rows for table cassandra-source.orders</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.queues.QueueHelpers$ - Found 2. Draining entries to batchSize 100.</br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraJsonWriter - Received 4 records.</br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraJsonWriter - Processed 4 records.</br>[pool-4-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Finished WorkerSourceTask{id=cassandra-source-0} commitOffsets successfully in 5 ms</br>[pool-1-thread-2] INFO org.apache.kafka.connect.runtime.WorkerSinkTask - WorkerSinkTask{id=cassandra-sink-0} Committing offsets</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Query SELECT * FROM source.orders WHERE created &gt; maxTimeuuid(?) AND created &lt;= minTimeuuid(?)  ALLOW FILTERING executing with bindings (2016-10-12 21:50:16.241Z, 2016-10-12 21:51:32.155Z).</br>[ForkJoinPool-1-worker-63] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying returning results for source.orders.</br>[ForkJoinPool-1-worker-63] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Processed 0 rows for table cassandra-source.orders</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 1 out of 1
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        0.05 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header orange">
                    <div class="cell">
                        Clean-up Containers
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Docker Compose Down
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        12.29
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose down</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose down
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_6_0" class="trigger" data-tooltip-id="6_0" title="Stopping kafkaconnectcassandra_fast-data-dev_1 ... </br>Stopping kafkaconnectcassandra_cassandra_1 ... </br>[2A[2KStopping kafkaconnectcassandra_fast-data-dev_1 ... done[2B[1A[2KStopping kafkaconnectcassandra_cassandra_1 ... done[1BRemoving kafkaconnectcassandra_fast-data-dev_1 ... </br>Removing kafkaconnectcassandra_cassandra_1 ... </br>[1A[2KRemoving kafkaconnectcassandra_cassandra_1 ... done[1B[2A[2KRemoving kafkaconnectcassandra_fast-data-dev_1 ... done[2BRemoving network kafkaconnectcassandra_default</br></br>">view</button>
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 1 out of 1
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        12.29 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div>
            </div>

        </div>

        <script src="https://code.jquery.com/jquery-1.12.2.min.js"></script>
        <script src="https://code.jquery.com/ui/1.11.4/jquery-ui.min.js"></script>
        <link rel="stylesheet" href="https://code.jquery.com/ui/1.11.4/themes/smoothness/jquery-ui.css">

        <script>
         $(function () {
             //show
             $(document).on('click', '.trigger', function () {
                 $(this).addClass("on");
                 $(this).tooltip({
                     items: '.trigger.on',
                     position: {
                         my: "left+30 center",
                         at: "right center",
                         collision: "flip"
                     },
                     content: function(){
                         var element = $( this );
                         return element.attr('title')
                     }
                 });
                 $(this).trigger('mouseenter');
             });
             //hide
             $(document).on('click', '.trigger.on', function () {
                 $(this).tooltip('close');
                 $(this).removeClass("on");
             });
             //prevent mouseout and other related events from firing their handlers
             $(".trigger").on('mouseout', function (e) {
                 e.stopImmediatePropagation();
             });
         });
        </script>
    </body>
</html>
