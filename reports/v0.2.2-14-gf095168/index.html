<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>Coyote Tester | kafka-connect-cassandra v0.2.2-14-gf095168 | Results</title>

    </head>
    <body>

        <div id="testResults" style="display:inline;width:33%"></div>
        <div id="testTimes" style="display:inline;width:66%"></div>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.4.4/d3.min.js"></script>
        <script src="https://storage.googleapis.com/artifacts-landoop/d3pie.min.js"></script>
        <script>
         var pie = new d3pie("testResults", {
             "header": {
                 "title": {
                     "text": "all passed",
                     "color": "#fffefe",
                     "fontSize": 34,
                     "font": "sans"
                 },
                 "subtitle": {
                     "text": "kafka-connect-cassandra v0.2.2-14-gf095168",
                     "color": "#E8E6E6",
                     "fontSize": 14,
                     "font": "sans"
                 },
                 "location": "pie-center",
                 "titleSubtitlePadding": 10
             },
             "footer": {
                "text": "Coyote-tester, part of Landoopâ„¢ test-suite. 2016 Oct 12, Wed, 21:59 UTC",
                "color": "#E8E6E6",
                "fontSize": 14,
                "font": "open sans",
                "location": "bottom-left"
             },
             "size": {
                 "canvasHeight": 375,
                 "canvasWidth": 500,
                 "pieInnerRadius": "72%",
                 "pieOuterRadius": "92%"
             },
             "data": {
                 "sortOrder": "label-desc",
                 "content": [
                     {
                         "label": "failed",
                         "value": 0,
                         "color": "#e21515"
                     },
                     {
                         "label": "passed",
                         "value": 15,
                         "color": "#64a61f"
                     }
                 ]
             },
             "labels": {
                 "outer": {
                     "format": "label-percentage1",
                     "pieDistance": 25
                 },
                 "inner": {
                     "format": "none"
                 },
                 "mainLabel": {
                     "color": "#ffffff",
                     "fontSize": 16
                 },
                 "percentage": {
                     "color": "#919191",
                     "fontSize": 16,
                     "decimalPlaces": 1
                 },
                 "value": {
                     "color": "#cccc43",
                     "fontSize": 16
                 },
                 "lines": {
                     "enabled": true,
                     "color": "#777777"
                 },
                 "truncation": {
                     "enabled": true
                 }
             },
             "effects": {
                 "pullOutSegmentOnClick": {
                     "effect": "linear",
                     "speed": 400,
                     "size": 8
                 }
             },
             "misc": {
                 "colors": {
                     "background": "#2b2b2b",
                     "segmentStroke": "#f6f6f6"
                 }
             }
         });
        </script>
        <script>
         var pie = new d3pie("testTimes", {
             "header": {
                 "title": {
                     "text": "54 s",
                     "color": "#fffefe",
                     "fontSize": 34,
                     "font": "sans"
             },
                 "subtitle": {
                     "text": "total time",
                     "color": "#999999",
                     "fontSize": 14,
                     "font": "sans"
                 },
                 "location": "pie-center",
                 "titleSubtitlePadding": 10
             },
             "footer": {
                "text": "",
                "color": "#999999",
                "fontSize": 10,
                "font": "open sans",
                "location": "bottom-left"
             },
             "size": {
                 "canvasHeight": 375,
                 "canvasWidth": 700,
                 "pieInnerRadius": "72%",
                 "pieOuterRadius": "85%"
             },
             "data": {
                 "sortOrder": "label-desc",
                 "smallSegmentGrouping": {
                     "enabled": true,
                     "value": 3
                 },
                 "content": [
                     {
                         "label": "Setup Containers, Docker Compose Pull",
                         "value": 1.804090386,
                         "color": "#2383c1"
                     },{
                         "label": "Setup Containers, Build Docker Images",
                         "value": 0.42827866800000003,
                         "color": "#64a61f"
                     },{
                         "label": "Setup Containers, Docker Compose Up",
                         "value": 1.28706106,
                         "color": "#7b6788"
                     },{
                         "label": "Setup Containers, Check docker compose log",
                         "value": 0.537708117,
                         "color": "#a05c56"
                     },{
                         "label": "Setup Cassandra Source Connector, Create Source Topic",
                         "value": 3.253246173,
                         "color": "#961919"
                     },{
                         "label": "Setup Cassandra Source Connector, Create Cassandra Source Table and Data",
                         "value": 2.514673803,
                         "color": "#d8d239"
                     },{
                         "label": "Setup Cassandra Source Connector, Create a Cassandra Source Distributed Connector",
                         "value": 1.6243300999999999,
                         "color": "#e98125"
                     },{
                         "label": "Setup Cassandra Sink Connector, Create Sink Topic",
                         "value": 2.585244411,
                         "color": "#d0743c"
                     },{
                         "label": "Setup Cassandra Sink Connector, Create Cassandra Sink Table",
                         "value": 2.108509554,
                         "color": "#635122"
                     },{
                         "label": "Setup Cassandra Sink Connector, Create a Cassandra Sink Distributed Connector",
                         "value": 1.163766808,
                         "color": "#6ada6a"
                     },{
                         "label": "Test Cassandra Source Connector, Read Entries from Topic",
                         "value": 20.852383663,
                         "color": "#0b6197"
                     },{
                         "label": "Test Cassandra Sink Connector, Write Entries into Topic",
                         "value": 2.982963378,
                         "color": "#7c9058"
                     },{
                         "label": "Test Cassandra Sink Connector, Verify entries",
                         "value": 1.809593862,
                         "color": "#207f32"
                     },{
                         "label": "Other Tests, Read First 2000 Lines of Connect Logs",
                         "value": 0.07007363100000001,
                         "color": "#44b9af"
                     },{
                         "label": "Clean-up Containers, Docker Compose Down",
                         "value": 10.925852154,
                         "color": "#2383c1"
                     },
                 ]
             },
             "labels": {
                 "outer": {
                     "format": "label-percentage1",
                     "pieDistance": 25
                 },
                 "inner": {
                     "format": "none"
                 },
                 "mainLabel": {
                     "color": "#ffffff",
                     "fontSize": 12
                 },
                 "percentage": {
                     "color": "#919191",
                     "fontSize": 12,
                     "decimalPlaces": 1
                 },
                 "value": {
                     "color": "#cccc43",
                     "fontSize": 12
                 },
                 "lines": {
                     "enabled": true,
                     "color": "#777777"
                 },
                 "truncation": {
                     "enabled": true
                 }
             },
             "effects": {
                 "pullOutSegmentOnClick": {
                     "effect": "linear",
                     "speed": 400,
                     "size": 8
                 }
             },
             "misc": {
                 "colors": {
                     "background": "#2b2b2b",
                     "segmentStroke": "#f6f6f6"
                 }
             }
         });
        </script>

        <style type="text/css">
         body {
             font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial;
             font-size: 14px;
             line-height: 20px;
             font-weight: 400;
             color: #3b3b3b;
             -webkit-font-smoothing: antialiased;
             font-smoothing: antialiased;
             background: #2b2b2b;
         }

         .wrapper {
             margin: 0 auto;
             padding: 40px;
             /*max-width: 800px;*/
         }

         div.ui-tooltip {
             color: red;
             border-radius: 20px;
             /*font: bold 12px "Helvetica Neue", Sans-Serif;*/
             /*text-transform: uppercase;*/
             box-shadow: 0 0 7px black;
             /*width: 400px;*/
             word-wrap: "normal";
             max-width: 900px;
         }

         .ui-tooltip-content {
             color: black;
             font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
             word-wrap: "normal";
             /*max-width: 900px;*/
         }

         .table {
             margin: 0 0 40px 0;
             width: 100%;
             box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2);
             display: table;
         }

         @media screen and (max-width: 90%) {
             .table {
                 display: block;
             }
         }

         .row {
             display: table-row;
             background: #f6f6f6;
         }

         .row:nth-of-type(odd) {
             background: #e9e9e9;
         }

         .row.header {
             font-weight: 900;
             color: #ffffff;
             background: #ea6153;
         }
         .row.green {
             background: #27ae60;
         }
         .row.blue {
             background: #2980b9;
         }
         .row.purple {
             background: #8e44ad;
         }
         .row.gray {
             background: #2c3e50;
         }
         .row.yellow {
             background: #f1c40f;
         }
         .row.orange {
             background: #d35400;
         }
         .row.turquoise {
             background: #1abc9c;
         }

         @media screen and (max-width: 90%) {
             .row {
                 padding: 8px 0;
                 display: block;
             }
         }

         .cell {
             padding: 6px 12px;
             display: table-cell;
         }

         .cell.red {
             background: #ea6153;
         }

         .cell.green {
             background: #27ae60;
         }

         .cell.skip {
             background: #2b2b2b;
         }

         .cell.center {
             text-align: center;
         }

         .cell.width12 {
             width: 12%;
             max-width: 10px;
         }
         @media screen and (max-width: 90%) {
             .cell {
                 padding: 2px 12px;
                 display: block;
             }
         }
         /* .hideContent {overflow:hidden;line-height:1em;height:2em;}
            .showContent {line-height:1em;height:auto;}
          */
        </style>

        <div class="wrapper">

            <div class="table">
            <div class="row header">
                    <div class="cell">
                        Setup Containers
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Docker Compose Pull
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.80
                    </div>
                    <div class="cell">
                        (ignore) 1
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose pull</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose pull
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                        Pulling repository docker.io/landoop/cassandra
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_0" class="trigger" data-tooltip-id="0_0" title="Pulling cassandra (landoop/cassandra:latest)...</br>Error: image landoop/cassandra:latest not found</br></br>">view</button>
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Build Docker Images
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        0.43
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose build</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose build
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_1" class="trigger" data-tooltip-id="0_1" title="Step 1 : FROM cassandra:latest</br> ---&gt; a552f6550254</br>Step 2 : MAINTAINER Marios Andreopoulos &lt;marios@landoop.com&gt;</br> ---&gt; Using cache</br> ---&gt; e58ed2491a79</br>Step 3 : RUN sed -e &#39;s/authenticator: AllowAllAuthenticator/authenticator: PasswordAuthenticator/&#39;         -i /etc/cassandra/cassandra.yaml</br> ---&gt; Using cache</br> ---&gt; 27808c1c0b3c</br>Successfully built 27808c1c0b3c</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_1" class="trigger" data-tooltip-id="0_1" title="Building cassandra</br>fast-data-dev uses an image, skipping</br></br>">view</button>
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Docker Compose Up
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.29
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose up -d</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose up -d
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_2" class="trigger" data-tooltip-id="0_2" title="Creating network &#34;kafkaconnectcassandra_default&#34; with the default driver</br>Creating kafkaconnectcassandra_cassandra_1</br>Creating kafkaconnectcassandra_fast-data-dev_1</br></br>">view</button>
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Check docker compose log
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        0.54
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose logs</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose logs
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_3" class="trigger" data-tooltip-id="0_3" title="Attaching to kafkaconnectcassandra_fast-data-dev_1, kafkaconnectcassandra_cassandra_1</br>[36mfast-data-dev_1  |[0m [92mSetting advertised host to [96mfast-data-dev[34m[92m.[34m</br>[36mfast-data-dev_1  |[0m [92mStarting services.[39m</br>[36mfast-data-dev_1  |[0m [34mYou may visit [96mhttp://fast-data-dev:3030[34m in about a minute.[39m</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:06,446 CRIT Supervisor running as root (no user in config file)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:06,450 INFO supervisord started with pid 7</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:07,453 INFO spawned: &#39;zookeeper&#39; with pid 50</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:07,455 INFO spawned: &#39;caddy&#39; with pid 51</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:07,460 INFO spawned: &#39;broker&#39; with pid 52</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:07,463 INFO spawned: &#39;smoke-tests&#39; with pid 53</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:07,465 INFO spawned: &#39;connect-distributed&#39; with pid 55</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:07,467 INFO spawned: &#39;logs-to-kafka&#39; with pid 56</br>[33mcassandra_1      |[0m INFO  21:56:13 Configuration location: file:/etc/cassandra/cassandra.yaml</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:07,469 INFO spawned: &#39;schema-registry&#39; with pid 57</br>[33mcassandra_1      |[0m INFO  21:56:13 Node configuration:[allocate_tokens_for_keyspace=null; authenticator=PasswordAuthenticator; authorizer=AllowAllAuthorizer; auto_bootstrap=true; auto_snapshot=true; batch_size_fail_threshold_in_kb=50; batch_size_warn_threshold_in_kb=5; batchlog_replay_throttle_in_kb=1024; broadcast_address=172.19.0.2; broadcast_rpc_address=172.19.0.2; buffer_pool_use_heap_if_exhausted=true; cas_contention_timeout_in_ms=1000; cdc_enabled=false; cdc_free_space_check_interval_ms=250; cdc_raw_directory=null; cdc_total_space_in_mb=null; client_encryption_options=&lt;REDACTED&gt;; cluster_name=Test Cluster; column_index_cache_size_in_kb=2; column_index_size_in_kb=64; commit_failure_policy=stop; commitlog_compression=null; commitlog_directory=/var/lib/cassandra/commitlog; commitlog_max_compression_buffers_in_pool=3; commitlog_periodic_queue_size=-1; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_batch_window_in_ms=null; commitlog_sync_period_in_ms=10000; commitlog_total_space_in_mb=null; compaction_large_partition_warning_threshold_mb=100; compaction_throughput_mb_per_sec=16; concurrent_compactors=null; concurrent_counter_writes=32; concurrent_materialized_view_writes=32; concurrent_reads=32; concurrent_replicates=null; concurrent_writes=32; counter_cache_keys_to_save=2147483647; counter_cache_save_period=7200; counter_cache_size_in_mb=null; counter_write_request_timeout_in_ms=5000; credentials_cache_max_entries=1000; credentials_update_interval_in_ms=-1; credentials_validity_in_ms=2000; cross_node_timeout=false; data_file_directories=[Ljava.lang.String;@29176cc1; disk_access_mode=auto; disk_failure_policy=stop; disk_optimization_estimate_percentile=0.95; disk_optimization_page_cross_chance=0.1; disk_optimization_strategy=ssd; dynamic_snitch=true; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; enable_scripted_user_defined_functions=false; enable_user_defined_functions=false; enable_user_defined_functions_threads=true; encryption_options=null; endpoint_snitch=SimpleSnitch; file_cache_size_in_mb=null; gc_log_threshold_in_ms=200; gc_warn_threshold_in_ms=1000; hinted_handoff_disabled_datacenters=[]; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_compression=null; hints_directory=null; hints_flush_period_in_ms=10000; incremental_backups=false; index_interval=null; index_summary_capacity_in_mb=null; index_summary_resize_interval_in_minutes=60; initial_token=null; inter_dc_stream_throughput_outbound_megabits_per_sec=200; inter_dc_tcp_nodelay=false; internode_authenticator=null; internode_compression=dc; internode_recv_buff_size_in_bytes=null; internode_send_buff_size_in_bytes=null; key_cache_keys_to_save=2147483647; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=172.19.0.2; listen_interface=null; listen_interface_prefer_ipv6=false; listen_on_broadcast_address=false; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; max_hints_file_size_in_mb=128; max_mutation_size_in_kb=null; max_streaming_retries=3; max_value_size_in_mb=256; memtable_allocation_type=heap_buffers; memtable_cleanup_threshold=null; memtable_flush_writers=1; memtable_heap_space_in_mb=null; memtable_offheap_space_in_mb=null; min_free_space_per_drive_in_mb=50; native_transport_max_concurrent_connections=-1; native_transport_max_concurrent_connections_per_ip=-1; native_transport_max_frame_size_in_mb=256; native_transport_max_threads=128; native_transport_port=9042; native_transport_port_ssl=null; num_tokens=256; otc_coalescing_strategy=TIMEHORIZON; otc_coalescing_window_us=200; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_cache_max_entries=1000; permissions_update_interval_in_ms=-1; permissions_validity_in_ms=2000; phi_convict_threshold=8.0; prepared_statements_cache_size_mb=null; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_scheduler_id=null; request_scheduler_options=null; request_timeout_in_ms=10000; role_manager=CassandraRoleManager; roles_cache_max_entries=1000; roles_update_interval_in_ms=-1; roles_validity_in_ms=2000; row_cache_class_name=org.apache.cassandra.cache.OHCProvider; row_cache_keys_to_save=2147483647; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=0.0.0.0; rpc_interface=null; rpc_interface_prefer_ipv6=false; rpc_keepalive=true; rpc_listen_backlog=50; rpc_max_threads=2147483647; rpc_min_threads=16; rpc_port=9160; rpc_recv_buff_size_in_bytes=null; rpc_send_buff_size_in_bytes=null; rpc_server_type=sync; saved_caches_directory=/var/lib/cassandra/saved_caches; seed_provider=org.apache.cassandra.locator.SimpleSeedProvider{seeds=172.19.0.2}; server_encryption_options=&lt;REDACTED&gt;; snapshot_before_compaction=false; ssl_storage_port=7001; sstable_preemptive_open_interval_in_mb=50; start_native_transport=true; start_rpc=false; storage_port=7000; stream_throughput_outbound_megabits_per_sec=200; streaming_socket_timeout_in_ms=86400000; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; thrift_prepared_statements_cache_size_mb=null; tombstone_failure_threshold=100000; tombstone_warn_threshold=1000; tracetype_query_ttl=86400; tracetype_repair_ttl=604800; transparent_data_encryption_options=org.apache.cassandra.config.TransparentDataEncryptionOptions@2f177a4b; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; unlogged_batch_across_partitions_warn_threshold=10; user_defined_function_fail_timeout=1500; user_defined_function_warn_timeout=500; user_function_timeout_policy=die; windows_timer_interval=1; write_request_timeout_in_ms=2000]</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:07,471 INFO spawned: &#39;rest-proxy&#39; with pid 59</br>[33mcassandra_1      |[0m INFO  21:56:13 DiskAccessMode &#39;auto&#39; determined to be mmap, indexAccessMode is mmap</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:08,571 INFO success: zookeeper entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:56:13 Global memtable on-heap threshold is enabled at 1996MB</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:08,571 INFO success: caddy entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:56:13 Global memtable off-heap threshold is enabled at 1996MB</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:08,571 INFO success: broker entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:56:13 Hostname: 99364a9c77f5</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:08,571 INFO success: smoke-tests entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:56:13 JVM vendor/version: OpenJDK 64-Bit Server VM/1.8.0_102</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:08,571 INFO success: connect-distributed entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:56:13 Heap size: 7.800GiB/7.800GiB</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:08,571 INFO success: logs-to-kafka entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:56:13 Code Cache Non-heap memory: init = 2555904(2496K) used = 6494976(6342K) committed = 6553600(6400K) max = 251658240(245760K)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:08,571 INFO success: schema-registry entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:56:13 Metaspace Non-heap memory: init = 0(0K) used = 15667432(15300K) committed = 16252928(15872K) max = -1(-1K)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:08,572 INFO success: rest-proxy entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:11,365 INFO exited: schema-registry (exit status 1; not expected)</br>[33mcassandra_1      |[0m INFO  21:56:13 Compressed Class Space Non-heap memory: init = 0(0K) used = 1894616(1850K) committed = 2097152(2048K) max = 1073741824(1048576K)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:11,368 INFO spawned: &#39;schema-registry&#39; with pid 446</br>[33mcassandra_1      |[0m INFO  21:56:13 Par Eden Space Heap memory: init = 1718091776(1677824K) used = 309264560(302016K) committed = 1718091776(1677824K) max = 1718091776(1677824K)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:11,392 INFO exited: rest-proxy (exit status 1; not expected)</br>[33mcassandra_1      |[0m INFO  21:56:13 Par Survivor Space Heap memory: init = 214695936(209664K) used = 0(0K) committed = 214695936(209664K) max = 214695936(209664K)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:11,394 INFO spawned: &#39;rest-proxy&#39; with pid 493</br>[33mcassandra_1      |[0m INFO  21:56:13 CMS Old Gen Heap memory: init = 6442450944(6291456K) used = 0(0K) committed = 6442450944(6291456K) max = 6442450944(6291456K)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:12,421 INFO success: schema-registry entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:56:13 Classpath: /etc/cassandra:/usr/share/cassandra/lib/HdrHistogram-2.1.9.jar:/usr/share/cassandra/lib/ST4-4.0.8.jar:/usr/share/cassandra/lib/airline-0.6.jar:/usr/share/cassandra/lib/antlr-runtime-3.5.2.jar:/usr/share/cassandra/lib/asm-5.0.4.jar:/usr/share/cassandra/lib/caffeine-2.2.6.jar:/usr/share/cassandra/lib/cassandra-driver-core-3.0.1-shaded.jar:/usr/share/cassandra/lib/commons-cli-1.1.jar:/usr/share/cassandra/lib/commons-codec-1.2.jar:/usr/share/cassandra/lib/commons-lang3-3.1.jar:/usr/share/cassandra/lib/commons-math3-3.2.jar:/usr/share/cassandra/lib/compress-lzf-0.8.4.jar:/usr/share/cassandra/lib/concurrent-trees-2.4.0.jar:/usr/share/cassandra/lib/concurrentlinkedhashmap-lru-1.4.jar:/usr/share/cassandra/lib/disruptor-3.0.1.jar:/usr/share/cassandra/lib/ecj-4.4.2.jar:/usr/share/cassandra/lib/guava-18.0.jar:/usr/share/cassandra/lib/high-scale-lib-1.0.6.jar:/usr/share/cassandra/lib/hppc-0.5.4.jar:/usr/share/cassandra/lib/jackson-core-asl-1.9.2.jar:/usr/share/cassandra/lib/jackson-mapper-asl-1.9.2.jar:/usr/share/cassandra/lib/jamm-0.3.0.jar:/usr/share/cassandra/lib/javax.inject.jar:/usr/share/cassandra/lib/jbcrypt-0.3m.jar:/usr/share/cassandra/lib/jcl-over-slf4j-1.7.7.jar:/usr/share/cassandra/lib/jflex-1.6.0.jar:/usr/share/cassandra/lib/jna-4.0.0.jar:/usr/share/cassandra/lib/joda-time-2.4.jar:/usr/share/cassandra/lib/json-simple-1.1.jar:/usr/share/cassandra/lib/libthrift-0.9.2.jar:/usr/share/cassandra/lib/log4j-over-slf4j-1.7.7.jar:/usr/share/cassandra/lib/logback-classic-1.1.3.jar:/usr/share/cassandra/lib/logback-core-1.1.3.jar:/usr/share/cassandra/lib/lz4-1.3.0.jar:/usr/share/cassandra/lib/metrics-core-3.1.0.jar:/usr/share/cassandra/lib/metrics-jvm-3.1.0.jar:/usr/share/cassandra/lib/metrics-logback-3.1.0.jar:/usr/share/cassandra/lib/netty-all-4.0.39.Final.jar:/usr/share/cassandra/lib/ohc-core-0.4.3.jar:/usr/share/cassandra/lib/ohc-core-j8-0.4.3.jar:/usr/share/cassandra/lib/primitive-1.0.jar:/usr/share/cassandra/lib/reporter-config-base-3.0.0.jar:/usr/share/cassandra/lib/reporter-config3-3.0.0.jar:/usr/share/cassandra/lib/sigar-1.6.4.jar:/usr/share/cassandra/lib/slf4j-api-1.7.7.jar:/usr/share/cassandra/lib/snakeyaml-1.11.jar:/usr/share/cassandra/lib/snappy-java-1.1.1.7.jar:/usr/share/cassandra/lib/snowball-stemmer-1.3.0.581.1.jar:/usr/share/cassandra/lib/stream-2.5.2.jar:/usr/share/cassandra/lib/thrift-server-0.3.7.jar:/usr/share/cassandra/apache-cassandra-3.9.jar:/usr/share/cassandra/apache-cassandra-thrift-3.9.jar:/usr/share/cassandra/apache-cassandra.jar:/usr/share/cassandra/stress.jar::/usr/share/cassandra/lib/jamm-0.3.0.jar</br>[33mcassandra_1      |[0m INFO  21:56:13 JVM Arguments: [-Xloggc:/var/log/cassandra/gc.log, -ea, -XX:+UseThreadPriorities, -XX:ThreadPriorityPolicy=42, -XX:+HeapDumpOnOutOfMemoryError, -Xss256k, -XX:StringTableSize=1000003, -XX:+AlwaysPreTouch, -XX:-UseBiasedLocking, -XX:+UseTLAB, -XX:+ResizeTLAB, -XX:+PerfDisableSharedMem, -Djava.net.preferIPv4Stack=true, -XX:+UseParNewGC, -XX:+UseConcMarkSweepGC, -XX:+CMSParallelRemarkEnabled, -XX:SurvivorRatio=8, -XX:MaxTenuringThreshold=1, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:CMSWaitDuration=10000, -XX:+CMSParallelInitialMarkEnabled, -XX:+CMSEdenChunksRecordAlways, -XX:+CMSClassUnloadingEnabled, -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, -XX:+PrintHeapAtGC, -XX:+PrintTenuringDistribution, -XX:+PrintGCApplicationStoppedTime, -XX:+PrintPromotionFailure, -XX:+UseGCLogFileRotation, -XX:NumberOfGCLogFiles=10, -XX:GCLogFileSize=10M, -Xms8192M, -Xmx8192M, -Xmn2048M, -XX:CompileCommandFile=/etc/cassandra/hotspot_compiler, -javaagent:/usr/share/cassandra/lib/jamm-0.3.0.jar, -Dcassandra.jmx.local.port=7199, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.password.file=/etc/cassandra/jmxremote.password, -Djava.library.path=/usr/share/cassandra/lib/sigar-bin, -Dlogback.configurationFile=logback.xml, -Dcassandra.logdir=/var/log/cassandra, -Dcassandra.storagedir=/var/lib/cassandra, -Dcassandra-foreground=yes]</br>[33mcassandra_1      |[0m WARN  21:56:13 Unable to lock JVM memory (ENOMEM). This can result in part of the JVM being swapped out, especially with mmapped I/O enabled. Increase RLIMIT_MEMLOCK or run Cassandra as root.</br>[33mcassandra_1      |[0m WARN  21:56:13 jemalloc shared library could not be preloaded to speed up memory allocations</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:12,421 INFO success: rest-proxy entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m WARN  21:56:13 JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:37,490 INFO exited: smoke-tests (exit status 0; expected)</br>[33mcassandra_1      |[0m WARN  21:56:13 OpenJDK is not recommended. Please upgrade to the newest Oracle Java release</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:56:47,489 INFO exited: logs-to-kafka (exit status 0; expected)</br>[33mcassandra_1      |[0m INFO  21:56:13 Initializing SIGAR library</br>[33mcassandra_1      |[0m INFO  21:56:13 Checked OS settings and found them configured for optimal performance.</br>[33mcassandra_1      |[0m WARN  21:56:13 Directory /var/lib/cassandra/data doesn&#39;t exist</br>[33mcassandra_1      |[0m WARN  21:56:13 Directory /var/lib/cassandra/commitlog doesn&#39;t exist</br>[33mcassandra_1      |[0m WARN  21:56:13 Directory /var/lib/cassandra/saved_caches doesn&#39;t exist</br>[33mcassandra_1      |[0m WARN  21:56:13 Directory /var/lib/cassandra/hints doesn&#39;t exist</br>[33mcassandra_1      |[0m INFO  21:56:13 Initialized prepared statement caches with 31 MB (native) and 31 MB (Thrift)</br>[33mcassandra_1      |[0m INFO  21:56:14 Initializing system.IndexInfo</br>[33mcassandra_1      |[0m INFO  21:56:14 Initializing system.batches</br>[33mcassandra_1      |[0m INFO  21:56:14 Initializing system.paxos</br>[33mcassandra_1      |[0m INFO  21:56:14 Initializing system.local</br>[33mcassandra_1      |[0m INFO  21:56:14 Initializing system.peers</br>[33mcassandra_1      |[0m INFO  21:56:14 Initializing system.peer_events</br>[33mcassandra_1      |[0m INFO  21:56:14 Initializing system.range_xfers</br>[33mcassandra_1      |[0m INFO  21:56:14 Initializing system.compaction_history</br>[33mcassandra_1      |[0m INFO  21:56:14 Initializing system.sstable_activity</br>[33mcassandra_1      |[0m INFO  21:56:14 Initializing system.size_estimates</br>[33mcassandra_1      |[0m INFO  21:56:14 Initializing system.available_ranges</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system.views_builds_in_progress</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system.built_views</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system.hints</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system.batchlog</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system.schema_keyspaces</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system.schema_columnfamilies</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system.schema_columns</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system.schema_triggers</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system.schema_usertypes</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system.schema_functions</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system.schema_aggregates</br>[33mcassandra_1      |[0m INFO  21:56:15 Not submitting build tasks for views in keyspace system as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:56:15 Configured JMX server at: service:jmx:rmi://127.0.0.1/jndi/rmi://127.0.0.1:7199/jmxrmi</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing key cache with capacity of 100 MBs.</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing row cache with capacity of 0 MBs</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing counter cache with capacity of 50 MBs</br>[33mcassandra_1      |[0m INFO  21:56:15 Scheduling counter cache save to every 7200 seconds (going to save all keys).</br>[33mcassandra_1      |[0m INFO  21:56:15 Global buffer pool is enabled, when pool is exhausted (max is 512.000MiB) it will allocate on heap</br>[33mcassandra_1      |[0m INFO  21:56:15 Populating token metadata from system tables</br>[33mcassandra_1      |[0m INFO  21:56:15 Token metadata: </br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system_schema.keyspaces</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system_schema.tables</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system_schema.columns</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system_schema.triggers</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system_schema.dropped_columns</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system_schema.views</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system_schema.types</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system_schema.functions</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system_schema.aggregates</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing system_schema.indexes</br>[33mcassandra_1      |[0m INFO  21:56:15 Not submitting build tasks for views in keyspace system_schema as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:56:15 Completed loading (1 ms; 5 keys) KeyCache cache</br>[33mcassandra_1      |[0m INFO  21:56:15 No commitlog files found; skipping replay</br>[33mcassandra_1      |[0m INFO  21:56:15 Populating token metadata from system tables</br>[33mcassandra_1      |[0m INFO  21:56:15 Token metadata: </br>[33mcassandra_1      |[0m INFO  21:56:15 Cassandra version: 3.9</br>[33mcassandra_1      |[0m INFO  21:56:15 Thrift API version: 20.1.0</br>[33mcassandra_1      |[0m INFO  21:56:15 CQL supported versions: 3.4.2 (default: 3.4.2)</br>[33mcassandra_1      |[0m INFO  21:56:15 Initializing index summary manager with a memory pool size of 399 MB and a resize interval of 60 minutes</br>[33mcassandra_1      |[0m INFO  21:56:16 Starting Messaging Service on /172.19.0.2:7000 (eth0)</br>[33mcassandra_1      |[0m WARN  21:56:16 No host ID found, created 77a49b47-daec-4b2c-a610-7d00d767e554 (Note: This should happen exactly once per node).</br>[33mcassandra_1      |[0m INFO  21:56:16 Loading persisted ring state</br>[33mcassandra_1      |[0m INFO  21:56:16 Starting up server gossip</br>[33mcassandra_1      |[0m INFO  21:56:16 This node will not auto bootstrap because it is configured to be a seed node.</br>[33mcassandra_1      |[0m INFO  21:56:16 Generated random tokens. tokens are [7965302455161360539, -6347155837712927332, 6849134120487663248, 4878713912930789183, -5972873342896216565, -2224805569738603667, 4907929230160956218, -2081314882654633059, 481818019666379987, -5805464096065031275, -5214697193955511752, -6199213726814381421, 1546163191728708506, -3499805111720120220, 4666440417497353847, -1751782219840424862, -1252164796308627580, 6980616954937853183, -4206045052125205703, -1998907780897054903, 3102671342574431460, -3643675206241694484, -8789575288391296745, -6463772741736353435, -7798913848978251515, -6258226956200187559, -5253738379588942785, -3348924000060566422, -3456169732142937120, -3826309185160864920, -5606486472354069240, -7893010670657169969, 4248647954186401530, 8558685382888736404, -8003404730263459349, -7684750877957685980, -4146002062190109124, 7040545162439023415, -6406005564944801542, 7792174067931785848, 2282479761164103149, 7422566798635521570, -8698191052631175904, 3292332375049855099, 3596906939795388621, 4858542841833583707, 5906596661850270948, -7503885847403165591, 3848231638522248945, 223007950342999940, -4091253697142455613, -7930890211675966329, -76816335644183619, 848112832721851502, -6609808816471751414, -5277845057538229603, -751496558005455352, 4191961502374264746, -4182306701643179148, -652329351894203206, -6573866026338574313, 938159295729599799, 8630733076768350283, 7583264583139914851, -8895814169999654507, 4013717453073302075, -1723590672669655981, -8366871585137303139, 2602939365326159808, -564197603826326570, 3094753434765077959, -7319783305382504420, -463217828098666316, 1193435748593693345, -4371671383150624434, 8568852117743019292, 3641615971515976443, -6972234523761985427, -9037401878744667589, 8148614728894254897, 3603418552231796298, -7653271505602882644, -4783722672195539629, 3813544295509790009, -9133815239304490500, -2532175457092329831, 8590717109797329735, 7874490109856355714, 8410828620820865152, 5396869778264711867, -8269163159349168818, 8094318174955357886, 6673057470215705506, 1350519401433647255, 166293363675312210, 1117884582685099490, -2775233169182023701, 168820755398366017, 6314907967868679767, -5396105219910967343, 5471976176595764095, -2367365329115236704, 1222592211832601189, 1064455507082021495, -6706016436056570540, 1559616689615932968, 7539105284426742958, -6027023901170837811, -8130616962997215013, 8205964029832451113, 6551027080216240140, -7171247655429643466, -4019335865730576994, 1817415784177776887, 3316996794157611782, -4792416878836684082, 5549956280680001768, 3555248904022419420, -197711513400346061, -5612330529921191890, 7099925325475928296, 3554327272677061946, 6404289800530210009, 92924276538177945, -6852144548291910223, 7769918918273036897, -5570002238153794918, -1448897646010595868, -7959171948110196601, -8367640686902077135, -8735555407053534629, 1262639409472599472, 4735557866261954624, -8131209267685264700, -3031166028458318578, 1534610399745678032, -5141351207251739101, -4557185188887151437, -6887404893200623270, -6361282855760153317, 7796338320658263354, 1445652820957875410, 5914806799383968202, 6828370515985670888, 2910998388162783021, -173459831209744977, 3569633931660820613, 2659517964589722696, -1224899161168469585, -1005931753066659650, -3582134191784606654, -2561484615123143213, -6294666526644305321, -4577986102861962074, -1659323440315517588, 9165510576525043113, 1105827568771735418, 4883618032125202419, 3967036377933722457, 2633223719202677678, 6030930035826767600, 1030564180433273098, 3877265286975608522, 3414060969520296424, 1152297736691777869, 6251881688493408498, 5282443599322213253, -8198727261723852985, 570639582906355340, 7801160687072382340, -442613473111452172, 361893100367177211, -1577515194936890502, -2623679044894618855, 3674555428371334892, 451727481683868600, -479084526526352832, 6701292702909422887, 2220454461477055039, -4814104317298382741, 6554072337812744234, -3325032505950266838, -8880815306747072160, -8420755504899169513, 5253547990063963523, -2132444562774528669, 5035279985330064072, -852124007756455962, -1403595327094542158, 5498673389266656341, -2761569991466330565, -2316574537692727275, -7578229332324662431, -6718466904698615683, -3373223203176864883, 8009359897958234160, -8023548266062141011, 3109616385003354330, -3821283353672491453, -1754034184108528315, -5913789836659551595, 7563222349883421149, 5156803897610267318, -5574114051369887901, 4848775413790897089, -4825838589172305157, 4614541996800624315, 8987090511394171329, 5898408010716555198, 1733282315193299501, 7554447675057772357, -4879493503205213501, 1891762474362322399, 6219951892252493579, -2138637665513062797, 6284218962410061434, 1811882832849753597, 6046938284333130866, 2365819610779339812, -5301768760518309197, 6584321912627745743, -3066913684353147951, 8611553207154146547, 8068304283618209129, 3059238357608340184, 1285076732965282286, 1734467324458037200, 7311187393182374516, 3047990109863755783, -7576643605828628723, 534631997367215861, 8829679384697548962, -4673462504890329455, -7819678520402378544, -7348075262046701703, -5911550497345893919, 3929719945534230138, -133336887249891062, -639361629390308332, -5891220386132041584, -816141994220666796, -6963556288887372888, -7573346674232731868, -1455007574854588098, -1741919629629350458, 8263017594453104074, -1719690947809787466, -8173759586751916634, -1453936185261688840, 7738735844664926326, 2214136096293747130, 7322225699642247540, 6173914214417460230, 8760611871285381492, -2322151240052806634, -5722729150547477863]</br>[33mcassandra_1      |[0m INFO  21:56:16 Create new Keyspace: KeyspaceMetadata{name=system_traces, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=2}}, tables=[org.apache.cassandra.config.CFMetaData@786f79fc[cfId=c5e99f16-8677-3914-b17e-960613512345,ksName=system_traces,cfName=sessions,flags=[COMPOUND],params=TableParams{comment=tracing sessions, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@48f76287, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [client command coordinator duration request started_at parameters]],partitionKeyColumns=[session_id],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UUIDType,columnMetadata=[client, command, session_id, coordinator, request, started_at, duration, parameters],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@3fb8b39a[cfId=8826e8e9-e16a-3728-8753-3bc1fc713c25,ksName=system_traces,cfName=events,flags=[COMPOUND],params=TableParams{comment=tracing events, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@48f76287, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.TimeUUIDType),partitionColumns=[[] | [activity source source_elapsed thread]],partitionKeyColumns=[session_id],clusteringColumns=[event_id],keyValidator=org.apache.cassandra.db.marshal.UUIDType,columnMetadata=[activity, session_id, thread, event_id, source, source_elapsed],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}</br>[33mcassandra_1      |[0m INFO  21:56:16 Not submitting build tasks for views in keyspace system_traces as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:56:16 Initializing system_traces.events</br>[33mcassandra_1      |[0m INFO  21:56:16 Initializing system_traces.sessions</br>[33mcassandra_1      |[0m INFO  21:56:16 Create new Keyspace: KeyspaceMetadata{name=system_distributed, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}, tables=[org.apache.cassandra.config.CFMetaData@504ef595[cfId=759fffad-624b-3181-80ee-fa9a52d1f627,ksName=system_distributed,cfName=repair_history,flags=[COMPOUND],params=TableParams{comment=Repair history, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@48f76287, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.TimeUUIDType),partitionColumns=[[] | [coordinator exception_message exception_stacktrace finished_at parent_id range_begin range_end started_at status participants]],partitionKeyColumns=[keyspace_name, columnfamily_name],clusteringColumns=[id],keyValidator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type),columnMetadata=[status, id, coordinator, finished_at, participants, exception_stacktrace, parent_id, range_end, range_begin, exception_message, keyspace_name, started_at, columnfamily_name],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@75ffa99b[cfId=deabd734-b99d-3b9c-92e5-fd92eb5abf14,ksName=system_distributed,cfName=parent_repair_history,flags=[COMPOUND],params=TableParams{comment=Repair history, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@48f76287, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [exception_message exception_stacktrace finished_at keyspace_name started_at columnfamily_names options requested_ranges successful_ranges]],partitionKeyColumns=[parent_id],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[requested_ranges, exception_message, keyspace_name, successful_ranges, started_at, finished_at, options, exception_stacktrace, parent_id, columnfamily_names],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@24680f36[cfId=5582b59f-8e4e-35e1-b913-3acada51eb04,ksName=system_distributed,cfName=view_build_status,flags=[COMPOUND],params=TableParams{comment=Materialized View build status, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@48f76287, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UUIDType),partitionColumns=[[] | [status]],partitionKeyColumns=[keyspace_name, view_name],clusteringColumns=[host_id],keyValidator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type),columnMetadata=[status, keyspace_name, view_name, host_id],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}</br>[33mcassandra_1      |[0m INFO  21:56:16 Not submitting build tasks for views in keyspace system_distributed as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:56:16 Initializing system_distributed.parent_repair_history</br>[33mcassandra_1      |[0m INFO  21:56:16 Initializing system_distributed.repair_history</br>[33mcassandra_1      |[0m INFO  21:56:16 Initializing system_distributed.view_build_status</br>[33mcassandra_1      |[0m INFO  21:56:16 Node /172.19.0.2 state jump to NORMAL</br>[33mcassandra_1      |[0m INFO  21:56:16 Create new Keyspace: KeyspaceMetadata{name=system_auth, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[org.apache.cassandra.config.CFMetaData@1fa50099[cfId=5bc52802-de25-35ed-aeab-188eecebb090,ksName=system_auth,cfName=roles,flags=[COMPOUND],params=TableParams{comment=role definitions, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@48f76287, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [can_login is_superuser salted_hash member_of]],partitionKeyColumns=[role],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[role, salted_hash, member_of, can_login, is_superuser],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@51163596[cfId=0ecdaa87-f8fb-3e60-88d1-74fb36fe5c0d,ksName=system_auth,cfName=role_members,flags=[COMPOUND],params=TableParams{comment=role memberships lookup table, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@48f76287, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | []],partitionKeyColumns=[role],clusteringColumns=[member],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[role, member],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@7448f6e4[cfId=3afbe79f-2194-31a7-add7-f5ab90d8ec9c,ksName=system_auth,cfName=role_permissions,flags=[COMPOUND],params=TableParams{comment=permissions granted to db roles, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@48f76287, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [permissions]],partitionKeyColumns=[role],clusteringColumns=[resource],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[resource, role, permissions],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@389151ac[cfId=5f2fbdad-91f1-3946-bd25-d5da3a5c35ec,ksName=system_auth,cfName=resource_role_permissons_index,flags=[COMPOUND],params=TableParams{comment=index of db roles with permissions granted on a resource, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@48f76287, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | []],partitionKeyColumns=[resource],clusteringColumns=[role],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[resource, role],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}</br>[33mcassandra_1      |[0m INFO  21:56:16 Not submitting build tasks for views in keyspace system_auth as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:56:16 Initializing system_auth.resource_role_permissons_index</br>[33mcassandra_1      |[0m INFO  21:56:16 Initializing system_auth.role_members</br>[33mcassandra_1      |[0m INFO  21:56:16 Initializing system_auth.role_permissions</br>[33mcassandra_1      |[0m INFO  21:56:16 Initializing system_auth.roles</br>[33mcassandra_1      |[0m INFO  21:56:16 (Re)initializing CredentialsCache (validity period/update interval/max entries) (2000/2000/1000)</br>[33mcassandra_1      |[0m INFO  21:56:16 Waiting for gossip to settle before accepting client requests...</br>[33mcassandra_1      |[0m INFO  21:56:24 No gossip backlog; proceeding</br>[33mcassandra_1      |[0m INFO  21:56:24 Netty using native Epoll event loop</br>[33mcassandra_1      |[0m INFO  21:56:24 Using Netty Version: [netty-buffer=netty-buffer-4.0.39.Final.38bdf86, netty-codec=netty-codec-4.0.39.Final.38bdf86, netty-codec-haproxy=netty-codec-haproxy-4.0.39.Final.38bdf86, netty-codec-http=netty-codec-http-4.0.39.Final.38bdf86, netty-codec-socks=netty-codec-socks-4.0.39.Final.38bdf86, netty-common=netty-common-4.0.39.Final.38bdf86, netty-handler=netty-handler-4.0.39.Final.38bdf86, netty-tcnative=netty-tcnative-1.1.33.Fork19.fe4816e, netty-transport=netty-transport-4.0.39.Final.38bdf86, netty-transport-native-epoll=netty-transport-native-epoll-4.0.39.Final.38bdf86, netty-transport-rxtx=netty-transport-rxtx-4.0.39.Final.38bdf86, netty-transport-sctp=netty-transport-sctp-4.0.39.Final.38bdf86, netty-transport-udt=netty-transport-udt-4.0.39.Final.38bdf86]</br>[33mcassandra_1      |[0m INFO  21:56:24 Starting listening for CQL clients on /0.0.0.0:9042 (unencrypted)...</br>[33mcassandra_1      |[0m INFO  21:56:24 Not starting RPC server as requested. Use JMX (StorageService-&gt;startRPCServer()) or nodetool (enablethrift) to start it</br>[33mcassandra_1      |[0m INFO  21:56:26 Scheduling approximate time-check task with a precision of 10 milliseconds</br>[33mcassandra_1      |[0m INFO  21:56:26 Created default superuser role &#39;cassandra&#39;</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 4 out of 4
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        4.06 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header green">
                    <div class="cell">
                        Setup Cassandra Source Connector
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Create Source Topic
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        3.25
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</br>  kafka-topics --zookeeper fast-data-dev:2181 --topic cassandra-source --partition 1 --replication 1 --create</br></br>'>docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev
  kafka-topics --zookeeper fast-data-dev:2181 --topic cassandra-source --partition 1 --replication 1 --create

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                        Created topic &#34;cassandra-source&#34;.
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Create Cassandra Source Table and Data
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.51
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra</br>  cqlsh -u cassandra -p cassandra cassandra</br></br>'>docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra
  cqlsh -u cassandra -p cassandra cassandra

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_1_1" class="trigger" data-tooltip-id="1_1" title=" id | created                              | price | product                 | qty</br>----+--------------------------------------+-------+-------------------------+-----</br>  1 | d3d64c60-90c6-11e6-a325-9b89c16b65a4 |  94.2 |  OP-DAX-P-20150201-95.7 | 100</br>  2 | d3d6e8a0-90c6-11e6-a325-9b89c16b65a4 |  99.5 |   OP-DAX-C-20150201-100 | 100</br>  3 | d3d736c0-90c6-11e6-a325-9b89c16b65a4 |   150 | FU-KOSPI-C-20150201-100 | 200</br></br>(3 rows)</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Create a Cassandra Source Distributed Connector
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.62
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev</br>  curl -vs --stderr - -X POST -H &#34;Content-Type: application/json&#34;</br>       --data @-</br>       &#34;http://fast-data-dev:8083/connectors&#34;</br></br>'>docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev
  curl -vs --stderr - -X POST -H &#34;Content-Type: application/json&#34;
       --data @-
       &#34;http://fast-data-dev:8083/connectors&#34;

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_1_2" class="trigger" data-tooltip-id="1_2" title="*   Trying 172.19.0.3...</br>* TCP_NODELAY set</br>* Connected to fast-data-dev (172.19.0.3) port 8083 (#0)</br>&gt; POST /connectors HTTP/1.1</br>&gt; Host: fast-data-dev:8083</br>&gt; User-Agent: curl/7.50.3</br>&gt; Accept: */*</br>&gt; Content-Type: application/json</br>&gt; Content-Length: 522</br>&gt; </br>} [522 bytes data]</br>* upload completely sent off: 522 out of 522 bytes</br>&lt; HTTP/1.1 201 Created</br>&lt; Date: Wed, 12 Oct 2016 21:57:12 GMT</br>&lt; Location: http://fast-data-dev:8083/connectors/cassandra-source</br>&lt; Content-Type: application/json</br>&lt; Content-Length: 511</br>&lt; Server: Jetty(9.2.12.v20150709)</br>&lt; </br>{ [511 bytes data]</br>{&#34;name&#34;:&#34;cassandra-source&#34;,&#34;config&#34;:{&#34;connector.class&#34;:&#34;com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector&#34;,&#34;tasks.max&#34;:&#34;1&#34;,&#34;connect.cassandra.key.space&#34;:&#34;source&#34;,&#34;connect.cassandra.import.route.query&#34;:&#34;INSERT INTO cassandra-source SELECT * FROM orders PK created&#34;,&#34;connect.cassandra.import.mode&#34;:&#34;incremental&#34;,&#34;connect.cassandra.contact.points&#34;:&#34;cassandra&#34;,&#34;connect.cassandra.username&#34;:&#34;cassandra&#34;,&#34;connect.cassandra.password&#34;:&#34;cassandra&#34;,&#34;name&#34;:&#34;cassandra-source&#34;},&#34;tasks&#34;:[]}* Curl_http_done: called premature == 0</br>* Connection #0 to host fast-data-dev left intact</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 3 out of 3
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        7.39 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header blue">
                    <div class="cell">
                        Setup Cassandra Sink Connector
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Create Sink Topic
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.59
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</br>  kafka-topics --zookeeper fast-data-dev:2181 --topic cassandra-sink --partition 1 --replication 1 --create</br></br>'>docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev
  kafka-topics --zookeeper fast-data-dev:2181 --topic cassandra-sink --partition 1 --replication 1 --create

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                        Created topic &#34;cassandra-sink&#34;.
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Create Cassandra Sink Table
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.11
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra</br>  cqlsh -u cassandra -p cassandra cassandra</br></br>'>docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra
  cqlsh -u cassandra -p cassandra cassandra

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Create a Cassandra Sink Distributed Connector
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.16
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev</br>  curl -vs --stderr - -X POST -H &#34;Content-Type: application/json&#34;</br>       --data @-</br>       &#34;http://fast-data-dev:8083/connectors&#34;</br></br>'>docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev
  curl -vs --stderr - -X POST -H &#34;Content-Type: application/json&#34;
       --data @-
       &#34;http://fast-data-dev:8083/connectors&#34;

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_2_2" class="trigger" data-tooltip-id="2_2" title="*   Trying 172.19.0.3...</br>* TCP_NODELAY set</br>* Connected to fast-data-dev (172.19.0.3) port 8083 (#0)</br>&gt; POST /connectors HTTP/1.1</br>&gt; Host: fast-data-dev:8083</br>&gt; User-Agent: curl/7.50.3</br>&gt; Accept: */*</br>&gt; Content-Type: application/json</br>&gt; Content-Length: 481</br>&gt; </br>} [481 bytes data]</br>* upload completely sent off: 481 out of 481 bytes</br>&lt; HTTP/1.1 201 Created</br>&lt; Date: Wed, 12 Oct 2016 21:57:18 GMT</br>&lt; Location: http://fast-data-dev:8083/connectors/cassandra-sink</br>&lt; Content-Type: application/json</br>&lt; Content-Length: 468</br>&lt; Server: Jetty(9.2.12.v20150709)</br>&lt; </br>{ [468 bytes data]</br>{&#34;name&#34;:&#34;cassandra-sink&#34;,&#34;config&#34;:{&#34;connector.class&#34;:&#34;com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector&#34;,&#34;tasks.max&#34;:&#34;1&#34;,&#34;topics&#34;:&#34;cassandra-sink&#34;,&#34;connect.cassandra.key.space&#34;:&#34;sink&#34;,&#34;connect.cassandra.export.route.query&#34;:&#34;INSERT INTO orders SELECT * FROM cassandra-sink&#34;,&#34;connect.cassandra.contact.points&#34;:&#34;cassandra&#34;,&#34;connect.cassandra.username&#34;:&#34;cassandra&#34;,&#34;connect.cassandra.password&#34;:&#34;cassandra&#34;,&#34;name&#34;:&#34;cassandra-sink&#34;},&#34;tasks&#34;:[]}* Curl_http_done: called premature == 0</br>* Connection #0 to host fast-data-dev left intact</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 3 out of 3
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        5.86 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header purple">
                    <div class="cell">
                        Test Cassandra Source Connector
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Read Entries from Topic
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        20.85
                    </div>
                    <div class="cell">
                        (ignore) 124
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='timeout 20 docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</br>  kafka-avro-console-consumer --zookeeper fast-data-dev:2181/confluent</br>                              --bootstrap-server fast-data-dev:9092</br>                              --topic cassandra-source --from-beginning --new-consumer</br>                              --property schema.registry.url=http://fast-data-dev:8081</br></br>'>timeout 20 docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        timeout 20 docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev
  kafka-avro-console-consumer --zookeeper fast-data-dev:2181/confluent
                              --bootstrap-server fast-data-dev:9092
                              --topic cassandra-source --from-beginning --new-consumer
                              --property schema.registry.url=http://fast-data-dev:8081

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_3_0" class="trigger" data-tooltip-id="3_0" title="{&#34;id&#34;:{&#34;int&#34;:1},&#34;created&#34;:{&#34;string&#34;:&#34;d3d64c60-90c6-11e6-a325-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:94.2},&#34;product&#34;:{&#34;string&#34;:&#34;OP-DAX-P-20150201-95.7&#34;},&#34;qty&#34;:{&#34;int&#34;:100}}</br>{&#34;id&#34;:{&#34;int&#34;:2},&#34;created&#34;:{&#34;string&#34;:&#34;d3d6e8a0-90c6-11e6-a325-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:99.5},&#34;product&#34;:{&#34;string&#34;:&#34;OP-DAX-C-20150201-100&#34;},&#34;qty&#34;:{&#34;int&#34;:100}}</br>{&#34;id&#34;:{&#34;int&#34;:3},&#34;created&#34;:{&#34;string&#34;:&#34;d3d736c0-90c6-11e6-a325-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:150.0},&#34;product&#34;:{&#34;string&#34;:&#34;FU-KOSPI-C-20150201-100&#34;},&#34;qty&#34;:{&#34;int&#34;:200}}</br>{&#34;id&#34;:{&#34;int&#34;:1},&#34;created&#34;:{&#34;string&#34;:&#34;d3d64c60-90c6-11e6-a325-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:94.2},&#34;product&#34;:{&#34;string&#34;:&#34;OP-DAX-P-20150201-95.7&#34;},&#34;qty&#34;:{&#34;int&#34;:100}}</br>{&#34;id&#34;:{&#34;int&#34;:2},&#34;created&#34;:{&#34;string&#34;:&#34;d3d6e8a0-90c6-11e6-a325-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:99.5},&#34;product&#34;:{&#34;string&#34;:&#34;OP-DAX-C-20150201-100&#34;},&#34;qty&#34;:{&#34;int&#34;:100}}</br>{&#34;id&#34;:{&#34;int&#34;:3},&#34;created&#34;:{&#34;string&#34;:&#34;d3d736c0-90c6-11e6-a325-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:150.0},&#34;product&#34;:{&#34;string&#34;:&#34;FU-KOSPI-C-20150201-100&#34;},&#34;qty&#34;:{&#34;int&#34;:200}}</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_3_0" class="trigger" data-tooltip-id="3_0" title="SLF4J: Class path contains multiple SLF4J bindings.</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-serde-tools/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/schema-registry/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</br>SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]</br>Processed a total of 6 messages</br></br>">view</button>
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 1 out of 1
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        20.85 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header gray">
                    <div class="cell">
                        Test Cassandra Sink Connector
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Write Entries into Topic
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.98
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm -i --network=kafkaconnectcassandra_default landoop/fast-data-dev</br>  kafka-avro-console-producer --broker-list fast-data-dev:9092</br>    --topic cassandra-sink --property schema.registry.url=&#34;http://fast-data-dev:8081&#34;</br>    --property</br>    value.schema=&#39;{&#34;type&#34;:&#34;record&#34;,&#34;name&#34;:&#34;myrecord&#34;,&#34;fields&#34;:[{&#34;name&#34;:&#34;id&#34;,&#34;type&#34;:&#34;int&#34;},{&#34;name&#34;:&#34;created&#34;, &#34;type&#34;: &#34;string&#34;}, {&#34;name&#34;:&#34;product&#34;, &#34;type&#34;: &#34;string&#34;}, {&#34;name&#34;:&#34;price&#34;, &#34;type&#34;: &#34;double&#34;}]}&#39;</br></br>'>docker run --rm -i --network=kafkaconnectcassandra_default landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm -i --network=kafkaconnectcassandra_default landoop/fast-data-dev
  kafka-avro-console-producer --broker-list fast-data-dev:9092
    --topic cassandra-sink --property schema.registry.url=&#34;http://fast-data-dev:8081&#34;
    --property
    value.schema=&#39;{&#34;type&#34;:&#34;record&#34;,&#34;name&#34;:&#34;myrecord&#34;,&#34;fields&#34;:[{&#34;name&#34;:&#34;id&#34;,&#34;type&#34;:&#34;int&#34;},{&#34;name&#34;:&#34;created&#34;, &#34;type&#34;: &#34;string&#34;}, {&#34;name&#34;:&#34;product&#34;, &#34;type&#34;: &#34;string&#34;}, {&#34;name&#34;:&#34;price&#34;, &#34;type&#34;: &#34;double&#34;}]}&#39;

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_4_0" class="trigger" data-tooltip-id="4_0" title="SLF4J: Class path contains multiple SLF4J bindings.</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-serde-tools/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/schema-registry/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</br>SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]</br></br>">view</button>
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Verify entries
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.81
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm -i --network=kafkaconnectcassandra_default landoop/cassandra</br>  cqlsh -u cassandra -p cassandra cassandra</br></br>'>docker run --rm -i --network=kafkaconnectcassandra_default landoop/cassandra</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm -i --network=kafkaconnectcassandra_default landoop/cassandra
  cqlsh -u cassandra -p cassandra cassandra

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_4_1" class="trigger" data-tooltip-id="4_1" title=" id | created             | price | product                         | qty</br>----+---------------------+-------+---------------------------------+------</br>  1 | 2016-05-06 13:53:00 |  94.2 |          OP-DAX-P-20150201-95.7 | null</br>  2 | 2016-05-06 13:54:00 |  99.5 |           OP-DAX-C-20150201-100 | null</br>  4 | 2016-05-06 13:56:00 |   150 |         FU-KOSPI-C-20150201-100 | null</br>  3 | 2016-05-06 13:55:00 | 10000 | FU-DATAMOUNTAINEER-20150201-100 | null</br></br>(4 rows)</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 2 out of 2
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        4.79 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header yellow">
                    <div class="cell">
                        Other Tests
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Read First 2000 Lines of Connect Logs
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        0.07
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker exec kafkaconnectcassandra_fast-data-dev_1 head -n2000 /var/log/connect-distributed.log</br></br>'>docker exec kafkaconnectcassandra_fast-data-dev_1 head -n2000 /var/log/connect-distributed.log</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker exec kafkaconnectcassandra_fast-data-dev_1 head -n2000 /var/log/connect-distributed.log

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_5_0" class="trigger" data-tooltip-id="5_0" title="SLF4J: Class path contains multiple SLF4J bindings.</br>SLF4J: Found binding in [jar:file:/extra-connect-jars/kafka-connect-twitter-0.1-develop-8624fbe-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-serde-tools/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-blockchain/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-bloomberg/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-cassandra/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-druid/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-elastic/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-hazelcast/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-hbase/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-hdfs/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-influxdb/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-jms/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-kudu/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-redis/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-rethink/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-voltdb/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-yahoo/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</br>[main] INFO org.apache.kafka.connect.runtime.distributed.DistributedConfig - DistributedConfig values: </br>	cluster = connect</br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	offset.storage.topic = connect-offsets</br>	ssl.truststore.password = null</br>	key.converter = class io.confluent.connect.avro.AvroConverter</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	config.storage.topic = connect-configs</br>	request.timeout.ms = 40000</br>	rest.advertised.host.name = null</br>	heartbeat.interval.ms = 3000</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	rest.port = 8083</br>	access.control.allow.origin = </br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	worker.unsync.backoff.ms = 300000</br>	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter</br>	send.buffer.bytes = 131072</br>	group.id = connect-cluster</br>	task.shutdown.graceful.timeout.ms = 5000</br>	rest.advertised.port = null</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	value.converter = class io.confluent.connect.avro.AvroConverter</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	worker.sync.timeout.ms = 3000</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	status.storage.topic = connect-statuses</br>	rest.host.name = null</br>	ssl.keystore.location = null</br>	offset.flush.timeout.ms = 5000</br>	ssl.cipher.suites = null</br>	offset.flush.interval.ms = 60000</br>	security.protocol = PLAINTEXT</br>	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter</br>	access.control.allow.methods = </br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br></br>[main] INFO org.eclipse.jetty.util.log - Logging initialized @6862ms</br>[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[main] INFO org.apache.kafka.connect.runtime.Connect - Kafka Connect starting</br>[main] INFO org.apache.kafka.connect.runtime.rest.RestServer - Starting REST server</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Herder starting</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Worker starting</br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 9223372036854775807</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 2147483647</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 9223372036854775807</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = producer-1</br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 2147483647</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.connect.storage.KafkaOffsetBackingStore - Starting KafkaOffsetBackingStore</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Starting KafkaBasedLog with topic connect-offsets</br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = producer-2</br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration group.id = connect-cluster was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = consumer-1</br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[main] INFO org.eclipse.jetty.server.Server - jetty-9.2.12.v20150709</br>[2016-10-12 21:56:16,030] INFO HV000001: Hibernate Validator 5.1.2.Final (org.hibernate.validator.internal.util.Version:27)</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Finished reading KafkaBasedLog for topic connect-offsets</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Started KafkaBasedLog for topic connect-offsets</br>[DistributedHerder] INFO org.apache.kafka.connect.storage.KafkaOffsetBackingStore - Finished reading offsets topic and starting KafkaOffsetBackingStore</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Worker started</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Starting KafkaBasedLog with topic connect-statuses</br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 0</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.StringSerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = producer-3</br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 0</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.StringSerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration group.id = connect-cluster was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = consumer-2</br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>Oct 12, 2016 9:56:16 PM org.glassfish.jersey.internal.Errors logErrors</br>WARNING: The following warnings have been detected: WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.</br>WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.</br>WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.</br>WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.</br></br>[main] INFO org.eclipse.jetty.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@71ad3d8a{/,null,AVAILABLE}</br>[main] INFO org.eclipse.jetty.server.ServerConnector - Started ServerConnector@7139bd31{HTTP/1.1}{0.0.0.0:8083}</br>[main] INFO org.eclipse.jetty.server.Server - Started @8985ms</br>[main] INFO org.apache.kafka.connect.runtime.rest.RestServer - REST server listening at http://172.19.0.3:8083/, advertising URL http://172.19.0.3:8083/</br>[main] INFO org.apache.kafka.connect.runtime.Connect - Kafka Connect started</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Finished reading KafkaBasedLog for topic connect-statuses</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Started KafkaBasedLog for topic connect-statuses</br>[DistributedHerder] INFO org.apache.kafka.connect.storage.KafkaConfigBackingStore - Starting KafkaConfigBackingStore</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Starting KafkaBasedLog with topic connect-configs</br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.StringSerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = producer-4</br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.StringSerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration group.id = connect-cluster was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = consumer-3</br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Finished reading KafkaBasedLog for topic connect-configs</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Started KafkaBasedLog for topic connect-configs</br>[DistributedHerder] INFO org.apache.kafka.connect.storage.KafkaConfigBackingStore - Started KafkaConfigBackingStore</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Herder started</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 1</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-f90335ad-950d-46fe-8596-ca126b83c717&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=-1, connectorIds=[], taskIds=[]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset -1</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[CLASSPATH traversal thread.] INFO org.reflections.Reflections - Reflections took 53588 ms to scan 1729 urls, producing 24326 keys and 198597 values </br>[KafkaBasedLog Work Thread - connect-configs] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Connector cassandra-source config updated</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Rebalance started</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished stopping tasks in preparation for rebalance</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 2</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-f90335ad-950d-46fe-8596-ca126b83c717&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=1, connectorIds=[cassandra-source], taskIds=[]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset 1</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-source of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[qtp330128595-34] INFO org.apache.kafka.connect.runtime.rest.RestServer - 172.19.0.4 - - [12/Oct/2016:21:57:12 +0000] &#34;POST /connectors HTTP/1.1&#34; 201 511  848</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-source with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Starting Cassandra source task with {connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.import.mode=incremental, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.username=cassandra}.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Setting task configurations for 1 workers.</br>[KafkaBasedLog Work Thread - connect-configs] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Tasks [cassandra-source-0] configs updated</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Rebalance started</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopped connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished stopping tasks in preparation for rebalance</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 3</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-f90335ad-950d-46fe-8596-ca126b83c717&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=3, connectorIds=[cassandra-source], taskIds=[cassandra-source-0]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset 3</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-source of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-source with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Starting Cassandra source task with {connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.import.mode=incremental, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.username=cassandra}.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Setting task configurations for 1 workers.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.TaskConfig - TaskConfig values: </br>	task.class = class com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated task cassandra-source-0 with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSource - CassandraConfigSource values: </br>	connect.cassandra.import.mode = incremental</br>	connect.cassandra.key.space = source</br>	connect.cassandra.import.source.allow.filtering = true</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.import.route.query = INSERT INTO cassandra-source SELECT * FROM orders PK created</br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.import.poll.interval = 60000</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.source.task.batch.size = 100</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.source.task.buffer.size = 10000</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.assigned.tables = orders</br>	connect.cassandra.max.retires = 20</br></br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - </br></br>    ____        __        __  ___                  __        _</br>   / __ \____ _/ /_____ _/  |/  /___  __  ______  / /_____ _(_)___  ___  ___  _____</br>  / / / / __ `/ __/ __ `/ /|_/ / __ \/ / / / __ \/ __/ __ `/ / __ \/ _ \/ _ \/ ___/</br> / /_/ / /_/ / /_/ /_/ / /  / / /_/ / /_/ / / / / /_/ /_/ / / / / /  __/  __/ /</br>/_____/\__,_/\__/\__,_/_/  /_/\____/\__,_/_/ /_/\__/\__,_/_/_/ /_/\___/\___/_/</br>       ______                                __           _____</br>      / ____/___ _______________ _____  ____/ /________ _/ ___/____  __  _______________</br>     / /   / __ `/ ___/ ___/ __ `/ __ \/ __  / ___/ __ `/\__ \/ __ \/ / / / ___/ ___/ _ \</br>    / /___/ /_/ (__  |__  ) /_/ / / / / /_/ / /  / /_/ /___/ / /_/ / /_/ / /  / /__/  __/</br>    \____/\__,_/____/____/\__,_/_/ /_/\__,_/_/   \__,_//____/\____/\__,_/_/   \___/\___/</br></br> By Andrew Stevenson.</br>[pool-1-thread-1] INFO com.datastax.driver.core.NettyUtil - Found Netty&#39;s native epoll transport in the classpath, using it</br>[pool-1-thread-1] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name &#39;datacenter1&#39; for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)</br>[pool-1-thread-1] INFO com.datastax.driver.core.Cluster - New Cassandra host cassandra/172.19.0.2:9042 added</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Connection to Cassandra established.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Received setting:</br> CassandraSourceSetting(com.datamountaineer.connector.config.Config@6f01b7b0,source,false,Some(created),60000,CassandraConfigSource({connect.cassandra.import.mode=incremental, connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, task.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.assigned.tables=orders, connect.cassandra.username=cassandra}),ThrowErrorPolicy(),20)</br>[pool-1-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Source task WorkerSourceTask{id=cassandra-source-0} finished initialization and start</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Query SELECT * FROM source.orders WHERE created &gt; maxTimeuuid(?) AND created &lt;= minTimeuuid(?)  ALLOW FILTERING executing with bindings (1900-01-01 00:00:00.000Z, 2016-10-12 21:57:15.980Z).</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying returning results for source.orders.</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:57:11.334Z</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:57:11.338Z</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:57:11.340Z</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.queues.QueueHelpers$ - Found 2. Draining entries to batchSize 100.</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Processed 3 rows for table cassandra-source.orders</br>[KafkaBasedLog Work Thread - connect-configs] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Connector cassandra-sink config updated</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Rebalance started</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopped connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping task cassandra-source-0</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Stopping Cassandra source.</br>[qtp330128595-44] INFO org.apache.kafka.connect.runtime.rest.RestServer - 172.19.0.4 - - [12/Oct/2016:21:57:18 +0000] &#34;POST /connectors HTTP/1.1&#34; 201 468  523</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Shutting down Queries.</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying stopped for source.cassandra-source.</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - All stopped.</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Shutting down Cassandra driver connections.</br>[pool-1-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Finished WorkerSourceTask{id=cassandra-source-0} commitOffsets successfully in 2261 ms</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished stopping tasks in preparation for rebalance</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 4</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-f90335ad-950d-46fe-8596-ca126b83c717&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=4, connectorIds=[cassandra-source, cassandra-sink], taskIds=[cassandra-source-0]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset 4</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-source of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-source with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Starting Cassandra source task with {connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.import.mode=incremental, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.username=cassandra}.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Setting task configurations for 1 workers.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>	tasks.max = 1</br>	name = cassandra-sink</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-sink of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-sink with version 1 of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSink - CassandraConfigSink values: </br>	connect.cassandra.key.space = sink</br>	connect.cassandra.export.route.query = INSERT INTO orders SELECT * FROM cassandra-sink</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.max.retires = 20</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>	tasks.max = 1</br>	name = cassandra-sink</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector - Setting task configurations for 1 workers.</br>[KafkaBasedLog Work Thread - connect-configs] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Tasks [cassandra-source-0, cassandra-sink-0] configs updated</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.TaskConfig - TaskConfig values: </br>	task.class = class com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated task cassandra-source-0 with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Rebalance started</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping connector cassandra-source</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSource - CassandraConfigSource values: </br>	connect.cassandra.import.mode = incremental</br>	connect.cassandra.key.space = source</br>	connect.cassandra.import.source.allow.filtering = true</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.import.route.query = INSERT INTO cassandra-source SELECT * FROM orders PK created</br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.import.poll.interval = 60000</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.source.task.batch.size = 100</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.source.task.buffer.size = 10000</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.assigned.tables = orders</br>	connect.cassandra.max.retires = 20</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopped connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopped connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping task cassandra-source-0</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - </br></br>    ____        __        __  ___                  __        _</br>   / __ \____ _/ /_____ _/  |/  /___  __  ______  / /_____ _(_)___  ___  ___  _____</br>  / / / / __ `/ __/ __ `/ /|_/ / __ \/ / / / __ \/ __/ __ `/ / __ \/ _ \/ _ \/ ___/</br> / /_/ / /_/ / /_/ /_/ / /  / / /_/ / /_/ / / / / /_/ /_/ / / / / /  __/  __/ /</br>/_____/\__,_/\__/\__,_/_/  /_/\____/\__,_/_/ /_/\__/\__,_/_/_/ /_/\___/\___/_/</br>       ______                                __           _____</br>      / ____/___ _______________ _____  ____/ /________ _/ ___/____  __  _______________</br>     / /   / __ `/ ___/ ___/ __ `/ __ \/ __  / ___/ __ `/\__ \/ __ \/ / / / ___/ ___/ _ \</br>    / /___/ /_/ (__  |__  ) /_/ / / / / /_/ / /  / /_/ /___/ / /_/ / /_/ / /  / /__/  __/</br>    \____/\__,_/____/____/\__,_/_/ /_/\__,_/_/   \__,_//____/\____/\__,_/_/   \___/\___/</br></br> By Andrew Stevenson.</br>[pool-1-thread-1] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name &#39;datacenter1&#39; for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)</br>[pool-1-thread-1] INFO com.datastax.driver.core.Cluster - New Cassandra host cassandra/172.19.0.2:9042 added</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Connection to Cassandra established.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Received setting:</br> CassandraSourceSetting(com.datamountaineer.connector.config.Config@32991ec,source,false,Some(created),60000,CassandraConfigSource({connect.cassandra.import.mode=incremental, connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, task.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.assigned.tables=orders, connect.cassandra.username=cassandra}),ThrowErrorPolicy(),20)</br>[pool-1-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Source task WorkerSourceTask{id=cassandra-source-0} finished initialization and start</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Stopping Cassandra source.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Shutting down Queries.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying stopped for source.cassandra-source.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - All stopped.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Shutting down Cassandra driver connections.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished stopping tasks in preparation for rebalance</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 5</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-f90335ad-950d-46fe-8596-ca126b83c717&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=6, connectorIds=[cassandra-source, cassandra-sink], taskIds=[cassandra-source-0, cassandra-sink-0]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset 6</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-source of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-source with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Starting Cassandra source task with {connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.import.mode=incremental, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.username=cassandra}.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Setting task configurations for 1 workers.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>	tasks.max = 1</br>	name = cassandra-sink</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-sink of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-sink with version 1 of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSink - CassandraConfigSink values: </br>	connect.cassandra.key.space = sink</br>	connect.cassandra.export.route.query = INSERT INTO orders SELECT * FROM cassandra-sink</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.max.retires = 20</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>	tasks.max = 1</br>	name = cassandra-sink</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector - Setting task configurations for 1 workers.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.TaskConfig - TaskConfig values: </br>	task.class = class com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated task cassandra-source-0 with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting task cassandra-sink-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.TaskConfig - TaskConfig values: </br>	task.class = class com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkTask</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating task cassandra-sink-0</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSource - CassandraConfigSource values: </br>	connect.cassandra.import.mode = incremental</br>	connect.cassandra.key.space = source</br>	connect.cassandra.import.source.allow.filtering = true</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.import.route.query = INSERT INTO cassandra-source SELECT * FROM orders PK created</br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.import.poll.interval = 60000</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.source.task.batch.size = 100</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.source.task.buffer.size = 10000</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.assigned.tables = orders</br>	connect.cassandra.max.retires = 20</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkTask - Task initialising</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated task cassandra-sink-0 with version 1 of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkTask</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - </br></br>    ____        __        __  ___                  __        _</br>   / __ \____ _/ /_____ _/  |/  /___  __  ______  / /_____ _(_)___  ___  ___  _____</br>  / / / / __ `/ __/ __ `/ /|_/ / __ \/ / / / __ \/ __/ __ `/ / __ \/ _ \/ _ \/ ___/</br> / /_/ / /_/ / /_/ /_/ / /  / / /_/ / /_/ / / / / /_/ /_/ / / / / /  __/  __/ /</br>/_____/\__,_/\__/\__,_/_/  /_/\____/\__,_/_/ /_/\__/\__,_/_/_/ /_/\___/\___/_/</br>       ______                                __           _____</br>      / ____/___ _______________ _____  ____/ /________ _/ ___/____  __  _______________</br>     / /   / __ `/ ___/ ___/ __ `/ __ \/ __  / ___/ __ `/\__ \/ __ \/ / / / ___/ ___/ _ \</br>    / /___/ /_/ (__  |__  ) /_/ / / / / /_/ / /  / /_/ /___/ / /_/ / /_/ / /  / /__/  __/</br>    \____/\__,_/____/____/\__,_/_/ /_/\__,_/_/   \__,_//____/\____/\__,_/_/   \___/\___/</br></br> By Andrew Stevenson.</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cassandra-sink</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = consumer-4</br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cassandra-sink</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSink - CassandraConfigSink values: </br>	connect.cassandra.key.space = sink</br>	connect.cassandra.export.route.query = INSERT INTO orders SELECT * FROM cassandra-sink</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.max.retires = 20</br></br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkTask - </br>    ____        __        __  ___                  __        _</br>   / __ \____ _/ /_____ _/  |/  /___  __  ______  / /_____ _(_)___  ___  ___  _____</br>  / / / / __ `/ __/ __ `/ /|_/ / __ \/ / / / __ \/ __/ __ `/ / __ \/ _ \/ _ \/ ___/</br> / /_/ / /_/ / /_/ /_/ / /  / / /_/ / /_/ / / / / /_/ /_/ / / / / /  __/  __/ /</br>/_____/\__,_/\__/\__,_/_/  /_/\____/\__,_/_/ /_/\__/\__,_/_/_/ /_/\___/\___/_/</br>       ______                                __           _____ _       __</br>      / ____/___ _______________ _____  ____/ /________ _/ ___/(_)___  / /__</br>     / /   / __ `/ ___/ ___/ __ `/ __ \/ __  / ___/ __ `/\__ \/ / __ \/ //_/</br>    / /___/ /_/ (__  |__  ) /_/ / / / / /_/ / /  / /_/ /___/ / / / / / ,&lt;</br>    \____/\__,_/____/____/\__,_/_/ /_/\__,_/_/   \__,_//____/_/_/ /_/_/|_|</br></br> By Andrew Stevenson.</br>[pool-1-thread-1] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name &#39;datacenter1&#39; for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)</br>[pool-1-thread-1] INFO com.datastax.driver.core.Cluster - New Cassandra host cassandra/172.19.0.2:9042 added</br>[pool-1-thread-2] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name &#39;datacenter1&#39; for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)</br>[pool-1-thread-2] INFO com.datastax.driver.core.Cluster - New Cassandra host cassandra/172.19.0.2:9042 added</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Connection to Cassandra established.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Received setting:</br> CassandraSourceSetting(com.datamountaineer.connector.config.Config@62b9b9ae,source,false,Some(created),60000,CassandraConfigSource({connect.cassandra.import.mode=incremental, connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, task.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.assigned.tables=orders, connect.cassandra.username=cassandra}),ThrowErrorPolicy(),20)</br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraJsonWriter - Initialising Cassandra writer.</br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraJsonWriter - Preparing statements for cassandra-sink.</br>[pool-1-thread-2] INFO org.apache.kafka.connect.runtime.WorkerSinkTask - Sink task WorkerSinkTask{id=cassandra-sink-0} finished initialization and start</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cassandra-sink.</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group connect-cassandra-sink</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cassandra-sink</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cassandra-sink with generation 1</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [cassandra-sink-0] for group connect-cassandra-sink</br>[pool-1-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Source task WorkerSourceTask{id=cassandra-source-0} finished initialization and start</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Query SELECT * FROM source.orders WHERE created &gt; maxTimeuuid(?) AND created &lt;= minTimeuuid(?)  ALLOW FILTERING executing with bindings (1900-01-01 00:00:00.000Z, 2016-10-12 21:57:26.430Z).</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying returning results for source.orders.</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:57:11.334Z</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.queues.QueueHelpers$ - Found 1. Draining entries to batchSize 100.</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:57:11.338Z</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:57:11.340Z</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.queues.QueueHelpers$ - Found 1. Draining entries to batchSize 100.</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Processed 3 rows for table cassandra-source.orders</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.queues.QueueHelpers$ - Found 1. Draining entries to batchSize 100.</br>[pool-4-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Finished WorkerSourceTask{id=cassandra-source-0} commitOffsets successfully in 3 ms</br>[pool-1-thread-2] INFO org.apache.kafka.connect.runtime.WorkerSinkTask - WorkerSinkTask{id=cassandra-sink-0} Committing offsets</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Query SELECT * FROM source.orders WHERE created &gt; maxTimeuuid(?) AND created &lt;= minTimeuuid(?)  ALLOW FILTERING executing with bindings (2016-10-12 21:57:11.340Z, 2016-10-12 21:58:26.431Z).</br>[ForkJoinPool-1-worker-5] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying returning results for source.orders.</br>[ForkJoinPool-1-worker-5] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Processed 0 rows for table cassandra-source.orders</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 1 out of 1
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        0.07 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header orange">
                    <div class="cell">
                        Clean-up Containers
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Docker Compose Down
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        10.93
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose down</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose down
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_6_0" class="trigger" data-tooltip-id="6_0" title="Stopping kafkaconnectcassandra_fast-data-dev_1 ... </br>Stopping kafkaconnectcassandra_cassandra_1 ... </br>[2A[2KStopping kafkaconnectcassandra_fast-data-dev_1 ... done[2B[1A[2KStopping kafkaconnectcassandra_cassandra_1 ... done[1BRemoving kafkaconnectcassandra_fast-data-dev_1 ... </br>Removing kafkaconnectcassandra_cassandra_1 ... </br>[2A[2KRemoving kafkaconnectcassandra_fast-data-dev_1 ... done[2B[1A[2KRemoving kafkaconnectcassandra_cassandra_1 ... done[1BRemoving network kafkaconnectcassandra_default</br></br>">view</button>
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 1 out of 1
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        10.93 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div>
            </div>

        </div>

        <script src="https://code.jquery.com/jquery-1.12.2.min.js"></script>
        <script src="https://code.jquery.com/ui/1.11.4/jquery-ui.min.js"></script>
        <link rel="stylesheet" href="https://code.jquery.com/ui/1.11.4/themes/smoothness/jquery-ui.css">

        <script>
         $(function () {
             //show
             $(document).on('click', '.trigger', function () {
                 $(this).addClass("on");
                 $(this).tooltip({
                     items: '.trigger.on',
                     position: {
                         my: "left+30 center",
                         at: "right center",
                         collision: "flip"
                     },
                     content: function(){
                         var element = $( this );
                         return element.attr('title')
                     }
                 });
                 $(this).trigger('mouseenter');
             });
             //hide
             $(document).on('click', '.trigger.on', function () {
                 $(this).tooltip('close');
                 $(this).removeClass("on");
             });
             //prevent mouseout and other related events from firing their handlers
             $(".trigger").on('mouseout', function (e) {
                 e.stopImmediatePropagation();
             });
         });
        </script>
    </body>
</html>
