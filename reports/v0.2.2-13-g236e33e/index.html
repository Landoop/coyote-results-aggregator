<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>Coyote Tester | kafka-connect-cassandra v0.2.2-13-g236e33e | Results</title>

    </head>
    <body>

        <div id="testResults" style="display:inline;width:33%"></div>
        <div id="testTimes" style="display:inline;width:66%"></div>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.4.4/d3.min.js"></script>
        <script src="https://storage.googleapis.com/artifacts-landoop/d3pie.min.js"></script>
        <script>
         var pie = new d3pie("testResults", {
             "header": {
                 "title": {
                     "text": "all passed",
                     "color": "#fffefe",
                     "fontSize": 34,
                     "font": "sans"
                 },
                 "subtitle": {
                     "text": "kafka-connect-cassandra v0.2.2-13-g236e33e",
                     "color": "#E8E6E6",
                     "fontSize": 14,
                     "font": "sans"
                 },
                 "location": "pie-center",
                 "titleSubtitlePadding": 10
             },
             "footer": {
                "text": "Coyote-tester, part of Landoopâ„¢ test-suite. 2016 Oct 12, Wed, 21:56 UTC",
                "color": "#E8E6E6",
                "fontSize": 14,
                "font": "open sans",
                "location": "bottom-left"
             },
             "size": {
                 "canvasHeight": 375,
                 "canvasWidth": 500,
                 "pieInnerRadius": "72%",
                 "pieOuterRadius": "92%"
             },
             "data": {
                 "sortOrder": "label-desc",
                 "content": [
                     {
                         "label": "failed",
                         "value": 0,
                         "color": "#e21515"
                     },
                     {
                         "label": "passed",
                         "value": 15,
                         "color": "#64a61f"
                     }
                 ]
             },
             "labels": {
                 "outer": {
                     "format": "label-percentage1",
                     "pieDistance": 25
                 },
                 "inner": {
                     "format": "none"
                 },
                 "mainLabel": {
                     "color": "#ffffff",
                     "fontSize": 16
                 },
                 "percentage": {
                     "color": "#919191",
                     "fontSize": 16,
                     "decimalPlaces": 1
                 },
                 "value": {
                     "color": "#cccc43",
                     "fontSize": 16
                 },
                 "lines": {
                     "enabled": true,
                     "color": "#777777"
                 },
                 "truncation": {
                     "enabled": true
                 }
             },
             "effects": {
                 "pullOutSegmentOnClick": {
                     "effect": "linear",
                     "speed": 400,
                     "size": 8
                 }
             },
             "misc": {
                 "colors": {
                     "background": "#2b2b2b",
                     "segmentStroke": "#f6f6f6"
                 }
             }
         });
        </script>
        <script>
         var pie = new d3pie("testTimes", {
             "header": {
                 "title": {
                     "text": "55 s",
                     "color": "#fffefe",
                     "fontSize": 34,
                     "font": "sans"
             },
                 "subtitle": {
                     "text": "total time",
                     "color": "#999999",
                     "fontSize": 14,
                     "font": "sans"
                 },
                 "location": "pie-center",
                 "titleSubtitlePadding": 10
             },
             "footer": {
                "text": "",
                "color": "#999999",
                "fontSize": 10,
                "font": "open sans",
                "location": "bottom-left"
             },
             "size": {
                 "canvasHeight": 375,
                 "canvasWidth": 700,
                 "pieInnerRadius": "72%",
                 "pieOuterRadius": "85%"
             },
             "data": {
                 "sortOrder": "label-desc",
                 "smallSegmentGrouping": {
                     "enabled": true,
                     "value": 3
                 },
                 "content": [
                     {
                         "label": "Setup Containers, Docker Compose Pull",
                         "value": 1.730730938,
                         "color": "#2383c1"
                     },{
                         "label": "Setup Containers, Build Docker Images",
                         "value": 0.45782582400000005,
                         "color": "#64a61f"
                     },{
                         "label": "Setup Containers, Docker Compose Up",
                         "value": 1.239965001,
                         "color": "#7b6788"
                     },{
                         "label": "Setup Containers, Check docker compose log",
                         "value": 0.544226862,
                         "color": "#a05c56"
                     },{
                         "label": "Setup Cassandra Source Connector, Create Source Topic",
                         "value": 3.060530406,
                         "color": "#961919"
                     },{
                         "label": "Setup Cassandra Source Connector, Create Cassandra Source Table and Data",
                         "value": 2.505171817,
                         "color": "#d8d239"
                     },{
                         "label": "Setup Cassandra Source Connector, Create a Cassandra Source Distributed Connector",
                         "value": 1.6204587350000001,
                         "color": "#e98125"
                     },{
                         "label": "Setup Cassandra Sink Connector, Create Sink Topic",
                         "value": 2.325209225,
                         "color": "#d0743c"
                     },{
                         "label": "Setup Cassandra Sink Connector, Create Cassandra Sink Table",
                         "value": 1.54853191,
                         "color": "#635122"
                     },{
                         "label": "Setup Cassandra Sink Connector, Create a Cassandra Sink Distributed Connector",
                         "value": 1.171980666,
                         "color": "#6ada6a"
                     },{
                         "label": "Test Cassandra Source Connector, Read Entries from Topic",
                         "value": 20.980279149,
                         "color": "#0b6197"
                     },{
                         "label": "Test Cassandra Sink Connector, Write Entries into Topic",
                         "value": 3.914153797,
                         "color": "#7c9058"
                     },{
                         "label": "Test Cassandra Sink Connector, Verify entries",
                         "value": 2.254827405,
                         "color": "#207f32"
                     },{
                         "label": "Other Tests, Read First 2000 Lines of Connect Logs",
                         "value": 0.05403286400000001,
                         "color": "#44b9af"
                     },{
                         "label": "Clean-up Containers, Docker Compose Down",
                         "value": 11.633050628,
                         "color": "#2383c1"
                     },
                 ]
             },
             "labels": {
                 "outer": {
                     "format": "label-percentage1",
                     "pieDistance": 25
                 },
                 "inner": {
                     "format": "none"
                 },
                 "mainLabel": {
                     "color": "#ffffff",
                     "fontSize": 12
                 },
                 "percentage": {
                     "color": "#919191",
                     "fontSize": 12,
                     "decimalPlaces": 1
                 },
                 "value": {
                     "color": "#cccc43",
                     "fontSize": 12
                 },
                 "lines": {
                     "enabled": true,
                     "color": "#777777"
                 },
                 "truncation": {
                     "enabled": true
                 }
             },
             "effects": {
                 "pullOutSegmentOnClick": {
                     "effect": "linear",
                     "speed": 400,
                     "size": 8
                 }
             },
             "misc": {
                 "colors": {
                     "background": "#2b2b2b",
                     "segmentStroke": "#f6f6f6"
                 }
             }
         });
        </script>

        <style type="text/css">
         body {
             font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial;
             font-size: 14px;
             line-height: 20px;
             font-weight: 400;
             color: #3b3b3b;
             -webkit-font-smoothing: antialiased;
             font-smoothing: antialiased;
             background: #2b2b2b;
         }

         .wrapper {
             margin: 0 auto;
             padding: 40px;
             /*max-width: 800px;*/
         }

         div.ui-tooltip {
             color: red;
             border-radius: 20px;
             /*font: bold 12px "Helvetica Neue", Sans-Serif;*/
             /*text-transform: uppercase;*/
             box-shadow: 0 0 7px black;
             /*width: 400px;*/
             word-wrap: "normal";
             max-width: 900px;
         }

         .ui-tooltip-content {
             color: black;
             font: 11px Consolas, "Liberation Mono", Menlo, Courier, monospace;
             word-wrap: "normal";
             /*max-width: 900px;*/
         }

         .table {
             margin: 0 0 40px 0;
             width: 100%;
             box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2);
             display: table;
         }

         @media screen and (max-width: 90%) {
             .table {
                 display: block;
             }
         }

         .row {
             display: table-row;
             background: #f6f6f6;
         }

         .row:nth-of-type(odd) {
             background: #e9e9e9;
         }

         .row.header {
             font-weight: 900;
             color: #ffffff;
             background: #ea6153;
         }
         .row.green {
             background: #27ae60;
         }
         .row.blue {
             background: #2980b9;
         }
         .row.purple {
             background: #8e44ad;
         }
         .row.gray {
             background: #2c3e50;
         }
         .row.yellow {
             background: #f1c40f;
         }
         .row.orange {
             background: #d35400;
         }
         .row.turquoise {
             background: #1abc9c;
         }

         @media screen and (max-width: 90%) {
             .row {
                 padding: 8px 0;
                 display: block;
             }
         }

         .cell {
             padding: 6px 12px;
             display: table-cell;
         }

         .cell.red {
             background: #ea6153;
         }

         .cell.green {
             background: #27ae60;
         }

         .cell.skip {
             background: #2b2b2b;
         }

         .cell.center {
             text-align: center;
         }

         .cell.width12 {
             width: 12%;
             max-width: 10px;
         }
         @media screen and (max-width: 90%) {
             .cell {
                 padding: 2px 12px;
                 display: block;
             }
         }
         /* .hideContent {overflow:hidden;line-height:1em;height:2em;}
            .showContent {line-height:1em;height:auto;}
          */
        </style>

        <div class="wrapper">

            <div class="table">
            <div class="row header">
                    <div class="cell">
                        Setup Containers
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Docker Compose Pull
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.73
                    </div>
                    <div class="cell">
                        (ignore) 1
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose pull</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose pull
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                        Pulling repository docker.io/landoop/cassandra
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_0" class="trigger" data-tooltip-id="0_0" title="Pulling cassandra (landoop/cassandra:latest)...</br>Error: image landoop/cassandra:latest not found</br></br>">view</button>
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Build Docker Images
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        0.46
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose build</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose build
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_1" class="trigger" data-tooltip-id="0_1" title="Step 1 : FROM cassandra:latest</br> ---&gt; a552f6550254</br>Step 2 : MAINTAINER Marios Andreopoulos &lt;marios@landoop.com&gt;</br> ---&gt; Using cache</br> ---&gt; e58ed2491a79</br>Step 3 : RUN sed -e &#39;s/authenticator: AllowAllAuthenticator/authenticator: PasswordAuthenticator/&#39;         -i /etc/cassandra/cassandra.yaml</br> ---&gt; Using cache</br> ---&gt; 27808c1c0b3c</br>Successfully built 27808c1c0b3c</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_1" class="trigger" data-tooltip-id="0_1" title="Building cassandra</br>fast-data-dev uses an image, skipping</br></br>">view</button>
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Docker Compose Up
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.24
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose up -d</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose up -d
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_2" class="trigger" data-tooltip-id="0_2" title="Creating network &#34;kafkaconnectcassandra_default&#34; with the default driver</br>Creating kafkaconnectcassandra_cassandra_1</br>Creating kafkaconnectcassandra_fast-data-dev_1</br></br>">view</button>
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Check docker compose log
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        0.54
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose logs</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose logs
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_0_3" class="trigger" data-tooltip-id="0_3" title="Attaching to kafkaconnectcassandra_fast-data-dev_1, kafkaconnectcassandra_cassandra_1</br>[33mcassandra_1      |[0m INFO  21:52:50 Configuration location: file:/etc/cassandra/cassandra.yaml</br>[33mcassandra_1      |[0m INFO  21:52:51 Node configuration:[allocate_tokens_for_keyspace=null; authenticator=PasswordAuthenticator; authorizer=AllowAllAuthorizer; auto_bootstrap=true; auto_snapshot=true; batch_size_fail_threshold_in_kb=50; batch_size_warn_threshold_in_kb=5; batchlog_replay_throttle_in_kb=1024; broadcast_address=172.19.0.2; broadcast_rpc_address=172.19.0.2; buffer_pool_use_heap_if_exhausted=true; cas_contention_timeout_in_ms=1000; cdc_enabled=false; cdc_free_space_check_interval_ms=250; cdc_raw_directory=null; cdc_total_space_in_mb=null; client_encryption_options=&lt;REDACTED&gt;; cluster_name=Test Cluster; column_index_cache_size_in_kb=2; column_index_size_in_kb=64; commit_failure_policy=stop; commitlog_compression=null; commitlog_directory=/var/lib/cassandra/commitlog; commitlog_max_compression_buffers_in_pool=3; commitlog_periodic_queue_size=-1; commitlog_segment_size_in_mb=32; commitlog_sync=periodic; commitlog_sync_batch_window_in_ms=null; commitlog_sync_period_in_ms=10000; commitlog_total_space_in_mb=null; compaction_large_partition_warning_threshold_mb=100; compaction_throughput_mb_per_sec=16; concurrent_compactors=null; concurrent_counter_writes=32; concurrent_materialized_view_writes=32; concurrent_reads=32; concurrent_replicates=null; concurrent_writes=32; counter_cache_keys_to_save=2147483647; counter_cache_save_period=7200; counter_cache_size_in_mb=null; counter_write_request_timeout_in_ms=5000; credentials_cache_max_entries=1000; credentials_update_interval_in_ms=-1; credentials_validity_in_ms=2000; cross_node_timeout=false; data_file_directories=[Ljava.lang.String;@29176cc1; disk_access_mode=auto; disk_failure_policy=stop; disk_optimization_estimate_percentile=0.95; disk_optimization_page_cross_chance=0.1; disk_optimization_strategy=ssd; dynamic_snitch=true; dynamic_snitch_badness_threshold=0.1; dynamic_snitch_reset_interval_in_ms=600000; dynamic_snitch_update_interval_in_ms=100; enable_scripted_user_defined_functions=false; enable_user_defined_functions=false; enable_user_defined_functions_threads=true; encryption_options=null; endpoint_snitch=SimpleSnitch; file_cache_size_in_mb=null; gc_log_threshold_in_ms=200; gc_warn_threshold_in_ms=1000; hinted_handoff_disabled_datacenters=[]; hinted_handoff_enabled=true; hinted_handoff_throttle_in_kb=1024; hints_compression=null; hints_directory=null; hints_flush_period_in_ms=10000; incremental_backups=false; index_interval=null; index_summary_capacity_in_mb=null; index_summary_resize_interval_in_minutes=60; initial_token=null; inter_dc_stream_throughput_outbound_megabits_per_sec=200; inter_dc_tcp_nodelay=false; internode_authenticator=null; internode_compression=dc; internode_recv_buff_size_in_bytes=null; internode_send_buff_size_in_bytes=null; key_cache_keys_to_save=2147483647; key_cache_save_period=14400; key_cache_size_in_mb=null; listen_address=172.19.0.2; listen_interface=null; listen_interface_prefer_ipv6=false; listen_on_broadcast_address=false; max_hint_window_in_ms=10800000; max_hints_delivery_threads=2; max_hints_file_size_in_mb=128; max_mutation_size_in_kb=null; max_streaming_retries=3; max_value_size_in_mb=256; memtable_allocation_type=heap_buffers; memtable_cleanup_threshold=null; memtable_flush_writers=1; memtable_heap_space_in_mb=null; memtable_offheap_space_in_mb=null; min_free_space_per_drive_in_mb=50; native_transport_max_concurrent_connections=-1; native_transport_max_concurrent_connections_per_ip=-1; native_transport_max_frame_size_in_mb=256; native_transport_max_threads=128; native_transport_port=9042; native_transport_port_ssl=null; num_tokens=256; otc_coalescing_strategy=TIMEHORIZON; otc_coalescing_window_us=200; partitioner=org.apache.cassandra.dht.Murmur3Partitioner; permissions_cache_max_entries=1000; permissions_update_interval_in_ms=-1; permissions_validity_in_ms=2000; phi_convict_threshold=8.0; prepared_statements_cache_size_mb=null; range_request_timeout_in_ms=10000; read_request_timeout_in_ms=5000; request_scheduler=org.apache.cassandra.scheduler.NoScheduler; request_scheduler_id=null; request_scheduler_options=null; request_timeout_in_ms=10000; role_manager=CassandraRoleManager; roles_cache_max_entries=1000; roles_update_interval_in_ms=-1; roles_validity_in_ms=2000; row_cache_class_name=org.apache.cassandra.cache.OHCProvider; row_cache_keys_to_save=2147483647; row_cache_save_period=0; row_cache_size_in_mb=0; rpc_address=0.0.0.0; rpc_interface=null; rpc_interface_prefer_ipv6=false; rpc_keepalive=true; rpc_listen_backlog=50; rpc_max_threads=2147483647; rpc_min_threads=16; rpc_port=9160; rpc_recv_buff_size_in_bytes=null; rpc_send_buff_size_in_bytes=null; rpc_server_type=sync; saved_caches_directory=/var/lib/cassandra/saved_caches; seed_provider=org.apache.cassandra.locator.SimpleSeedProvider{seeds=172.19.0.2}; server_encryption_options=&lt;REDACTED&gt;; snapshot_before_compaction=false; ssl_storage_port=7001; sstable_preemptive_open_interval_in_mb=50; start_native_transport=true; start_rpc=false; storage_port=7000; stream_throughput_outbound_megabits_per_sec=200; streaming_socket_timeout_in_ms=86400000; thrift_framed_transport_size_in_mb=15; thrift_max_message_length_in_mb=16; thrift_prepared_statements_cache_size_mb=null; tombstone_failure_threshold=100000; tombstone_warn_threshold=1000; tracetype_query_ttl=86400; tracetype_repair_ttl=604800; transparent_data_encryption_options=org.apache.cassandra.config.TransparentDataEncryptionOptions@2f177a4b; trickle_fsync=false; trickle_fsync_interval_in_kb=10240; truncate_request_timeout_in_ms=60000; unlogged_batch_across_partitions_warn_threshold=10; user_defined_function_fail_timeout=1500; user_defined_function_warn_timeout=500; user_function_timeout_policy=die; windows_timer_interval=1; write_request_timeout_in_ms=2000]</br>[33mcassandra_1      |[0m INFO  21:52:51 DiskAccessMode &#39;auto&#39; determined to be mmap, indexAccessMode is mmap</br>[33mcassandra_1      |[0m INFO  21:52:51 Global memtable on-heap threshold is enabled at 1996MB</br>[33mcassandra_1      |[0m INFO  21:52:51 Global memtable off-heap threshold is enabled at 1996MB</br>[33mcassandra_1      |[0m INFO  21:52:51 Hostname: 127b08d39cb5</br>[33mcassandra_1      |[0m INFO  21:52:51 JVM vendor/version: OpenJDK 64-Bit Server VM/1.8.0_102</br>[33mcassandra_1      |[0m INFO  21:52:51 Heap size: 7.800GiB/7.800GiB</br>[33mcassandra_1      |[0m INFO  21:52:51 Code Cache Non-heap memory: init = 2555904(2496K) used = 6389120(6239K) committed = 6422528(6272K) max = 251658240(245760K)</br>[33mcassandra_1      |[0m INFO  21:52:51 Metaspace Non-heap memory: init = 0(0K) used = 15505408(15142K) committed = 15990784(15616K) max = -1(-1K)</br>[33mcassandra_1      |[0m INFO  21:52:51 Compressed Class Space Non-heap memory: init = 0(0K) used = 1871648(1827K) committed = 2097152(2048K) max = 1073741824(1048576K)</br>[33mcassandra_1      |[0m INFO  21:52:51 Par Eden Space Heap memory: init = 1718091776(1677824K) used = 309260424(302012K) committed = 1718091776(1677824K) max = 1718091776(1677824K)</br>[33mcassandra_1      |[0m INFO  21:52:51 Par Survivor Space Heap memory: init = 214695936(209664K) used = 0(0K) committed = 214695936(209664K) max = 214695936(209664K)</br>[33mcassandra_1      |[0m INFO  21:52:51 CMS Old Gen Heap memory: init = 6442450944(6291456K) used = 0(0K) committed = 6442450944(6291456K) max = 6442450944(6291456K)</br>[36mfast-data-dev_1  |[0m [92mSetting advertised host to [96mfast-data-dev[34m[92m.[34m</br>[36mfast-data-dev_1  |[0m [92mStarting services.[39m</br>[36mfast-data-dev_1  |[0m [34mYou may visit [96mhttp://fast-data-dev:3030[34m in about a minute.[39m</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:39,716 CRIT Supervisor running as root (no user in config file)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:39,719 INFO supervisord started with pid 7</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:40,721 INFO spawned: &#39;zookeeper&#39; with pid 51</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:40,723 INFO spawned: &#39;caddy&#39; with pid 52</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:40,724 INFO spawned: &#39;broker&#39; with pid 53</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:40,726 INFO spawned: &#39;smoke-tests&#39; with pid 54</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:40,727 INFO spawned: &#39;connect-distributed&#39; with pid 55</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:40,729 INFO spawned: &#39;logs-to-kafka&#39; with pid 57</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:40,731 INFO spawned: &#39;schema-registry&#39; with pid 59</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:40,732 INFO spawned: &#39;rest-proxy&#39; with pid 61</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:41,793 INFO success: zookeeper entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:41,793 INFO success: caddy entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:41,793 INFO success: broker entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:41,793 INFO success: smoke-tests entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:41,793 INFO success: connect-distributed entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:52:51 Classpath: /etc/cassandra:/usr/share/cassandra/lib/HdrHistogram-2.1.9.jar:/usr/share/cassandra/lib/ST4-4.0.8.jar:/usr/share/cassandra/lib/airline-0.6.jar:/usr/share/cassandra/lib/antlr-runtime-3.5.2.jar:/usr/share/cassandra/lib/asm-5.0.4.jar:/usr/share/cassandra/lib/caffeine-2.2.6.jar:/usr/share/cassandra/lib/cassandra-driver-core-3.0.1-shaded.jar:/usr/share/cassandra/lib/commons-cli-1.1.jar:/usr/share/cassandra/lib/commons-codec-1.2.jar:/usr/share/cassandra/lib/commons-lang3-3.1.jar:/usr/share/cassandra/lib/commons-math3-3.2.jar:/usr/share/cassandra/lib/compress-lzf-0.8.4.jar:/usr/share/cassandra/lib/concurrent-trees-2.4.0.jar:/usr/share/cassandra/lib/concurrentlinkedhashmap-lru-1.4.jar:/usr/share/cassandra/lib/disruptor-3.0.1.jar:/usr/share/cassandra/lib/ecj-4.4.2.jar:/usr/share/cassandra/lib/guava-18.0.jar:/usr/share/cassandra/lib/high-scale-lib-1.0.6.jar:/usr/share/cassandra/lib/hppc-0.5.4.jar:/usr/share/cassandra/lib/jackson-core-asl-1.9.2.jar:/usr/share/cassandra/lib/jackson-mapper-asl-1.9.2.jar:/usr/share/cassandra/lib/jamm-0.3.0.jar:/usr/share/cassandra/lib/javax.inject.jar:/usr/share/cassandra/lib/jbcrypt-0.3m.jar:/usr/share/cassandra/lib/jcl-over-slf4j-1.7.7.jar:/usr/share/cassandra/lib/jflex-1.6.0.jar:/usr/share/cassandra/lib/jna-4.0.0.jar:/usr/share/cassandra/lib/joda-time-2.4.jar:/usr/share/cassandra/lib/json-simple-1.1.jar:/usr/share/cassandra/lib/libthrift-0.9.2.jar:/usr/share/cassandra/lib/log4j-over-slf4j-1.7.7.jar:/usr/share/cassandra/lib/logback-classic-1.1.3.jar:/usr/share/cassandra/lib/logback-core-1.1.3.jar:/usr/share/cassandra/lib/lz4-1.3.0.jar:/usr/share/cassandra/lib/metrics-core-3.1.0.jar:/usr/share/cassandra/lib/metrics-jvm-3.1.0.jar:/usr/share/cassandra/lib/metrics-logback-3.1.0.jar:/usr/share/cassandra/lib/netty-all-4.0.39.Final.jar:/usr/share/cassandra/lib/ohc-core-0.4.3.jar:/usr/share/cassandra/lib/ohc-core-j8-0.4.3.jar:/usr/share/cassandra/lib/primitive-1.0.jar:/usr/share/cassandra/lib/reporter-config-base-3.0.0.jar:/usr/share/cassandra/lib/reporter-config3-3.0.0.jar:/usr/share/cassandra/lib/sigar-1.6.4.jar:/usr/share/cassandra/lib/slf4j-api-1.7.7.jar:/usr/share/cassandra/lib/snakeyaml-1.11.jar:/usr/share/cassandra/lib/snappy-java-1.1.1.7.jar:/usr/share/cassandra/lib/snowball-stemmer-1.3.0.581.1.jar:/usr/share/cassandra/lib/stream-2.5.2.jar:/usr/share/cassandra/lib/thrift-server-0.3.7.jar:/usr/share/cassandra/apache-cassandra-3.9.jar:/usr/share/cassandra/apache-cassandra-thrift-3.9.jar:/usr/share/cassandra/apache-cassandra.jar:/usr/share/cassandra/stress.jar::/usr/share/cassandra/lib/jamm-0.3.0.jar</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:41,794 INFO success: logs-to-kafka entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:41,794 INFO success: schema-registry entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:41,794 INFO success: rest-proxy entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:47,213 INFO exited: schema-registry (exit status 1; not expected)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:47,218 INFO spawned: &#39;schema-registry&#39; with pid 415</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:47,460 INFO exited: rest-proxy (exit status 1; not expected)</br>[33mcassandra_1      |[0m INFO  21:52:51 JVM Arguments: [-Xloggc:/var/log/cassandra/gc.log, -ea, -XX:+UseThreadPriorities, -XX:ThreadPriorityPolicy=42, -XX:+HeapDumpOnOutOfMemoryError, -Xss256k, -XX:StringTableSize=1000003, -XX:+AlwaysPreTouch, -XX:-UseBiasedLocking, -XX:+UseTLAB, -XX:+ResizeTLAB, -XX:+PerfDisableSharedMem, -Djava.net.preferIPv4Stack=true, -XX:+UseParNewGC, -XX:+UseConcMarkSweepGC, -XX:+CMSParallelRemarkEnabled, -XX:SurvivorRatio=8, -XX:MaxTenuringThreshold=1, -XX:CMSInitiatingOccupancyFraction=75, -XX:+UseCMSInitiatingOccupancyOnly, -XX:CMSWaitDuration=10000, -XX:+CMSParallelInitialMarkEnabled, -XX:+CMSEdenChunksRecordAlways, -XX:+CMSClassUnloadingEnabled, -XX:+PrintGCDetails, -XX:+PrintGCDateStamps, -XX:+PrintHeapAtGC, -XX:+PrintTenuringDistribution, -XX:+PrintGCApplicationStoppedTime, -XX:+PrintPromotionFailure, -XX:+UseGCLogFileRotation, -XX:NumberOfGCLogFiles=10, -XX:GCLogFileSize=10M, -Xms8192M, -Xmx8192M, -Xmn2048M, -XX:CompileCommandFile=/etc/cassandra/hotspot_compiler, -javaagent:/usr/share/cassandra/lib/jamm-0.3.0.jar, -Dcassandra.jmx.local.port=7199, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.password.file=/etc/cassandra/jmxremote.password, -Djava.library.path=/usr/share/cassandra/lib/sigar-bin, -Dlogback.configurationFile=logback.xml, -Dcassandra.logdir=/var/log/cassandra, -Dcassandra.storagedir=/var/lib/cassandra, -Dcassandra-foreground=yes]</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:47,462 INFO spawned: &#39;rest-proxy&#39; with pid 480</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:48,244 INFO success: schema-registry entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:48,461 INFO success: rest-proxy entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m WARN  21:52:51 Unable to lock JVM memory (ENOMEM). This can result in part of the JVM being swapped out, especially with mmapped I/O enabled. Increase RLIMIT_MEMLOCK or run Cassandra as root.</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:48,492 INFO exited: schema-registry (exit status 1; not expected)</br>[33mcassandra_1      |[0m WARN  21:52:51 jemalloc shared library could not be preloaded to speed up memory allocations</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:48,493 INFO spawned: &#39;schema-registry&#39; with pid 562</br>[33mcassandra_1      |[0m WARN  21:52:51 JMX is not enabled to receive remote connections. Please see cassandra-env.sh for more info.</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:48,792 INFO exited: rest-proxy (exit status 1; not expected)</br>[33mcassandra_1      |[0m WARN  21:52:51 OpenJDK is not recommended. Please upgrade to the newest Oracle Java release</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:48,795 INFO spawned: &#39;rest-proxy&#39; with pid 643</br>[33mcassandra_1      |[0m INFO  21:52:51 Initializing SIGAR library</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:49,597 INFO success: schema-registry entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m INFO  21:52:51 Checked OS settings and found them configured for optimal performance.</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:52:50,166 INFO success: rest-proxy entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)</br>[33mcassandra_1      |[0m WARN  21:52:51 Directory /var/lib/cassandra/data doesn&#39;t exist</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:53:10,744 INFO exited: smoke-tests (exit status 0; expected)</br>[33mcassandra_1      |[0m WARN  21:52:51 Directory /var/lib/cassandra/commitlog doesn&#39;t exist</br>[36mfast-data-dev_1  |[0m 2016-10-12 21:53:20,742 INFO exited: logs-to-kafka (exit status 0; expected)</br>[33mcassandra_1      |[0m WARN  21:52:51 Directory /var/lib/cassandra/saved_caches doesn&#39;t exist</br>[33mcassandra_1      |[0m WARN  21:52:51 Directory /var/lib/cassandra/hints doesn&#39;t exist</br>[33mcassandra_1      |[0m INFO  21:52:51 Initialized prepared statement caches with 31 MB (native) and 31 MB (Thrift)</br>[33mcassandra_1      |[0m INFO  21:52:52 Initializing system.IndexInfo</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.batches</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.paxos</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.local</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.peers</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.peer_events</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.range_xfers</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.compaction_history</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.sstable_activity</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.size_estimates</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.available_ranges</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.views_builds_in_progress</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.built_views</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.hints</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.batchlog</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.schema_keyspaces</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.schema_columnfamilies</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.schema_columns</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.schema_triggers</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.schema_usertypes</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.schema_functions</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing system.schema_aggregates</br>[33mcassandra_1      |[0m INFO  21:52:53 Not submitting build tasks for views in keyspace system as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:52:53 Configured JMX server at: service:jmx:rmi://127.0.0.1/jndi/rmi://127.0.0.1:7199/jmxrmi</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing key cache with capacity of 100 MBs.</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing row cache with capacity of 0 MBs</br>[33mcassandra_1      |[0m INFO  21:52:53 Initializing counter cache with capacity of 50 MBs</br>[33mcassandra_1      |[0m INFO  21:52:53 Scheduling counter cache save to every 7200 seconds (going to save all keys).</br>[33mcassandra_1      |[0m INFO  21:52:54 Global buffer pool is enabled, when pool is exhausted (max is 512.000MiB) it will allocate on heap</br>[33mcassandra_1      |[0m INFO  21:52:54 Populating token metadata from system tables</br>[33mcassandra_1      |[0m INFO  21:52:54 Token metadata: </br>[33mcassandra_1      |[0m INFO  21:52:54 Initializing system_schema.keyspaces</br>[33mcassandra_1      |[0m INFO  21:52:54 Initializing system_schema.tables</br>[33mcassandra_1      |[0m INFO  21:52:54 Initializing system_schema.columns</br>[33mcassandra_1      |[0m INFO  21:52:54 Initializing system_schema.triggers</br>[33mcassandra_1      |[0m INFO  21:52:54 Initializing system_schema.dropped_columns</br>[33mcassandra_1      |[0m INFO  21:52:54 Initializing system_schema.views</br>[33mcassandra_1      |[0m INFO  21:52:54 Initializing system_schema.types</br>[33mcassandra_1      |[0m INFO  21:52:54 Initializing system_schema.functions</br>[33mcassandra_1      |[0m INFO  21:52:54 Initializing system_schema.aggregates</br>[33mcassandra_1      |[0m INFO  21:52:54 Initializing system_schema.indexes</br>[33mcassandra_1      |[0m INFO  21:52:54 Not submitting build tasks for views in keyspace system_schema as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:52:54 Completed loading (2 ms; 5 keys) KeyCache cache</br>[33mcassandra_1      |[0m INFO  21:52:54 No commitlog files found; skipping replay</br>[33mcassandra_1      |[0m INFO  21:52:54 Populating token metadata from system tables</br>[33mcassandra_1      |[0m INFO  21:52:54 Token metadata: </br>[33mcassandra_1      |[0m INFO  21:52:54 Cassandra version: 3.9</br>[33mcassandra_1      |[0m INFO  21:52:54 Thrift API version: 20.1.0</br>[33mcassandra_1      |[0m INFO  21:52:54 CQL supported versions: 3.4.2 (default: 3.4.2)</br>[33mcassandra_1      |[0m INFO  21:52:54 Initializing index summary manager with a memory pool size of 399 MB and a resize interval of 60 minutes</br>[33mcassandra_1      |[0m INFO  21:52:54 Starting Messaging Service on /172.19.0.2:7000 (eth0)</br>[33mcassandra_1      |[0m WARN  21:52:54 No host ID found, created e6f3f328-da9a-46f6-bf35-8846471ea4fd (Note: This should happen exactly once per node).</br>[33mcassandra_1      |[0m INFO  21:52:54 Loading persisted ring state</br>[33mcassandra_1      |[0m INFO  21:52:54 Starting up server gossip</br>[33mcassandra_1      |[0m INFO  21:52:54 This node will not auto bootstrap because it is configured to be a seed node.</br>[33mcassandra_1      |[0m INFO  21:52:54 Generated random tokens. tokens are [3967749195850512712, 3670901018247878072, 4726685214872568613, 8582408589603916460, 1260433205679253947, 7470755523970135344, -9003361594887020273, -766297765332657595, -7613084563652686399, 8563678112726527184, 484917411837742211, -1690450342018967737, -1683064437375369386, 5189366824149752088, -7118029105140593115, 878661219459484766, -5416411116404262083, -962299222399227891, -3620212531990565513, 6786361256971274921, -5685397168312472096, -4989845776592450198, -3950395035527227059, 9079015205802744790, -6348218970347135584, 4104008884637415246, -1086679430609540670, 5575596218514953202, 1226798303012912016, -7738598271259013800, 3029748890583274361, 6284145167724643461, 6141577377714238504, -6912969100016901847, -203984441816944737, 2825563915534159753, 2330761274197280721, 1788796881389290335, -6654614095574586958, -6045057155590925104, 298276166537596310, -1637137319164858884, -4277423919081322490, 8944869409180398939, 6822639800346309154, 1325281758598239759, -3603568191363072102, -9047690737959647414, -1022945820690419994, -2841159288407789443, 445538483428169252, 4137477449581114027, -2001748890079336736, -5722020415829301070, 2404826392819401619, -5397485591683022476, -5534656398542634735, 2613937669383521499, 3027854313662986381, 2144111984569987382, -147792476140093634, 535773643283108272, -1692919900753556789, 6449128677435725834, -3509086423732253180, -6704019416718376314, -3857636511536531020, 2559534089095608507, -2232203345279868601, -6011480789871904877, -900503197149019966, 3345601014257528194, 7981581914396039547, 564678741869219420, -6495317686237582386, 2411728982447773190, -5111324384952665328, -3942621833695148701, 408604599165555290, 1296353000810464670, 4408781735739270869, -8663911791245319985, -5116843094379155965, 5175237738427417346, -1903200643755813735, -9119460535854412279, 3734178017711523764, 361060909050001778, 6646869776217644514, -2287819619982157209, -5697239719766355567, 2258316586460575024, 7463197405465440841, -4541439875783529632, -4013373500299557062, 5137457739679691560, -7059067118653507048, -7331898237825129833, 416518274343275656, 8307777956369404845, -2978756319200005836, -4083865623113949811, 7825388470352850888, -4462164150591201518, 3626446667326916703, -5713422516664004953, -3189086734405947899, -3913851556747196520, 5410826933691735621, 6766725960280165019, 817224926610950692, -866803794206775842, -340453503772886544, -4643251850514020580, 7834747928652377076, -3670065008495775044, 2546910771809503273, -73560240164924359, -3285250264026101073, 5639301355614333133, -2831177778259252635, 8527494207863668849, 6983566245660914064, -9100954119287010815, -6692590583956522399, 48029337458887134, 327153460461927954, 6484826387520929169, 6145342221987974311, 8177979938416403601, 2392032807686340153, -7208786133070139058, -1474831673758371623, 6914786707513149913, -6104231405732650697, 4312220916411500903, -6963281161892680485, -5342507796886990524, -520301743201349183, 7028295639334267898, -1696740255712873779, 6916891913382161086, 5275137431666742855, 1247617699757517902, 1248603970151833282, -8697065008746816966, -6409203553139500415, 284226289979186843, -7726620385480104595, 2753929727188612623, 3687000172988641998, 4788963544041635164, 6470801634227193109, -4646842863637609375, 3744913287079077108, -5012990034155612456, 8761633546977544286, 8688854369570123768, 5274263292433919981, -7921543148156899833, -5367368793175227901, -6281463619808105403, -6706431952826625153, -5857634614923653421, 7886315378201933406, -3552438832652037333, 719821128851490345, -1015616234477931769, -6191116921487939212, 378700427265137023, -7530415713384751038, -8555230715488778461, -93954227507580276, -8431836636718006099, -5586573300757268838, -4077224539160263628, 7316467030728712607, 883993480416479153, -2999536949507415601, 6237592745542576623, -235003012923260864, 3137878782464789449, -7096582290840707601, -6754161799511508471, -7494068446731838239, -9015584811043372126, 2820662608571002610, -4009957146006816859, 1279493509259734005, -3399954976152130695, -6502785896342967265, 5206666614492737738, -750486684322671602, 7768234301396207875, 8161513344388301315, 4309155559425507091, 193263533542328282, -7385096348473614144, 2727304442226801657, 5769553495096632330, 5916390393103353153, 4713174490923576357, -7658922150794186940, 4620031840676214151, 1898866930036339744, -3680530672060320957, 8761946554267458014, -1574919184925058490, -5754627899299679141, 1468753208246249145, 2431131570184694345, -6138863306744064027, 8709453968489381418, 6372153794791872865, 8695257066287221753, -8259011941262771201, 9089972196122100243, -8323838163536167915, -4392277225397098319, 6998327035413633062, -6780204214481885360, -7660228882037253223, 2234804922548978007, 7961012002845834180, 3156202464553991658, -7481288027846600688, -3156121415164322160, -741902399505937730, 4716535746973547058, 4964388080724545859, 7532117975756272993, 4036628749912142109, 9005182700180407167, -8442700377358476839, 7261126055250384947, -2419215401588957965, -5549719921652480269, 885980542928085024, 5633862909890069694, 724426999171465218, 6353616298664285359, 3515096072732024004, -3140704813482898988, -7785275244403917868, -2508409529238550392, 8653761140129369704, -383170908045755146, -3251982572893494580, -2045560797260631062, -3823011338789038242, -6133103640577367278, -1036979740402676729, -4511527977307799049, -8849763071399873709, 4596547656168558745, -9164971872941672625]</br>[33mcassandra_1      |[0m INFO  21:52:54 Create new Keyspace: KeyspaceMetadata{name=system_traces, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=2}}, tables=[org.apache.cassandra.config.CFMetaData@3ddc7d11[cfId=c5e99f16-8677-3914-b17e-960613512345,ksName=system_traces,cfName=sessions,flags=[COMPOUND],params=TableParams{comment=tracing sessions, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@33c74e43, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [client command coordinator duration request started_at parameters]],partitionKeyColumns=[session_id],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UUIDType,columnMetadata=[client, command, session_id, coordinator, request, started_at, duration, parameters],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@294e352f[cfId=8826e8e9-e16a-3728-8753-3bc1fc713c25,ksName=system_traces,cfName=events,flags=[COMPOUND],params=TableParams{comment=tracing events, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@33c74e43, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.TimeUUIDType),partitionColumns=[[] | [activity source source_elapsed thread]],partitionKeyColumns=[session_id],clusteringColumns=[event_id],keyValidator=org.apache.cassandra.db.marshal.UUIDType,columnMetadata=[activity, session_id, thread, event_id, source, source_elapsed],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}</br>[33mcassandra_1      |[0m INFO  21:52:54 Not submitting build tasks for views in keyspace system_traces as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:52:55 Initializing system_traces.events</br>[33mcassandra_1      |[0m INFO  21:52:55 Initializing system_traces.sessions</br>[33mcassandra_1      |[0m INFO  21:52:55 Create new Keyspace: KeyspaceMetadata{name=system_distributed, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=3}}, tables=[org.apache.cassandra.config.CFMetaData@66ef86a[cfId=759fffad-624b-3181-80ee-fa9a52d1f627,ksName=system_distributed,cfName=repair_history,flags=[COMPOUND],params=TableParams{comment=Repair history, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@33c74e43, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.TimeUUIDType),partitionColumns=[[] | [coordinator exception_message exception_stacktrace finished_at parent_id range_begin range_end started_at status participants]],partitionKeyColumns=[keyspace_name, columnfamily_name],clusteringColumns=[id],keyValidator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type),columnMetadata=[status, id, coordinator, finished_at, participants, exception_stacktrace, parent_id, range_end, range_begin, exception_message, keyspace_name, started_at, columnfamily_name],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@3343dcfe[cfId=deabd734-b99d-3b9c-92e5-fd92eb5abf14,ksName=system_distributed,cfName=parent_repair_history,flags=[COMPOUND],params=TableParams{comment=Repair history, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@33c74e43, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [exception_message exception_stacktrace finished_at keyspace_name started_at columnfamily_names options requested_ranges successful_ranges]],partitionKeyColumns=[parent_id],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.TimeUUIDType,columnMetadata=[requested_ranges, exception_message, keyspace_name, successful_ranges, started_at, finished_at, options, exception_stacktrace, parent_id, columnfamily_names],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@5418cc74[cfId=5582b59f-8e4e-35e1-b913-3acada51eb04,ksName=system_distributed,cfName=view_build_status,flags=[COMPOUND],params=TableParams{comment=Materialized View build status, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=0, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@33c74e43, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UUIDType),partitionColumns=[[] | [status]],partitionKeyColumns=[keyspace_name, view_name],clusteringColumns=[host_id],keyValidator=org.apache.cassandra.db.marshal.CompositeType(org.apache.cassandra.db.marshal.UTF8Type,org.apache.cassandra.db.marshal.UTF8Type),columnMetadata=[status, keyspace_name, view_name, host_id],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}</br>[33mcassandra_1      |[0m INFO  21:52:55 Not submitting build tasks for views in keyspace system_distributed as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:52:55 Initializing system_distributed.parent_repair_history</br>[33mcassandra_1      |[0m INFO  21:52:55 Initializing system_distributed.repair_history</br>[33mcassandra_1      |[0m INFO  21:52:55 Initializing system_distributed.view_build_status</br>[33mcassandra_1      |[0m INFO  21:52:55 Node /172.19.0.2 state jump to NORMAL</br>[33mcassandra_1      |[0m INFO  21:52:55 Create new Keyspace: KeyspaceMetadata{name=system_auth, params=KeyspaceParams{durable_writes=true, replication=ReplicationParams{class=org.apache.cassandra.locator.SimpleStrategy, replication_factor=1}}, tables=[org.apache.cassandra.config.CFMetaData@610eec13[cfId=5bc52802-de25-35ed-aeab-188eecebb090,ksName=system_auth,cfName=roles,flags=[COMPOUND],params=TableParams{comment=role definitions, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@33c74e43, extensions={}, cdc=false},comparator=comparator(),partitionColumns=[[] | [can_login is_superuser salted_hash member_of]],partitionKeyColumns=[role],clusteringColumns=[],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[role, salted_hash, member_of, can_login, is_superuser],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@67d26137[cfId=0ecdaa87-f8fb-3e60-88d1-74fb36fe5c0d,ksName=system_auth,cfName=role_members,flags=[COMPOUND],params=TableParams{comment=role memberships lookup table, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@33c74e43, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | []],partitionKeyColumns=[role],clusteringColumns=[member],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[role, member],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@5a3214ef[cfId=3afbe79f-2194-31a7-add7-f5ab90d8ec9c,ksName=system_auth,cfName=role_permissions,flags=[COMPOUND],params=TableParams{comment=permissions granted to db roles, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@33c74e43, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | [permissions]],partitionKeyColumns=[role],clusteringColumns=[resource],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[resource, role, permissions],droppedColumns={},triggers=[],indexes=[]], org.apache.cassandra.config.CFMetaData@436b7ae6[cfId=5f2fbdad-91f1-3946-bd25-d5da3a5c35ec,ksName=system_auth,cfName=resource_role_permissons_index,flags=[COMPOUND],params=TableParams{comment=index of db roles with permissions granted on a resource, read_repair_chance=0.0, dclocal_read_repair_chance=0.0, bloom_filter_fp_chance=0.01, crc_check_chance=1.0, gc_grace_seconds=7776000, default_time_to_live=0, memtable_flush_period_in_ms=3600000, min_index_interval=128, max_index_interval=2048, speculative_retry=99PERCENTILE, caching={&#39;keys&#39; : &#39;ALL&#39;, &#39;rows_per_partition&#39; : &#39;NONE&#39;}, compaction=CompactionParams{class=org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy, options={min_threshold=4, max_threshold=32}}, compression=org.apache.cassandra.schema.CompressionParams@33c74e43, extensions={}, cdc=false},comparator=comparator(org.apache.cassandra.db.marshal.UTF8Type),partitionColumns=[[] | []],partitionKeyColumns=[resource],clusteringColumns=[role],keyValidator=org.apache.cassandra.db.marshal.UTF8Type,columnMetadata=[resource, role],droppedColumns={},triggers=[],indexes=[]]], views=[], functions=[], types=[]}</br>[33mcassandra_1      |[0m INFO  21:52:55 Not submitting build tasks for views in keyspace system_auth as storage service is not initialized</br>[33mcassandra_1      |[0m INFO  21:52:55 Initializing system_auth.resource_role_permissons_index</br>[33mcassandra_1      |[0m INFO  21:52:55 Initializing system_auth.role_members</br>[33mcassandra_1      |[0m INFO  21:52:55 Initializing system_auth.role_permissions</br>[33mcassandra_1      |[0m INFO  21:52:55 Initializing system_auth.roles</br>[33mcassandra_1      |[0m INFO  21:52:55 (Re)initializing CredentialsCache (validity period/update interval/max entries) (2000/2000/1000)</br>[33mcassandra_1      |[0m INFO  21:52:55 Waiting for gossip to settle before accepting client requests...</br>[33mcassandra_1      |[0m INFO  21:53:03 No gossip backlog; proceeding</br>[33mcassandra_1      |[0m INFO  21:53:03 Netty using native Epoll event loop</br>[33mcassandra_1      |[0m INFO  21:53:03 Using Netty Version: [netty-buffer=netty-buffer-4.0.39.Final.38bdf86, netty-codec=netty-codec-4.0.39.Final.38bdf86, netty-codec-haproxy=netty-codec-haproxy-4.0.39.Final.38bdf86, netty-codec-http=netty-codec-http-4.0.39.Final.38bdf86, netty-codec-socks=netty-codec-socks-4.0.39.Final.38bdf86, netty-common=netty-common-4.0.39.Final.38bdf86, netty-handler=netty-handler-4.0.39.Final.38bdf86, netty-tcnative=netty-tcnative-1.1.33.Fork19.fe4816e, netty-transport=netty-transport-4.0.39.Final.38bdf86, netty-transport-native-epoll=netty-transport-native-epoll-4.0.39.Final.38bdf86, netty-transport-rxtx=netty-transport-rxtx-4.0.39.Final.38bdf86, netty-transport-sctp=netty-transport-sctp-4.0.39.Final.38bdf86, netty-transport-udt=netty-transport-udt-4.0.39.Final.38bdf86]</br>[33mcassandra_1      |[0m INFO  21:53:03 Starting listening for CQL clients on /0.0.0.0:9042 (unencrypted)...</br>[33mcassandra_1      |[0m INFO  21:53:03 Not starting RPC server as requested. Use JMX (StorageService-&gt;startRPCServer()) or nodetool (enablethrift) to start it</br>[33mcassandra_1      |[0m INFO  21:53:05 Scheduling approximate time-check task with a precision of 10 milliseconds</br>[33mcassandra_1      |[0m INFO  21:53:05 Created default superuser role &#39;cassandra&#39;</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 4 out of 4
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        3.97 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header green">
                    <div class="cell">
                        Setup Cassandra Source Connector
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Create Source Topic
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        3.06
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</br>  kafka-topics --zookeeper fast-data-dev:2181 --topic cassandra-source --partition 1 --replication 1 --create</br></br>'>docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev
  kafka-topics --zookeeper fast-data-dev:2181 --topic cassandra-source --partition 1 --replication 1 --create

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                        Created topic &#34;cassandra-source&#34;.
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Create Cassandra Source Table and Data
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.51
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra</br>  cqlsh -u cassandra -p cassandra cassandra</br></br>'>docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra
  cqlsh -u cassandra -p cassandra cassandra

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_1_1" class="trigger" data-tooltip-id="1_1" title=" id | created                              | price | product                 | qty</br>----+--------------------------------------+-------+-------------------------+-----</br>  1 | 5897b340-90c6-11e6-b029-9b89c16b65a4 |  94.2 |  OP-DAX-P-20150201-95.7 | 100</br>  2 | 58982870-90c6-11e6-b029-9b89c16b65a4 |  99.5 |   OP-DAX-C-20150201-100 | 100</br>  3 | 58987690-90c6-11e6-b029-9b89c16b65a4 |   150 | FU-KOSPI-C-20150201-100 | 200</br></br>(3 rows)</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Create a Cassandra Source Distributed Connector
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.62
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev</br>  curl -vs --stderr - -X POST -H &#34;Content-Type: application/json&#34;</br>       --data @-</br>       &#34;http://fast-data-dev:8083/connectors&#34;</br></br>'>docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev
  curl -vs --stderr - -X POST -H &#34;Content-Type: application/json&#34;
       --data @-
       &#34;http://fast-data-dev:8083/connectors&#34;

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_1_2" class="trigger" data-tooltip-id="1_2" title="*   Trying 172.19.0.3...</br>* TCP_NODELAY set</br>* Connected to fast-data-dev (172.19.0.3) port 8083 (#0)</br>&gt; POST /connectors HTTP/1.1</br>&gt; Host: fast-data-dev:8083</br>&gt; User-Agent: curl/7.50.3</br>&gt; Accept: */*</br>&gt; Content-Type: application/json</br>&gt; Content-Length: 522</br>&gt; </br>} [522 bytes data]</br>* upload completely sent off: 522 out of 522 bytes</br>&lt; HTTP/1.1 201 Created</br>&lt; Date: Wed, 12 Oct 2016 21:53:45 GMT</br>&lt; Location: http://fast-data-dev:8083/connectors/cassandra-source</br>&lt; Content-Type: application/json</br>&lt; Content-Length: 511</br>&lt; Server: Jetty(9.2.12.v20150709)</br>&lt; </br>{ [511 bytes data]</br>{&#34;name&#34;:&#34;cassandra-source&#34;,&#34;config&#34;:{&#34;connector.class&#34;:&#34;com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector&#34;,&#34;tasks.max&#34;:&#34;1&#34;,&#34;connect.cassandra.key.space&#34;:&#34;source&#34;,&#34;connect.cassandra.import.route.query&#34;:&#34;INSERT INTO cassandra-source SELECT * FROM orders PK created&#34;,&#34;connect.cassandra.import.mode&#34;:&#34;incremental&#34;,&#34;connect.cassandra.contact.points&#34;:&#34;cassandra&#34;,&#34;connect.cassandra.username&#34;:&#34;cassandra&#34;,&#34;connect.cassandra.password&#34;:&#34;cassandra&#34;,&#34;name&#34;:&#34;cassandra-source&#34;},&#34;tasks&#34;:[]}* Curl_http_done: called premature == 0</br>* Connection #0 to host fast-data-dev left intact</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 3 out of 3
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        7.19 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header blue">
                    <div class="cell">
                        Setup Cassandra Sink Connector
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Create Sink Topic
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.33
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</br>  kafka-topics --zookeeper fast-data-dev:2181 --topic cassandra-sink --partition 1 --replication 1 --create</br></br>'>docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev
  kafka-topics --zookeeper fast-data-dev:2181 --topic cassandra-sink --partition 1 --replication 1 --create

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                        Created topic &#34;cassandra-sink&#34;.
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Create Cassandra Sink Table
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.55
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra</br>  cqlsh -u cassandra -p cassandra cassandra</br></br>'>docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default -i landoop/cassandra
  cqlsh -u cassandra -p cassandra cassandra

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Create a Cassandra Sink Distributed Connector
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        1.17
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev</br>  curl -vs --stderr - -X POST -H &#34;Content-Type: application/json&#34;</br>       --data @-</br>       &#34;http://fast-data-dev:8083/connectors&#34;</br></br>'>docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm --network=kafkaconnectcassandra_default -i landoop/fast-data-dev
  curl -vs --stderr - -X POST -H &#34;Content-Type: application/json&#34;
       --data @-
       &#34;http://fast-data-dev:8083/connectors&#34;

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_2_2" class="trigger" data-tooltip-id="2_2" title="*   Trying 172.19.0.3...</br>* TCP_NODELAY set</br>* Connected to fast-data-dev (172.19.0.3) port 8083 (#0)</br>&gt; POST /connectors HTTP/1.1</br>&gt; Host: fast-data-dev:8083</br>&gt; User-Agent: curl/7.50.3</br>&gt; Accept: */*</br>&gt; Content-Type: application/json</br>&gt; Content-Length: 481</br>&gt; </br>} [481 bytes data]</br>* upload completely sent off: 481 out of 481 bytes</br>&lt; HTTP/1.1 201 Created</br>&lt; Date: Wed, 12 Oct 2016 21:53:50 GMT</br>&lt; Location: http://fast-data-dev:8083/connectors/cassandra-sink</br>&lt; Content-Type: application/json</br>&lt; Content-Length: 468</br>&lt; Server: Jetty(9.2.12.v20150709)</br>&lt; </br>{ [468 bytes data]</br>{&#34;name&#34;:&#34;cassandra-sink&#34;,&#34;config&#34;:{&#34;connector.class&#34;:&#34;com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector&#34;,&#34;tasks.max&#34;:&#34;1&#34;,&#34;topics&#34;:&#34;cassandra-sink&#34;,&#34;connect.cassandra.key.space&#34;:&#34;sink&#34;,&#34;connect.cassandra.export.route.query&#34;:&#34;INSERT INTO orders SELECT * FROM cassandra-sink&#34;,&#34;connect.cassandra.contact.points&#34;:&#34;cassandra&#34;,&#34;connect.cassandra.username&#34;:&#34;cassandra&#34;,&#34;connect.cassandra.password&#34;:&#34;cassandra&#34;,&#34;name&#34;:&#34;cassandra-sink&#34;},&#34;tasks&#34;:[]}* Curl_http_done: called premature == 0</br>* Connection #0 to host fast-data-dev left intact</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 3 out of 3
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        5.05 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header purple">
                    <div class="cell">
                        Test Cassandra Source Connector
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Read Entries from Topic
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        20.98
                    </div>
                    <div class="cell">
                        (ignore) 124
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='timeout 20 docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</br>  kafka-avro-console-consumer --zookeeper fast-data-dev:2181/confluent</br>                              --bootstrap-server fast-data-dev:9092</br>                              --topic cassandra-source --from-beginning --new-consumer</br>                              --property schema.registry.url=http://fast-data-dev:8081</br></br>'>timeout 20 docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        timeout 20 docker run --rm --network=kafkaconnectcassandra_default landoop/fast-data-dev
  kafka-avro-console-consumer --zookeeper fast-data-dev:2181/confluent
                              --bootstrap-server fast-data-dev:9092
                              --topic cassandra-source --from-beginning --new-consumer
                              --property schema.registry.url=http://fast-data-dev:8081

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_3_0" class="trigger" data-tooltip-id="3_0" title="{&#34;id&#34;:{&#34;int&#34;:1},&#34;created&#34;:{&#34;string&#34;:&#34;5897b340-90c6-11e6-b029-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:94.2},&#34;product&#34;:{&#34;string&#34;:&#34;OP-DAX-P-20150201-95.7&#34;},&#34;qty&#34;:{&#34;int&#34;:100}}</br>{&#34;id&#34;:{&#34;int&#34;:2},&#34;created&#34;:{&#34;string&#34;:&#34;58982870-90c6-11e6-b029-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:99.5},&#34;product&#34;:{&#34;string&#34;:&#34;OP-DAX-C-20150201-100&#34;},&#34;qty&#34;:{&#34;int&#34;:100}}</br>{&#34;id&#34;:{&#34;int&#34;:3},&#34;created&#34;:{&#34;string&#34;:&#34;58987690-90c6-11e6-b029-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:150.0},&#34;product&#34;:{&#34;string&#34;:&#34;FU-KOSPI-C-20150201-100&#34;},&#34;qty&#34;:{&#34;int&#34;:200}}</br>{&#34;id&#34;:{&#34;int&#34;:1},&#34;created&#34;:{&#34;string&#34;:&#34;5897b340-90c6-11e6-b029-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:94.2},&#34;product&#34;:{&#34;string&#34;:&#34;OP-DAX-P-20150201-95.7&#34;},&#34;qty&#34;:{&#34;int&#34;:100}}</br>{&#34;id&#34;:{&#34;int&#34;:2},&#34;created&#34;:{&#34;string&#34;:&#34;58982870-90c6-11e6-b029-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:99.5},&#34;product&#34;:{&#34;string&#34;:&#34;OP-DAX-C-20150201-100&#34;},&#34;qty&#34;:{&#34;int&#34;:100}}</br>{&#34;id&#34;:{&#34;int&#34;:3},&#34;created&#34;:{&#34;string&#34;:&#34;58987690-90c6-11e6-b029-9b89c16b65a4&#34;},&#34;price&#34;:{&#34;float&#34;:150.0},&#34;product&#34;:{&#34;string&#34;:&#34;FU-KOSPI-C-20150201-100&#34;},&#34;qty&#34;:{&#34;int&#34;:200}}</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_3_0" class="trigger" data-tooltip-id="3_0" title="SLF4J: Class path contains multiple SLF4J bindings.</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-serde-tools/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/schema-registry/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</br>SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]</br>Processed a total of 6 messages</br></br>">view</button>
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 1 out of 1
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        20.98 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header gray">
                    <div class="cell">
                        Test Cassandra Sink Connector
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Write Entries into Topic
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        3.91
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm -i --network=kafkaconnectcassandra_default landoop/fast-data-dev</br>  kafka-avro-console-producer --broker-list fast-data-dev:9092</br>    --topic cassandra-sink --property schema.registry.url=&#34;http://fast-data-dev:8081&#34;</br>    --property</br>    value.schema=&#39;{&#34;type&#34;:&#34;record&#34;,&#34;name&#34;:&#34;myrecord&#34;,&#34;fields&#34;:[{&#34;name&#34;:&#34;id&#34;,&#34;type&#34;:&#34;int&#34;},{&#34;name&#34;:&#34;created&#34;, &#34;type&#34;: &#34;string&#34;}, {&#34;name&#34;:&#34;product&#34;, &#34;type&#34;: &#34;string&#34;}, {&#34;name&#34;:&#34;price&#34;, &#34;type&#34;: &#34;double&#34;}]}&#39;</br></br>'>docker run --rm -i --network=kafkaconnectcassandra_default landoop/fast-data-dev</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm -i --network=kafkaconnectcassandra_default landoop/fast-data-dev
  kafka-avro-console-producer --broker-list fast-data-dev:9092
    --topic cassandra-sink --property schema.registry.url=&#34;http://fast-data-dev:8081&#34;
    --property
    value.schema=&#39;{&#34;type&#34;:&#34;record&#34;,&#34;name&#34;:&#34;myrecord&#34;,&#34;fields&#34;:[{&#34;name&#34;:&#34;id&#34;,&#34;type&#34;:&#34;int&#34;},{&#34;name&#34;:&#34;created&#34;, &#34;type&#34;: &#34;string&#34;}, {&#34;name&#34;:&#34;product&#34;, &#34;type&#34;: &#34;string&#34;}, {&#34;name&#34;:&#34;price&#34;, &#34;type&#34;: &#34;double&#34;}]}&#39;

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_4_0" class="trigger" data-tooltip-id="4_0" title="SLF4J: Class path contains multiple SLF4J bindings.</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-serde-tools/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/schema-registry/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</br>SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]</br></br>">view</button>
                        
                    </div>
                </div><div class="row">
                    <div class="cell">
                        Verify entries
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        2.25
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker run --rm -i --network=kafkaconnectcassandra_default landoop/cassandra</br>  cqlsh -u cassandra -p cassandra cassandra</br></br>'>docker run --rm -i --network=kafkaconnectcassandra_default landoop/cassandra</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker run --rm -i --network=kafkaconnectcassandra_default landoop/cassandra
  cqlsh -u cassandra -p cassandra cassandra

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_4_1" class="trigger" data-tooltip-id="4_1" title=" id | created             | price | product                         | qty</br>----+---------------------+-------+---------------------------------+------</br>  1 | 2016-05-06 13:53:00 |  94.2 |          OP-DAX-P-20150201-95.7 | null</br>  2 | 2016-05-06 13:54:00 |  99.5 |           OP-DAX-C-20150201-100 | null</br>  4 | 2016-05-06 13:56:00 |   150 |         FU-KOSPI-C-20150201-100 | null</br>  3 | 2016-05-06 13:55:00 | 10000 | FU-DATAMOUNTAINEER-20150201-100 | null</br></br>(4 rows)</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 2 out of 2
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        6.17 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header yellow">
                    <div class="cell">
                        Other Tests
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Read First 2000 Lines of Connect Logs
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        0.05
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         <a href="" title='docker exec kafkaconnectcassandra_fast-data-dev_1 head -n2000 /var/log/connect-distributed.log</br></br>'>docker exec kafkaconnectcassandra_fast-data-dev_1 head -n2000 /var/log/connect-distributed.log</a>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker exec kafkaconnectcassandra_fast-data-dev_1 head -n2000 /var/log/connect-distributed.log

                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_5_0" class="trigger" data-tooltip-id="5_0" title="SLF4J: Class path contains multiple SLF4J bindings.</br>SLF4J: Found binding in [jar:file:/extra-connect-jars/kafka-connect-twitter-0.1-develop-8624fbe-jar-with-dependencies.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/confluent-common/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-serde-tools/slf4j-log4j12-1.7.6.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-blockchain/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-bloomberg/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-cassandra/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-druid/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-elastic/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-hazelcast/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-hbase/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-hdfs/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-influxdb/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-jms/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-kudu/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-redis/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-rethink/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-voltdb/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka-connect-yahoo/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: Found binding in [jar:file:/opt/confluent-3.0.1/share/java/kafka/slf4j-log4j12-1.7.21.jar!/org/slf4j/impl/StaticLoggerBinder.class]</br>SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.</br>[main] INFO org.apache.kafka.connect.runtime.distributed.DistributedConfig - DistributedConfig values: </br>	cluster = connect</br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	offset.storage.topic = connect-offsets</br>	ssl.truststore.password = null</br>	key.converter = class io.confluent.connect.avro.AvroConverter</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	config.storage.topic = connect-configs</br>	request.timeout.ms = 40000</br>	rest.advertised.host.name = null</br>	heartbeat.interval.ms = 3000</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	rest.port = 8083</br>	access.control.allow.origin = </br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	worker.unsync.backoff.ms = 300000</br>	internal.value.converter = class org.apache.kafka.connect.json.JsonConverter</br>	send.buffer.bytes = 131072</br>	group.id = connect-cluster</br>	task.shutdown.graceful.timeout.ms = 5000</br>	rest.advertised.port = null</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	value.converter = class io.confluent.connect.avro.AvroConverter</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	worker.sync.timeout.ms = 3000</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	status.storage.topic = connect-statuses</br>	rest.host.name = null</br>	ssl.keystore.location = null</br>	offset.flush.timeout.ms = 5000</br>	ssl.cipher.suites = null</br>	offset.flush.interval.ms = 60000</br>	security.protocol = PLAINTEXT</br>	internal.key.converter = class org.apache.kafka.connect.json.JsonConverter</br>	access.control.allow.methods = </br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br></br>[main] INFO org.eclipse.jetty.util.log - Logging initialized @12735ms</br>[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[main] INFO org.apache.kafka.connect.runtime.Connect - Kafka Connect starting</br>[main] INFO org.apache.kafka.connect.runtime.rest.RestServer - Starting REST server</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Herder starting</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Worker starting</br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 9223372036854775807</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 2147483647</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 9223372036854775807</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = producer-1</br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 2147483647</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.connect.storage.KafkaOffsetBackingStore - Starting KafkaOffsetBackingStore</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Starting KafkaBasedLog with topic connect-offsets</br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = producer-2</br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration group.id = connect-cluster was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = consumer-1</br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[main] INFO org.eclipse.jetty.server.Server - jetty-9.2.12.v20150709</br>[2016-10-12 21:52:56,010] INFO HV000001: Hibernate Validator 5.1.2.Final (org.hibernate.validator.internal.util.Version:27)</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Marking the coordinator fast-data-dev:9092 (id: 2147483647 rack: null) dead for group connect-cluster</br>Oct 12, 2016 9:52:56 PM org.glassfish.jersey.internal.Errors logErrors</br>WARNING: The following warnings have been detected: WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.</br>WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.</br>WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.</br>WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.</br></br>[main] INFO org.eclipse.jetty.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@71ad3d8a{/,null,AVAILABLE}</br>[main] INFO org.eclipse.jetty.server.ServerConnector - Started ServerConnector@7139bd31{HTTP/1.1}{0.0.0.0:8083}</br>[main] INFO org.eclipse.jetty.server.Server - Started @15533ms</br>[main] INFO org.apache.kafka.connect.runtime.rest.RestServer - REST server listening at http://172.19.0.3:8083/, advertising URL http://172.19.0.3:8083/</br>[main] INFO org.apache.kafka.connect.runtime.Connect - Kafka Connect started</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Finished reading KafkaBasedLog for topic connect-offsets</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Started KafkaBasedLog for topic connect-offsets</br>[DistributedHerder] INFO org.apache.kafka.connect.storage.KafkaOffsetBackingStore - Finished reading offsets topic and starting KafkaOffsetBackingStore</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Worker started</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Starting KafkaBasedLog with topic connect-statuses</br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 0</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.StringSerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = producer-3</br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 0</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.StringSerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration group.id = connect-cluster was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = consumer-2</br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Finished reading KafkaBasedLog for topic connect-statuses</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Started KafkaBasedLog for topic connect-statuses</br>[DistributedHerder] INFO org.apache.kafka.connect.storage.KafkaConfigBackingStore - Starting KafkaConfigBackingStore</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Starting KafkaBasedLog with topic connect-configs</br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.StringSerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	sasl.mechanism = GSSAPI</br>	max.block.ms = 60000</br>	interceptor.classes = null</br>	ssl.truststore.password = null</br>	client.id = producer-4</br>	ssl.endpoint.identification.algorithm = null</br>	request.timeout.ms = 30000</br>	acks = all</br>	receive.buffer.bytes = 32768</br>	ssl.truststore.type = JKS</br>	retries = 2147483647</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	send.buffer.bytes = 131072</br>	compression.type = none</br>	metadata.fetch.timeout.ms = 60000</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	buffer.memory = 33554432</br>	timeout.ms = 30000</br>	key.serializer = class org.apache.kafka.common.serialization.StringSerializer</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	block.on.buffer.full = false</br>	ssl.key.password = null</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	max.in.flight.requests.per.connection = 1</br>	metrics.num.samples = 2</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	batch.size = 16384</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	max.request.size = 1048576</br>	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner</br>	linger.ms = 0</br></br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration group.id = connect-cluster was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.producer.ProducerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = consumer-3</br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cluster</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration config.storage.topic = connect-configs was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration status.storage.topic = connect-statuses was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration rest.port = 8083 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.key.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter.schemas.enable = false was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration internal.value.converter = org.apache.kafka.connect.json.JsonConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration offset.storage.topic = connect-offsets was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration value.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter = io.confluent.connect.avro.AvroConverter was supplied but isn&#39;t a known config.</br>[DistributedHerder] WARN org.apache.kafka.clients.consumer.ConsumerConfig - The configuration key.converter.schema.registry.url = http://localhost:8081 was supplied but isn&#39;t a known config.</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Finished reading KafkaBasedLog for topic connect-configs</br>[DistributedHerder] INFO org.apache.kafka.connect.util.KafkaBasedLog - Started KafkaBasedLog for topic connect-configs</br>[DistributedHerder] INFO org.apache.kafka.connect.storage.KafkaConfigBackingStore - Started KafkaConfigBackingStore</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Herder started</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cluster.</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 1</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-6ca4f06d-ba0d-4490-a4c4-c29b647a0177&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=-1, connectorIds=[], taskIds=[]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset -1</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[KafkaBasedLog Work Thread - connect-configs] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Connector cassandra-source config updated</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Rebalance started</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished stopping tasks in preparation for rebalance</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 2</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-6ca4f06d-ba0d-4490-a4c4-c29b647a0177&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=1, connectorIds=[cassandra-source], taskIds=[]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset 1</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-source of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[qtp330128595-29] INFO org.apache.kafka.connect.runtime.rest.RestServer - 172.19.0.4 - - [12/Oct/2016:21:53:45 +0000] &#34;POST /connectors HTTP/1.1&#34; 201 511  868</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-source with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Starting Cassandra source task with {connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.import.mode=incremental, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.username=cassandra}.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Setting task configurations for 1 workers.</br>[KafkaBasedLog Work Thread - connect-configs] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Tasks [cassandra-source-0] configs updated</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Rebalance started</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopped connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished stopping tasks in preparation for rebalance</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 3</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-6ca4f06d-ba0d-4490-a4c4-c29b647a0177&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=3, connectorIds=[cassandra-source], taskIds=[cassandra-source-0]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset 3</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-source of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-source with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Starting Cassandra source task with {connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.import.mode=incremental, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.username=cassandra}.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Setting task configurations for 1 workers.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.TaskConfig - TaskConfig values: </br>	task.class = class com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated task cassandra-source-0 with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSource - CassandraConfigSource values: </br>	connect.cassandra.import.mode = incremental</br>	connect.cassandra.key.space = source</br>	connect.cassandra.import.source.allow.filtering = true</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.import.route.query = INSERT INTO cassandra-source SELECT * FROM orders PK created</br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.import.poll.interval = 60000</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.source.task.batch.size = 100</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.source.task.buffer.size = 10000</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.assigned.tables = orders</br>	connect.cassandra.max.retires = 20</br></br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - </br></br>    ____        __        __  ___                  __        _</br>   / __ \____ _/ /_____ _/  |/  /___  __  ______  / /_____ _(_)___  ___  ___  _____</br>  / / / / __ `/ __/ __ `/ /|_/ / __ \/ / / / __ \/ __/ __ `/ / __ \/ _ \/ _ \/ ___/</br> / /_/ / /_/ / /_/ /_/ / /  / / /_/ / /_/ / / / / /_/ /_/ / / / / /  __/  __/ /</br>/_____/\__,_/\__/\__,_/_/  /_/\____/\__,_/_/ /_/\__/\__,_/_/_/ /_/\___/\___/_/</br>       ______                                __           _____</br>      / ____/___ _______________ _____  ____/ /________ _/ ___/____  __  _______________</br>     / /   / __ `/ ___/ ___/ __ `/ __ \/ __  / ___/ __ `/\__ \/ __ \/ / / / ___/ ___/ _ \</br>    / /___/ /_/ (__  |__  ) /_/ / / / / /_/ / /  / /_/ /___/ / /_/ / /_/ / /  / /__/  __/</br>    \____/\__,_/____/____/\__,_/_/ /_/\__,_/_/   \__,_//____/\____/\__,_/_/   \___/\___/</br></br> By Andrew Stevenson.</br>[pool-1-thread-1] INFO com.datastax.driver.core.NettyUtil - Found Netty&#39;s native epoll transport in the classpath, using it</br>[pool-1-thread-1] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name &#39;datacenter1&#39; for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)</br>[pool-1-thread-1] INFO com.datastax.driver.core.Cluster - New Cassandra host cassandra/172.19.0.2:9042 added</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Connection to Cassandra established.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Received setting:</br> CassandraSourceSetting(com.datamountaineer.connector.config.Config@60444b8a,source,false,Some(created),60000,CassandraConfigSource({connect.cassandra.import.mode=incremental, connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, task.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.assigned.tables=orders, connect.cassandra.username=cassandra}),ThrowErrorPolicy(),20)</br>[pool-1-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Source task WorkerSourceTask{id=cassandra-source-0} finished initialization and start</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Query SELECT * FROM source.orders WHERE created &gt; maxTimeuuid(?) AND created &lt;= minTimeuuid(?)  ALLOW FILTERING executing with bindings (1900-01-01 00:00:00.000Z, 2016-10-12 21:53:49.454Z).</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying returning results for source.orders.</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:53:44.564Z</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:53:44.567Z</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:53:44.569Z</br>[ForkJoinPool-1-worker-29] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Processed 3 rows for table cassandra-source.orders</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.queues.QueueHelpers$ - Found 3. Draining entries to batchSize 100.</br>[KafkaBasedLog Work Thread - connect-configs] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Connector cassandra-sink config updated</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Rebalance started</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopped connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping task cassandra-source-0</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Stopping Cassandra source.</br>[qtp330128595-44] INFO org.apache.kafka.connect.runtime.rest.RestServer - 172.19.0.4 - - [12/Oct/2016:21:53:50 +0000] &#34;POST /connectors HTTP/1.1&#34; 201 468  511</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Shutting down Queries.</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying stopped for source.cassandra-source.</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - All stopped.</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Shutting down Cassandra driver connections.</br>[CLASSPATH traversal thread.] INFO org.reflections.Reflections - Reflections took 54217 ms to scan 1729 urls, producing 24326 keys and 198597 values </br>[pool-1-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Finished WorkerSourceTask{id=cassandra-source-0} commitOffsets successfully in 2249 ms</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished stopping tasks in preparation for rebalance</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 4</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-6ca4f06d-ba0d-4490-a4c4-c29b647a0177&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=4, connectorIds=[cassandra-source, cassandra-sink], taskIds=[cassandra-source-0]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset 4</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-source of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-source with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Starting Cassandra source task with {connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.import.mode=incremental, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.username=cassandra}.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Setting task configurations for 1 workers.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>	tasks.max = 1</br>	name = cassandra-sink</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-sink of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-sink with version 1 of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSink - CassandraConfigSink values: </br>	connect.cassandra.key.space = sink</br>	connect.cassandra.export.route.query = INSERT INTO orders SELECT * FROM cassandra-sink</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.max.retires = 20</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>	tasks.max = 1</br>	name = cassandra-sink</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector - Setting task configurations for 1 workers.</br>[KafkaBasedLog Work Thread - connect-configs] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Tasks [cassandra-source-0, cassandra-sink-0] configs updated</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.TaskConfig - TaskConfig values: </br>	task.class = class com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated task cassandra-source-0 with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Rebalance started</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopped connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping connector cassandra-sink</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSource - CassandraConfigSource values: </br>	connect.cassandra.import.mode = incremental</br>	connect.cassandra.key.space = source</br>	connect.cassandra.import.source.allow.filtering = true</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.import.route.query = INSERT INTO cassandra-source SELECT * FROM orders PK created</br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.import.poll.interval = 60000</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.source.task.batch.size = 100</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.source.task.buffer.size = 10000</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.assigned.tables = orders</br>	connect.cassandra.max.retires = 20</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopped connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Stopping task cassandra-source-0</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - </br></br>    ____        __        __  ___                  __        _</br>   / __ \____ _/ /_____ _/  |/  /___  __  ______  / /_____ _(_)___  ___  ___  _____</br>  / / / / __ `/ __/ __ `/ /|_/ / __ \/ / / / __ \/ __/ __ `/ / __ \/ _ \/ _ \/ ___/</br> / /_/ / /_/ / /_/ /_/ / /  / / /_/ / /_/ / / / / /_/ /_/ / / / / /  __/  __/ /</br>/_____/\__,_/\__/\__,_/_/  /_/\____/\__,_/_/ /_/\__/\__,_/_/_/ /_/\___/\___/_/</br>       ______                                __           _____</br>      / ____/___ _______________ _____  ____/ /________ _/ ___/____  __  _______________</br>     / /   / __ `/ ___/ ___/ __ `/ __ \/ __  / ___/ __ `/\__ \/ __ \/ / / / ___/ ___/ _ \</br>    / /___/ /_/ (__  |__  ) /_/ / / / / /_/ / /  / /_/ /___/ / /_/ / /_/ / /  / /__/  __/</br>    \____/\__,_/____/____/\__,_/_/ /_/\__,_/_/   \__,_//____/\____/\__,_/_/   \___/\___/</br></br> By Andrew Stevenson.</br>[pool-1-thread-1] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name &#39;datacenter1&#39; for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)</br>[pool-1-thread-1] INFO com.datastax.driver.core.Cluster - New Cassandra host cassandra/172.19.0.2:9042 added</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Connection to Cassandra established.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Received setting:</br> CassandraSourceSetting(com.datamountaineer.connector.config.Config@4f4f6e09,source,false,Some(created),60000,CassandraConfigSource({connect.cassandra.import.mode=incremental, connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, task.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.assigned.tables=orders, connect.cassandra.username=cassandra}),ThrowErrorPolicy(),20)</br>[pool-1-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Source task WorkerSourceTask{id=cassandra-source-0} finished initialization and start</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Stopping Cassandra source.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Shutting down Queries.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying stopped for source.cassandra-source.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - All stopped.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Shutting down Cassandra driver connections.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished stopping tasks in preparation for rebalance</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cluster</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cluster with generation 5</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Joined group and got assignment: Assignment{error=0, leader=&#39;connect-1-6ca4f06d-ba0d-4490-a4c4-c29b647a0177&#39;, leaderUrl=&#39;http://172.19.0.3:8083/&#39;, offset=6, connectorIds=[cassandra-source, cassandra-sink], taskIds=[cassandra-source-0, cassandra-sink-0]}</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connectors and tasks using config offset 6</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-source of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-source with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Starting Cassandra source task with {connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.import.mode=incremental, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.username=cassandra}.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-source</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector</br>	tasks.max = 1</br>	name = cassandra-source</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector - Setting task configurations for 1 workers.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.ConnectorConfig - ConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>	tasks.max = 1</br>	name = cassandra-sink</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating connector cassandra-sink of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated connector cassandra-sink with version 1 of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSink - CassandraConfigSink values: </br>	connect.cassandra.key.space = sink</br>	connect.cassandra.export.route.query = INSERT INTO orders SELECT * FROM cassandra-sink</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.max.retires = 20</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Finished creating connector cassandra-sink</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.SourceConnectorConfig - SourceConnectorConfig values: </br>	connector.class = com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector</br>	tasks.max = 1</br>	name = cassandra-sink</br></br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkConnector - Setting task configurations for 1 workers.</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.TaskConfig - TaskConfig values: </br>	task.class = class com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating task cassandra-source-0</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated task cassandra-source-0 with version null of type com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Starting task cassandra-sink-0</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSource - CassandraConfigSource values: </br>	connect.cassandra.import.mode = incremental</br>	connect.cassandra.key.space = source</br>	connect.cassandra.import.source.allow.filtering = true</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.import.route.query = INSERT INTO cassandra-source SELECT * FROM orders PK created</br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.import.poll.interval = 60000</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.source.task.batch.size = 100</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.source.task.buffer.size = 10000</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.assigned.tables = orders</br>	connect.cassandra.max.retires = 20</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.TaskConfig - TaskConfig values: </br>	task.class = class com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkTask</br></br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Creating task cassandra-sink-0</br>[DistributedHerder] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkTask - Task initialising</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.Worker - Instantiated task cassandra-sink-0 with version 1 of type com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkTask</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - </br></br>    ____        __        __  ___                  __        _</br>   / __ \____ _/ /_____ _/  |/  /___  __  ______  / /_____ _(_)___  ___  ___  _____</br>  / / / / __ `/ __/ __ `/ /|_/ / __ \/ / / / __ \/ __/ __ `/ / __ \/ _ \/ _ \/ ___/</br> / /_/ / /_/ / /_/ /_/ / /  / / /_/ / /_/ / / / / /_/ /_/ / / / / /  __/  __/ /</br>/_____/\__,_/\__/\__,_/_/  /_/\____/\__,_/_/ /_/\__/\__,_/_/_/ /_/\___/\___/_/</br>       ______                                __           _____</br>      / ____/___ _______________ _____  ____/ /________ _/ ___/____  __  _______________</br>     / /   / __ `/ ___/ ___/ __ `/ __ \/ __  / ___/ __ `/\__ \/ __ \/ / / / ___/ ___/ _ \</br>    / /___/ /_/ (__  |__  ) /_/ / / / / /_/ / /  / /_/ /___/ / /_/ / /_/ / /  / /__/  __/</br>    \____/\__,_/____/____/\__,_/_/ /_/\__,_/_/   \__,_//____/\____/\__,_/_/   \___/\___/</br></br> By Andrew Stevenson.</br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = </br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cassandra-sink</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.clients.consumer.ConsumerConfig - ConsumerConfig values: </br>	metric.reporters = []</br>	metadata.max.age.ms = 300000</br>	partition.assignment.strategy = [org.apache.kafka.clients.consumer.RangeAssignor]</br>	reconnect.backoff.ms = 50</br>	sasl.kerberos.ticket.renew.window.factor = 0.8</br>	max.partition.fetch.bytes = 1048576</br>	bootstrap.servers = [localhost:9092]</br>	ssl.keystore.type = JKS</br>	enable.auto.commit = false</br>	sasl.mechanism = GSSAPI</br>	interceptor.classes = null</br>	exclude.internal.topics = true</br>	ssl.truststore.password = null</br>	client.id = consumer-4</br>	ssl.endpoint.identification.algorithm = null</br>	max.poll.records = 2147483647</br>	check.crcs = true</br>	request.timeout.ms = 40000</br>	heartbeat.interval.ms = 3000</br>	auto.commit.interval.ms = 5000</br>	receive.buffer.bytes = 65536</br>	ssl.truststore.type = JKS</br>	ssl.truststore.location = null</br>	ssl.keystore.password = null</br>	fetch.min.bytes = 1</br>	send.buffer.bytes = 131072</br>	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	group.id = connect-cassandra-sink</br>	retry.backoff.ms = 100</br>	sasl.kerberos.kinit.cmd = /usr/bin/kinit</br>	sasl.kerberos.service.name = null</br>	sasl.kerberos.ticket.renew.jitter = 0.05</br>	ssl.trustmanager.algorithm = PKIX</br>	ssl.key.password = null</br>	fetch.max.wait.ms = 500</br>	sasl.kerberos.min.time.before.relogin = 60000</br>	connections.max.idle.ms = 540000</br>	session.timeout.ms = 30000</br>	metrics.num.samples = 2</br>	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer</br>	ssl.protocol = TLS</br>	ssl.provider = null</br>	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]</br>	ssl.keystore.location = null</br>	ssl.cipher.suites = null</br>	security.protocol = PLAINTEXT</br>	ssl.keymanager.algorithm = SunX509</br>	metrics.sample.window.ms = 30000</br>	auto.offset.reset = earliest</br></br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version : 0.10.0.0</br>[DistributedHerder] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId : b8642491e78c5a13</br>[DistributedHerder] INFO org.apache.kafka.connect.runtime.distributed.DistributedHerder - Finished starting connectors and tasks</br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.config.CassandraConfigSink - CassandraConfigSink values: </br>	connect.cassandra.key.space = sink</br>	connect.cassandra.export.route.query = INSERT INTO orders SELECT * FROM cassandra-sink</br>	connect.cassandra.trust.store.path = </br>	connect.cassandra.ssl.client.cert.auth = false</br>	connect.cassandra.password = [hidden]</br>	connect.cassandra.key.store.password = [hidden]</br>	connect.cassandra.username = cassandra</br>	connect.cassandra.error.policy = THROW</br>	connect.cassandra.contact.points = cassandra</br>	connect.cassandra.ssl.enabled = false</br>	connect.cassandra.trust.store.password = [hidden]</br>	connect.cassandra.port = 9042</br>	connect.cassandra.key.store.path = </br>	connect.cassandra.retry.interval = 60000</br>	connect.cassandra.max.retires = 20</br></br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraSinkTask - </br>    ____        __        __  ___                  __        _</br>   / __ \____ _/ /_____ _/  |/  /___  __  ______  / /_____ _(_)___  ___  ___  _____</br>  / / / / __ `/ __/ __ `/ /|_/ / __ \/ / / / __ \/ __/ __ `/ / __ \/ _ \/ _ \/ ___/</br> / /_/ / /_/ / /_/ /_/ / /  / / /_/ / /_/ / / / / /_/ /_/ / / / / /  __/  __/ /</br>/_____/\__,_/\__/\__,_/_/  /_/\____/\__,_/_/ /_/\__/\__,_/_/_/ /_/\___/\___/_/</br>       ______                                __           _____ _       __</br>      / ____/___ _______________ _____  ____/ /________ _/ ___/(_)___  / /__</br>     / /   / __ `/ ___/ ___/ __ `/ __ \/ __  / ___/ __ `/\__ \/ / __ \/ //_/</br>    / /___/ /_/ (__  |__  ) /_/ / / / / /_/ / /  / /_/ /___/ / / / / / ,&lt;</br>    \____/\__,_/____/____/\__,_/_/ /_/\__,_/_/   \__,_//____/_/_/ /_/_/|_|</br></br> By Andrew Stevenson.</br>[pool-1-thread-1] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name &#39;datacenter1&#39; for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)</br>[pool-1-thread-1] INFO com.datastax.driver.core.Cluster - New Cassandra host cassandra/172.19.0.2:9042 added</br>[pool-1-thread-2] INFO com.datastax.driver.core.policies.DCAwareRoundRobinPolicy - Using data-center name &#39;datacenter1&#39; for DCAwareRoundRobinPolicy (if this is incorrect, please provide the correct datacenter name with DCAwareRoundRobinPolicy constructor)</br>[pool-1-thread-2] INFO com.datastax.driver.core.Cluster - New Cassandra host cassandra/172.19.0.2:9042 added</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask - Connection to Cassandra established.</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Received setting:</br> CassandraSourceSetting(com.datamountaineer.connector.config.Config@3af8200e,source,false,Some(created),60000,CassandraConfigSource({connect.cassandra.import.mode=incremental, connector.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceConnector, connect.cassandra.key.space=source, connect.cassandra.contact.points=cassandra, task.class=com.datamountaineer.streamreactor.connect.cassandra.source.CassandraSourceTask, tasks.max=1, name=cassandra-source, connect.cassandra.import.route.query=INSERT INTO cassandra-source SELECT * FROM orders PK created, connect.cassandra.password=cassandra, connect.cassandra.assigned.tables=orders, connect.cassandra.username=cassandra}),ThrowErrorPolicy(),20)</br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraJsonWriter - Initialising Cassandra writer.</br>[pool-1-thread-2] INFO com.datamountaineer.streamreactor.connect.cassandra.sink.CassandraJsonWriter - Preparing statements for cassandra-sink.</br>[pool-1-thread-2] INFO org.apache.kafka.connect.runtime.WorkerSinkTask - Sink task WorkerSinkTask{id=cassandra-sink-0} finished initialization and start</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Discovered coordinator fast-data-dev:9092 (id: 2147483647 rack: null) for group connect-cassandra-sink.</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Revoking previously assigned partitions [] for group connect-cassandra-sink</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - (Re-)joining group connect-cassandra-sink</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator - Successfully joined group connect-cassandra-sink with generation 1</br>[pool-1-thread-2] INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator - Setting newly assigned partitions [cassandra-sink-0] for group connect-cassandra-sink</br>[pool-1-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Source task WorkerSourceTask{id=cassandra-source-0} finished initialization and start</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Query SELECT * FROM source.orders WHERE created &gt; maxTimeuuid(?) AND created &lt;= minTimeuuid(?)  ALLOW FILTERING executing with bindings (1900-01-01 00:00:00.000Z, 2016-10-12 21:53:58.729Z).</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying returning results for source.orders.</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:53:44.564Z</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.queues.QueueHelpers$ - Found 1. Draining entries to batchSize 100.</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:53:44.567Z</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.queues.QueueHelpers$ - Found 1. Draining entries to batchSize 100.</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Storing offset 2016-10-12 21:53:44.569Z</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.queues.QueueHelpers$ - Found 1. Draining entries to batchSize 100.</br>[ForkJoinPool-1-worker-43] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Processed 3 rows for table cassandra-source.orders</br>[pool-4-thread-1] INFO org.apache.kafka.connect.runtime.WorkerSourceTask - Finished WorkerSourceTask{id=cassandra-source-0} commitOffsets successfully in 4 ms</br>[pool-1-thread-2] INFO org.apache.kafka.connect.runtime.WorkerSinkTask - WorkerSinkTask{id=cassandra-sink-0} Committing offsets</br>[pool-1-thread-1] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Query SELECT * FROM source.orders WHERE created &gt; maxTimeuuid(?) AND created &lt;= minTimeuuid(?)  ALLOW FILTERING executing with bindings (2016-10-12 21:53:44.569Z, 2016-10-12 21:54:58.730Z).</br>[ForkJoinPool-1-worker-27] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Querying returning results for source.orders.</br>[ForkJoinPool-1-worker-27] INFO com.datamountaineer.streamreactor.connect.cassandra.source.CassandraTableReader - Processed 0 rows for table cassandra-source.orders</br></br>">view</button>
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 1 out of 1
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        0.05 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div><div class="row header orange">
                    <div class="cell">
                        Clean-up Containers
                    </div>
                    <div class="cell">
                        <!--                         Status -->
                    </div>
                    <div class="cell">
                        Time (sec)
                    </div>
                    <div class="cell">
                        Exit Code
                    </div>
                    <div class="cell">
                        Command
                    </div>
                    <div class="cell width12">
                        StdOutput
                    </div>
                    <div class="cell width12">
                        StdError
                    </div>
                </div>

                <div class="row">
                    <div class="cell">
                        Docker Compose Down
                    </div>
                    <div class="cell  center">
                         &#10004;
                    </div>
                    <div class="cell">
                        11.63
                    </div>
                    <div class="cell">
                        0
                    </div>
                    <!-- <div class="cell" style="overflow:hidden;">
                         
                         
                         docker-compose down</br>
                         
                         
                         </div> -->
                    <div class="cell">
                        docker-compose down
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        
                    </div>
                    <div class="cell" style="overflow:hidden;">
                        <button id="trigger_6_0" class="trigger" data-tooltip-id="6_0" title="Stopping kafkaconnectcassandra_fast-data-dev_1 ... </br>Stopping kafkaconnectcassandra_cassandra_1 ... </br>[2A[2KStopping kafkaconnectcassandra_fast-data-dev_1 ... done[2B[1A[2KStopping kafkaconnectcassandra_cassandra_1 ... done[1BRemoving kafkaconnectcassandra_fast-data-dev_1 ... </br>Removing kafkaconnectcassandra_cassandra_1 ... </br>[1A[2KRemoving kafkaconnectcassandra_cassandra_1 ... done[1B[2A[2KRemoving kafkaconnectcassandra_fast-data-dev_1 ... done[2BRemoving network kafkaconnectcassandra_default</br></br>">view</button>
                        
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell" style="font-weight: bold;">
                        Passed 1 out of 1
                    </div>
                    <div class="cell" style="font-weight: bold;">
                        11.63 seconds
                    </div>
                </div>

                <div class="row">
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                    <div class="cell skip"></div>
                </div>
            </div>

        </div>

        <script src="https://code.jquery.com/jquery-1.12.2.min.js"></script>
        <script src="https://code.jquery.com/ui/1.11.4/jquery-ui.min.js"></script>
        <link rel="stylesheet" href="https://code.jquery.com/ui/1.11.4/themes/smoothness/jquery-ui.css">

        <script>
         $(function () {
             //show
             $(document).on('click', '.trigger', function () {
                 $(this).addClass("on");
                 $(this).tooltip({
                     items: '.trigger.on',
                     position: {
                         my: "left+30 center",
                         at: "right center",
                         collision: "flip"
                     },
                     content: function(){
                         var element = $( this );
                         return element.attr('title')
                     }
                 });
                 $(this).trigger('mouseenter');
             });
             //hide
             $(document).on('click', '.trigger.on', function () {
                 $(this).tooltip('close');
                 $(this).removeClass("on");
             });
             //prevent mouseout and other related events from firing their handlers
             $(".trigger").on('mouseout', function (e) {
                 e.stopImmediatePropagation();
             });
         });
        </script>
    </body>
</html>
